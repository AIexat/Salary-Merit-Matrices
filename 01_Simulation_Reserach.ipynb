{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e2608-b836-4ea8-8086-79af67cf7a01",
   "metadata": {},
   "source": [
    "# Merit Matrix Monte Carlo Analysis - Multi-Configuration\n",
    "\n",
    "**Цель исследования:** Валидация точности метода агрегированных распределений для расчета бюджета повышений заработной платы через Monte Carlo симуляции.\n",
    "\n",
    "**Ключевой вопрос:** При каком размере группы сотрудников метод становится надежным (success rate ≥ 80%)?\n",
    "\n",
    "## Методология\n",
    "\n",
    "1. **Данные:** 395,325 сотрудников из Москвы (обзор компенсаций, май 2025)\n",
    "2. **Группировка:** Сегментация по Company × Function (типичная практика HR)\n",
    "3. **Тестирование:** 120 конфигураций merit matrices (2-7 CR bins × 3-7 ratings × 4 типа распределений)\n",
    "4. **Симуляция:** 50,000 Monte Carlo итераций на группу\n",
    "5. **Метрика успеха:** % симуляций, попавших в диапазон ±5% от целевого бюджета\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Configuration Section** → Параметры анализа и конфигурации матриц\n",
    "2. **Data Loading** → Загрузка и подготовка данных о компенсациях\n",
    "3. **Analysis Execution** → Запуск Monte Carlo симуляций для всех конфигураций\n",
    "4. **Results** → Анализ результатов и сохранение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae9698-384e-42f4-a197-7123e1a6fe0d",
   "metadata": {},
   "source": [
    "### Библиотеки и их назначение\n",
    "\n",
    "**Научные вычисления:**\n",
    "- `numpy` — векторизованные операции, массивы для матриц\n",
    "- `pandas` — обработка табличных данных, группировка по Company×Function\n",
    "- `scipy.stats.dirichlet` — perturbation распределений рейтингов в Monte Carlo\n",
    "\n",
    "**Оптимизация производительности:**\n",
    "- `numba` — JIT-компиляция критичного Monte Carlo loop (ускорение ~100x)\n",
    "- `prange` — параллелизация симуляций на всех CPU cores\n",
    "\n",
    "**Утилиты:**\n",
    "- `time`, `datetime` — измерение времени выполнения\n",
    "- `pathlib.Path` — кроссплатформенная работа с файлами\n",
    "- `warnings` — отключение технических предупреждений для читаемости\n",
    "\n",
    "**Визуализация:**\n",
    "- `matplotlib`, `seaborn` — создание heatmaps и графиков результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119ee72-58a7-4bf5-96c1-1c6c269d8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import dirichlet\n",
    "from numba import jit, prange\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87617e9-4e41-4dfd-b581-ccb323931872",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "### Источник данных\n",
    "\n",
    "**Обзор компенсаций:** Реальные данные о зарплатах от компаний-участников  \n",
    "**Референтная дата:** 01 мая 2025 года  \n",
    "**Охват:** Все регионы России, множество функций и грейдов  \n",
    "\n",
    "### Этапы подготовки данных\n",
    "\n",
    "#### Шаг 1: Загрузка и переименование\n",
    "- Загружаем исходный parquet файл с данными обзора\n",
    "- Переименовываем столбцы на английский для консистентности кода\n",
    "\n",
    "#### Шаг 2: Географическая фильтрация\n",
    "- **Выбираем только Москву** для однородности рынка труда\n",
    "- Обоснование: Москва содержит наибольшую выборку по всем функциям и грейдам\n",
    "\n",
    "#### Шаг 3: Расчет Midpoint\n",
    "- **Midpoint** = медиана базовой зарплаты внутри Company × Function × Grade\n",
    "- Отражает \"серединную точку\" диапазона, на которую ориентируется компания\n",
    "- Использование медианы: устойчивость к выбросам, стандарт в compensation management\n",
    "\n",
    "#### Шаг 4: Расчет Compa Ratio (CR)\n",
    "- **CR = Базовая зарплата / Midpoint**\n",
    "- CR < 1.0 → сотрудник получает ниже медианы своего грейда\n",
    "- CR = 1.0 → сотрудник на медиане\n",
    "- CR > 1.0 → сотрудник получает выше медианы\n",
    "\n",
    "#### Шаг 5: Агрегация\n",
    "- Убираем Grade из финального датасета\n",
    "- CR уже учитывает позицию относительно грейда\n",
    "- Merit matrices применяются ко всей функции независимо от грейда\n",
    "\n",
    "### Результат\n",
    "- **Итоговый датасет:** Company | Function | BP | CR\n",
    "- Готов для группировки по Company × Function и анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ebacf2c-6ccb-4916-8459-9e34cafb3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка исходных данных обзора компенсаций\n",
    "df_original = pd.read_parquet('03_Final_to_Code_corrected.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e2ab5c51-a6f0-436c-87a3-c1bf9a4f3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименование столбцов для удобства работы\n",
    "df_original = df_original.rename(columns={'Регион/область (заполняется автоматически)': 'Region',\n",
    "                                         'Название компании (заполняется автоматически)': 'Company',\n",
    "                                         'Название функции (заполняется автоматически)': 'Function',\n",
    "                                         'Грейд / Уровень обзора': 'Grade',\n",
    "                                         'Базовый оклад (BP)': 'BP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f30f5e8f-c11d-416d-848c-48a4e7543cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация: только Москва для консистентности анализа\n",
    "df_original = df_original[df_original['Region'] == 'Москва'].copy()\n",
    "\n",
    "# Отбор необходимых столбцов\n",
    "df_original = df_original[['Company', 'Function', 'Grade', 'BP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8e17e73f-8e96-4f72-b4f9-4ca539c1e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Midpoint: медиана BP внутри каждой Company × Function × Grade\n",
    "# Midpoint отражает серединную точку диапазона зарплат для позиции\n",
    "midpoints = df_original.groupby(['Company', \n",
    "                                 'Function', \n",
    "                                 'Grade'])['BP'].median().reset_index()\n",
    "\n",
    "# Устанавливаем названия столбца\n",
    "midpoints = midpoints.rename(columns={'BP': 'Midpoint'})\n",
    "\n",
    "# Объединение данных с рассчитанными midpoints\n",
    "dataset = pd.merge(df_original, midpoints, on=['Company', \n",
    "                                 'Function', \n",
    "                                 'Grade'], how='inner')\n",
    "\n",
    "# Расчет Compa Ratio (CR) для каждого сотрудника\n",
    "# CR = текущая зарплата / midpoint грейда\n",
    "# CR показывает позицию сотрудника относительно рыночной медианы\n",
    "dataset['CR'] = dataset['BP'] / dataset['Midpoint']\n",
    "\n",
    "# Финальная агрегация: убираем Grade\n",
    "# Merit matrices применяются ко всей функции независимо от грейда\n",
    "# CR уже учитывает позицию сотрудника относительно его грейда\n",
    "dataset = dataset[['Company', 'Function', 'BP', 'CR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "122d9975-1c2d-49c2-8cd8-700bd7ce5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем данные для фиксации выборки\n",
    "dataset.to_parquet('Moscow.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f950f3-1bf5-4997-804c-8b9cfef2a800",
   "metadata": {},
   "source": [
    "## 3. Configuration Parameters\n",
    "\n",
    "### Параметры исследования\n",
    "\n",
    "Эта секция определяет ключевые параметры для всего анализа. Изменение этих значений \n",
    "позволяет адаптировать исследование под различные сценарии.\n",
    "\n",
    "#### Входные/выходные файлы\n",
    "- `INPUT_FILE`: Подготовленный датасет с данными Moscow\n",
    "- `OUTPUT_DIR`: Директория для сохранения результатов всех конфигураций\n",
    "\n",
    "#### Параметры Monte Carlo симуляции\n",
    "- `N_SIMULATIONS = 50,000`: Количество итераций на группу\n",
    "  - Больше итераций = выше точность оценки, но дольше время выполнения\n",
    "  - 50K обеспечивает стабильные результаты с приемлемым временем\n",
    "\n",
    "- `MIN_SAMPLE_SIZE = 10`: Минимум сотрудников для включения группы в анализ\n",
    "  - Группы меньше этого размера пропускаются (высокая вариативность)\n",
    "\n",
    "- `BUDGET_TOLERANCE_LOWER/UPPER = 5%`: Диапазон допустимого отклонения\n",
    "  - Symmetric: ±5% означает, что бюджет от 95% до 105% от target считается успешным\n",
    "  - Success rate = % симуляций, попавших в этот диапазон\n",
    "\n",
    "- `CONCENTRATION = 250`: Параметр Dirichlet распределения\n",
    "  - Контролирует variance perturbation вокруг целевого распределения\n",
    "  - Высокое значение (250) → малые отклонения (~±2-3%)\n",
    "  - Имитирует: менеджеры в целом следуют политике, но есть небольшие отклонения\n",
    "\n",
    "#### Тестируемые конфигурации\n",
    "- `CR_BINS_RANGE = [2, 3, 4, 5, 6, 7]`: Количество CR bins в матрице\n",
    "- `RATINGS_RANGE = [3, 4, 5, 6, 7]`: Количество рейтингов\n",
    "- **Типы распределений = 4** (normal, skewed_high, skewed_low, uniform)\n",
    "\n",
    "**Итого: 6 × 5 × 4 = 120 конфигураций для тестирования**\n",
    "\n",
    "### Цель параметризации\n",
    "Проверить **робастность** метода агрегированных распределений:\n",
    "- Зависит ли точность от размера матрицы?\n",
    "- Зависит ли точность от типа распределения рейтингов?\n",
    "- Или главный фактор — размер группы сотрудников?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82863c-3114-42ab-987c-5414e2fddd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "INPUT_FILE = 'Moscow.parquet.gzip'  #\n",
    "OUTPUT_DIR = 'merit_analysis_results'\n",
    "\n",
    "# Analysis parameters\n",
    "N_SIMULATIONS = 50_000          # Monte Carlo iterations per group\n",
    "MIN_SAMPLE_SIZE = 10            # Minimum employees per Company+Function\n",
    "BUDGET_TOLERANCE_LOWER = 0.05   # 5% below target budget tolerance\n",
    "BUDGET_TOLERANCE_UPPER = 0.05   # 5% above target budget tolerance\n",
    "CONCENTRATION = 250             # Dirichlet concentration parameter\n",
    "\n",
    "# Matrix and distribution ranges to test\n",
    "CR_BINS_RANGE = range(2, 8)     # Test 2, 3, 4, 5, 6, 7 CR bins\n",
    "RATINGS_RANGE = range(3, 8)     # Test 3, 4, 5, 6, 7 ratings\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*100)\n",
    "print(f\"  Input file: {INPUT_FILE}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  CR bins to test: {list(CR_BINS_RANGE)}\")\n",
    "print(f\"  Ratings to test: {list(RATINGS_RANGE)}\")\n",
    "print(f\"  Simulations per group: {N_SIMULATIONS:,}\")\n",
    "print(f\"  Budget tolerance: -{BUDGET_TOLERANCE_LOWER*100:.0f}% / +{BUDGET_TOLERANCE_UPPER*100:.0f}%\")\n",
    "\n",
    "# Calculate total combinations\n",
    "total_configs = len(list(CR_BINS_RANGE)) * len(list(RATINGS_RANGE)) * 4  # 4 distribution types\n",
    "print(f\"  Total configurations to test: {total_configs}\")\n",
    "print(\"=\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51dad47-3a49-4eb4-8e07-3eccc202da7f",
   "metadata": {},
   "source": [
    "## 4. Rating Distributions Configuration\n",
    "\n",
    "### Типы распределений рейтингов\n",
    "\n",
    "Определяем 4 типа распределений для тестирования различных сценариев оценки \n",
    "эффективности сотрудников. Каждый тип отражает различную философию performance management.\n",
    "\n",
    "#### 1. Normal (Нормальное распределение)\n",
    "**Философия:** Bell curve — большинство сотрудников \"средние\", меньшинство в хвостах\n",
    "- **Применение:** Наиболее распространенный подход в компаниях\n",
    "- **Пример (5 рейтингов):** 10% | 15% | 50% | 15% | 10%\n",
    "- **Характеристика:** Симметричное распределение вокруг среднего рейтинга\n",
    "\n",
    "#### 2. Skewed High (Скошенное вправо)\n",
    "**Философия:** \"High performers\" — позитивное смещение оценок\n",
    "- **Применение:** Компании с сильной performance culture, tech стартапы\n",
    "- **Пример (5 рейтингов):** 5% | 10% | 20% | 30% | 35%\n",
    "- **Характеристика:** Больше сотрудников получают высокие оценки\n",
    "\n",
    "#### 3. Skewed Low (Скошенное влево)\n",
    "**Философия:** \"Tough grading\" — консервативный подход к оценкам\n",
    "- **Применение:** Традиционные компании, строгие стандарты\n",
    "- **Пример (5 рейтингов):** 35% | 30% | 20% | 10% | 5%\n",
    "- **Характеристика:** Больше сотрудников получают низкие оценки\n",
    "\n",
    "#### 4. Uniform (Равномерное распределение)\n",
    "**Философия:** \"All ratings equally likely\" — отсутствие предпочтений\n",
    "- **Применение:** Baseline для сравнения, теоретический сценарий\n",
    "- **Пример (5 рейтингов):** 20% | 20% | 20% | 20% | 20%\n",
    "- **Характеристика:** Все рейтинги одинаково вероятны\n",
    "\n",
    "### Адаптация к количеству рейтингов\n",
    "- Каждый тип распределения определен для 3, 4, 5, 6, 7 рейтингов\n",
    "- Паттерн распределения сохраняется независимо от количества рейтингов\n",
    "- Все распределения нормализованы (сумма = 100%)\n",
    "\n",
    "### Использование в Monte Carlo\n",
    "- Эти распределения служат **целевыми** (target)\n",
    "- В каждой итерации распределение пертрубируется через Dirichlet(α)\n",
    "- Имитирует реальность: менеджеры стремятся к target, но есть вариация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf17aa8-21be-4326-b2a9-abb52abd4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = {\n",
    "    'normal': {\n",
    "        3: {1: 10, 2: 80, 3: 10},\n",
    "        4: {1: 10, 2: 30, 3: 50, 4: 10},\n",
    "        5: {1: 10, 2: 15, 3: 50, 4: 15, 5: 10},\n",
    "        6: {1: 5, 2: 10, 3: 25, 4: 35, 5: 20, 6: 5},\n",
    "        7: {1: 5, 2: 10, 3: 15, 4: 40, 5: 15, 6: 10, 7: 5}\n",
    "    },\n",
    "    'skewed_high': {\n",
    "        3: {1: 10, 2: 30, 3: 60},\n",
    "        4: {1: 5, 2: 15, 3: 35, 4: 45},\n",
    "        5: {1: 5, 2: 10, 3: 20, 4: 30, 5: 35},\n",
    "        6: {1: 5, 2: 5, 3: 10, 4: 20, 5: 30, 6: 30},\n",
    "        7: {1: 3, 2: 5, 3: 7, 4: 15, 5: 20, 6: 25, 7: 25}\n",
    "    },\n",
    "    'skewed_low': {\n",
    "        3: {1: 60, 2: 30, 3: 10},\n",
    "        4: {1: 45, 2: 35, 3: 15, 4: 5},\n",
    "        5: {1: 35, 2: 30, 3: 20, 4: 10, 5: 5},\n",
    "        6: {1: 30, 2: 30, 3: 20, 4: 10, 5: 5, 6: 5},\n",
    "        7: {1: 25, 2: 25, 3: 20, 4: 15, 5: 7, 6: 5, 7: 3}\n",
    "    },\n",
    "    'uniform': {\n",
    "        3: {1: 33.33, 2: 33.33, 3: 33.34},\n",
    "        4: {1: 25, 2: 25, 3: 25, 4: 25},\n",
    "        5: {1: 20, 2: 20, 3: 20, 4: 20, 5: 20},\n",
    "        6: {1: 16.67, 2: 16.67, 3: 16.66, 4: 16.67, 5: 16.67, 6: 16.66},\n",
    "        7: {1: 14.29, 2: 14.29, 3: 14.28, 4: 14.28, 5: 14.29, 6: 14.29, 7: 14.28}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display distributions\n",
    "print(\"=\"*100)\n",
    "print(\"RATING DISTRIBUTIONS\")\n",
    "print(\"=\"*100)\n",
    "for dist_name, dist_configs in DISTRIBUTIONS.items():\n",
    "    print(f\"\\n{dist_name.upper().replace('_', ' ')}:\")\n",
    "    print(\"-\" * 80)\n",
    "    for n_ratings, dist in dist_configs.items():\n",
    "        print(f\"  {n_ratings} ratings: {dist} (sum={sum(dist.values()):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8aeb16-4119-40cd-8adb-9652ebdbc288",
   "metadata": {},
   "source": [
    "## 5. Merit Matrix Generator Functions\n",
    "\n",
    "### Функции генерации матриц повышений\n",
    "\n",
    "Этот модуль автоматически создает merit matrices различных размеров, следуя \n",
    "ключевым принципам справедливости compensation management.\n",
    "\n",
    "#### Функция `generate_merit_matrix(n_cr_bins, n_ratings)`\n",
    "\n",
    "**Принципы генерации:**\n",
    "\n",
    "1. **Монотонность по рейтингу (horizontal):**\n",
    "   - Higher rating → Higher merit increase\n",
    "   - В каждом CR bin повышение растет слева направо\n",
    "\n",
    "2. **Монотонность по CR (vertical):**\n",
    "   - Higher CR → Lower merit increase\n",
    "   - В каждом рейтинге повышение уменьшается сверху вниз\n",
    "\n",
    "3. **Взвешивание факторов:**\n",
    "   - Rating weight = 70% (primary differentiator)\n",
    "   - CR weight = 30% (secondary adjustment)\n",
    "   - Обоснование: Performance важнее текущей позиции в диапазоне\n",
    "\n",
    "4. **Диапазон повышений:**\n",
    "   - Minimum = 1% (worst case: high CR, low rating)\n",
    "   - Maximum = 20% (best case: low CR, high rating)\n",
    "   - Реалистичные значения для типичных merit cycles\n",
    "\n",
    "**Алгоритм:**\n",
    "```\n",
    "For each cell (cr_idx, rating_idx):\n",
    "  1. Normalize positions to [0, 1]\n",
    "  2. cr_factor = 1 - cr_position (inverse: low CR = high merit)\n",
    "  3. rating_factor = rating_position (direct: high rating = high merit)\n",
    "  4. combined = 0.7 × rating + 0.3 × cr\n",
    "  5. merit = 1% + combined × (20% - 1%)\n",
    "```\n",
    "\n",
    "#### Функция `generate_cr_bins(n_bins)`\n",
    "\n",
    "**Создание границ CR bins:**\n",
    "\n",
    "Определяет edges для категоризации сотрудников по Compa Ratio.\n",
    "Bins становятся более детальными с увеличением n_bins, с фокусом на зоне 0.8-1.2 \n",
    "(где концентрируется большинство сотрудников).\n",
    "\n",
    "**Примеры конфигураций:**\n",
    "- **2 bins:** [0, 1.0, ∞) — простое деление: ниже/выше рынка\n",
    "- **3 bins:** [0, 0.85, 1.15, ∞) — ниже / на рынке / выше рынка\n",
    "- **5 bins:** [0, 0.80, 0.90, 1.10, 1.20, ∞) — детальная градация\n",
    "- **7 bins:** [0, 0.75, 0.85, 0.92, 1.08, 1.15, 1.25, ∞) — максимальная детализация\n",
    "\n",
    "**Логика boundaries:**\n",
    "- Более узкие интервалы около 1.0 (где большинство данных)\n",
    "- Более широкие интервалы в хвостах (меньше данных)\n",
    "- Последний bin всегда открыт справа (∞) для outliers\n",
    "\n",
    "### Модифицируемость\n",
    "**ВАЖНО:** Если требуются другие проценты повышений, измените:\n",
    "- `min_merit` и `max_merit` в `generate_merit_matrix()`\n",
    "- Weights (0.7 / 0.3) для изменения относительной важности rating vs CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f9add-0e2e-4983-aaaa-80a82806387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merit_matrix(n_cr_bins, n_ratings):\n",
    "    \"\"\"\n",
    "    Generate merit matrix following the logic:\n",
    "    - Top-left (low CR, low rating) = moderate merit\n",
    "    - Top-right (low CR, high rating) = highest merit\n",
    "    - Bottom-left (high CR, low rating) = lowest merit\n",
    "    - Bottom-right (high CR, high rating) = moderate-high merit\n",
    "    \"\"\"\n",
    "    min_merit = 1.0    # Bottom-left corner\n",
    "    max_merit = 20.0   # Top-right corner\n",
    "    \n",
    "    matrix = np.zeros((n_cr_bins, n_ratings))\n",
    "    \n",
    "    for cr_idx in range(n_cr_bins):\n",
    "        for rating_idx in range(n_ratings):\n",
    "            cr_position = cr_idx / (n_cr_bins - 1) if n_cr_bins > 1 else 0\n",
    "            rating_position = rating_idx / (n_ratings - 1) if n_ratings > 1 else 0\n",
    "            \n",
    "            # Rating is more important (70%) than CR position (30%)\n",
    "            rating_factor = rating_position\n",
    "            cr_factor = 1 - cr_position  # Inverse because lower CR = higher merit\n",
    "            combined_factor = (rating_factor * 0.7 + cr_factor * 0.3)\n",
    "            \n",
    "            # Scale to merit range\n",
    "            merit = min_merit + (max_merit - min_merit) * combined_factor\n",
    "            matrix[cr_idx, rating_idx] = round(merit, 1)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def generate_cr_bins(n_bins):\n",
    "    \"\"\"Generate CR bin edges based on number of bins.\"\"\"\n",
    "    if n_bins == 2:\n",
    "        return np.array([0.0, 1.0, np.inf], dtype=np.float32), ['[0.00, 1.00)', '[1.00, ∞)']\n",
    "    elif n_bins == 3:\n",
    "        return np.array([0.0, 0.85, 1.15, np.inf], dtype=np.float32), ['[0.00, 0.85)', '[0.85, 1.15)', '[1.15, ∞)']\n",
    "    elif n_bins == 4:\n",
    "        return np.array([0.0, 0.80, 0.95, 1.15, np.inf], dtype=np.float32), ['[0.00, 0.80)', '[0.80, 0.95)', '[0.95, 1.15)', '[1.15, ∞)']\n",
    "    elif n_bins == 5:\n",
    "        return np.array([0.0, 0.80, 0.90, 1.10, 1.20, np.inf], dtype=np.float32), ['[0.00, 0.80)', '[0.80, 0.90)', '[0.90, 1.10)', '[1.10, 1.20)', '[1.20, ∞)']\n",
    "    elif n_bins == 6:\n",
    "        return np.array([0.0, 0.75, 0.85, 0.95, 1.10, 1.25, np.inf], dtype=np.float32), ['[0.00, 0.75)', '[0.75, 0.85)', '[0.85, 0.95)', '[0.95, 1.10)', '[1.10, 1.25)', '[1.25, ∞)']\n",
    "    elif n_bins == 7:\n",
    "        return np.array([0.0, 0.75, 0.85, 0.92, 1.08, 1.15, 1.25, np.inf], dtype=np.float32), ['[0.00, 0.75)', '[0.75, 0.85)', '[0.85, 0.92)', '[0.92, 1.08)', '[1.08, 1.15)', '[1.15, 1.25)', '[1.25, ∞)']\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported number of CR bins: {n_bins}\")\n",
    "\n",
    "print(\"✅ Merit matrix generator functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9e909-5dce-4853-954b-f27d35b696c3",
   "metadata": {},
   "source": [
    "## 6. Preview Merit Matrices\n",
    "\n",
    "### Визуализация всех тестируемых матриц\n",
    "\n",
    "Эта секция отображает все 30 merit matrices (6 CR bins × 5 ratings), которые будут \n",
    "использоваться в анализе. Перед запуском полного анализа критически важно:\n",
    "\n",
    "1. **Проверить корректность значений** — соответствуют ли проценты бизнес-логике?\n",
    "2. **Верифицировать монотонность** — увеличивается ли merit слева-направо и сверху-вниз?\n",
    "3. **Оценить диапазоны** — разумны ли min/max значения для вашего контекста?\n",
    "\n",
    "### Формат отображения\n",
    "\n",
    "**Для каждой матрицы показываются:**\n",
    "- **Размер:** n CR Bins × m Ratings\n",
    "- **CR Bin labels:** Диапазоны для каждого бина (например, [0.85, 1.15))\n",
    "- **Merit Matrix (%):** Таблица процентов повышений\n",
    "- **Statistics:** Min, Max, Mean значений в матрице\n",
    "\n",
    "### Интерпретация матрицы\n",
    "\n",
    "**Ориентация:**\n",
    "- **Rows (Vertical):** CR Bins\n",
    "  - Bin 0 (top) = Lowest CR (лучшая позиция — платим ниже рынка)\n",
    "  - Bin N (bottom) = Highest CR (худшая позиция — платим выше рынка)\n",
    "- **Columns (Horizontal):** Ratings\n",
    "  - Rating 1 (left) = Lowest performance\n",
    "  - Rating N (right) = Highest performance\n",
    "\n",
    "**Углы матрицы:**\n",
    "- **Top-Right** (low CR, high rating): Максимальное повышение (~20%)\n",
    "- **Bottom-Left** (high CR, low rating): Минимальное повышение (~1%)\n",
    "- **Top-Left / Bottom-Right**: Промежуточные значения\n",
    "\n",
    "### Модификация\n",
    "Если матрицы не соответствуют вашей компенсационной политике, \n",
    "вернитесь в секцию 5 и измените параметры `generate_merit_matrix()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339973db-534c-43c2-8261-958dc1970ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_matrices():\n",
    "    \"\"\"Display all merit matrices for review.\"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"MERIT MATRICES PREVIEW\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\nFormat: Rows = CR Bins (top = low CR, bottom = high CR)\")\n",
    "    print(\"        Columns = Ratings (left = low, right = high)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    for n_cr in CR_BINS_RANGE:\n",
    "        for n_ratings in RATINGS_RANGE:\n",
    "            matrix = generate_merit_matrix(n_cr, n_ratings)\n",
    "            bin_edges, bin_labels = generate_cr_bins(n_cr)\n",
    "            \n",
    "            print(f\"\\n{'-'*100}\")\n",
    "            print(f\"MATRIX: {n_cr} CR Bins × {n_ratings} Ratings\")\n",
    "            print(f\"{'-'*100}\")\n",
    "            \n",
    "            # Show CR bins\n",
    "            print(\"\\nCR Bins:\")\n",
    "            for i, label in enumerate(bin_labels):\n",
    "                print(f\"  Bin {i}: {label}\")\n",
    "            \n",
    "            # Show matrix\n",
    "            print(\"\\nMerit Matrix (%):\")\n",
    "            df = pd.DataFrame(\n",
    "                matrix,\n",
    "                index=[f\"CR_Bin_{i}\" for i in range(n_cr)],\n",
    "                columns=[f\"Rating_{i+1}\" for i in range(n_ratings)]\n",
    "            )\n",
    "            print(df.to_string())\n",
    "            \n",
    "            print(f\"\\nStats: Min={matrix.min():.1f}%, Max={matrix.max():.1f}%, Mean={matrix.mean():.1f}%\")\n",
    "\n",
    "# Display all matrices\n",
    "display_all_matrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0bfc06-9010-4066-883a-161677cb528b",
   "metadata": {},
   "source": [
    "## 7. Numba-Optimized Simulation Function\n",
    "\n",
    "### Критичная функция производительности\n",
    "\n",
    "Это **ядро Monte Carlo симуляции** — самая вычислительно-интенсивная часть анализа.\n",
    "Оптимизация здесь критична, так как функция вызывается миллионы раз:\n",
    "- 120 конфигураций × ~300 групп × 50,000 итераций = **~1.8 миллиарда вызовов**\n",
    "\n",
    "### Оптимизации производительности\n",
    "\n",
    "#### 1. Numba JIT компиляция\n",
    "- `@jit(nopython=True)`: Компилирует Python в машинный код\n",
    "- **Ускорение:** ~100x по сравнению с чистым Python\n",
    "- `nopython=True`: Строгий режим (только NumPy операции, без Python objects)\n",
    "\n",
    "#### 2. Параллелизация\n",
    "- `parallel=True`: Автоматическая параллелизация на доступные CPU cores\n",
    "- `prange()`: Parallel range — каждая итерация выполняется независимо\n",
    "- **Ускорение:** Линейное с количеством cores (4 cores → ~4x speedup)\n",
    "\n",
    "#### 3. Vectorization\n",
    "- Все случайные числа pre-generated вне цикла\n",
    "- `all_sampled_probs`: [n_simulations × n_ratings] — заранее\n",
    "- `all_random_values`: [n_simulations × n_employees] — заранее\n",
    "- Устраняет overhead генерации RNG внутри горячего цикла\n",
    "\n",
    "#### 4. Быстрое присвоение рейтингов\n",
    "- Используется inverse transform sampling через cumulative probabilities\n",
    "- O(R) сложность вместо O(R log R) для каждого сотрудника\n",
    "- R = количество рейтингов (3-7)\n",
    "\n",
    "### Алгоритм симуляции\n",
    "\n",
    "```\n",
    "Для каждой из 50,000 симуляций (параллельно):\n",
    "  1. Взять pre-sampled распределение рейтингов (Dirichlet perturbation)\n",
    "  2. Построить cumulative probabilities для fast sampling\n",
    "  3. Для каждого сотрудника:\n",
    "     a. Присвоить рейтинг (inverse transform)\n",
    "     b. Найти merit% в матрице [cr_bin, rating]\n",
    "     c. Рассчитать merit amount = base_salary × merit%\n",
    "     d. Накопить в total\n",
    "  4. Рассчитать average merit% = total / total_base_salary\n",
    "  5. Проверить: budget_lower ≤ average merit% ≤ budget_upper\n",
    "```\n",
    "\n",
    "### Производительность\n",
    "- **Без оптимизаций:** ~300-500 секунд на группу из 100 сотрудников\n",
    "- **С оптимизациями:** ~2-3 секунды на группу из 100 сотрудников\n",
    "- **Speedup:** ~150x общее ускорение\n",
    "\n",
    "### Технические детали\n",
    "- `fastmath=True`: Разрешает compiler оптимизировать floating-point арифметику\n",
    "- `cache=True`: Кэширует скомпилированную версию между запусками\n",
    "- Все массивы используют `np.float32` для экономии памяти (важно при 50K итераций)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77754da2-a4c2-41b8-81fa-0dd67d6e6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True, fastmath=True, cache=True)\n",
    "def _run_simulations_weighted(n_simulations, n_employees, base_salaries, cr_bins,\n",
    "                              total_base_salary, all_sampled_probs, all_random_values,\n",
    "                              merit_matrix, budget_lower_bound, budget_upper_bound,\n",
    "                              average_merit_pcts, total_merit_amounts, within_budget):\n",
    "    \"\"\"Numba-optimized Monte Carlo simulation loop with parallelization.\"\"\"\n",
    "    n_ratings = merit_matrix.shape[1]\n",
    "    \n",
    "    for sim_idx in prange(n_simulations):\n",
    "        sampled_probs = all_sampled_probs[sim_idx]\n",
    "        \n",
    "        # Build cumulative probabilities\n",
    "        cum_probs = np.empty(n_ratings, dtype=np.float32)\n",
    "        cum_probs[0] = sampled_probs[0]\n",
    "        for i in range(1, n_ratings):\n",
    "            cum_probs[i] = cum_probs[i-1] + sampled_probs[i]\n",
    "        \n",
    "        total_merit_amount = 0.0\n",
    "        \n",
    "        for emp_idx in range(n_employees):\n",
    "            rand_val = all_random_values[sim_idx, emp_idx]\n",
    "            \n",
    "            # Assign rating\n",
    "            rating_idx = 0\n",
    "            for i in range(n_ratings):\n",
    "                if rand_val <= cum_probs[i]:\n",
    "                    rating_idx = i\n",
    "                    break\n",
    "            \n",
    "            # Calculate merit\n",
    "            cr_bin = cr_bins[emp_idx]\n",
    "            merit_pct = merit_matrix[cr_bin, rating_idx]\n",
    "            merit_amount = base_salaries[emp_idx] * (merit_pct / 100.0)\n",
    "            total_merit_amount += merit_amount\n",
    "        \n",
    "        avg_merit_pct = (total_merit_amount / total_base_salary) * 100.0\n",
    "        \n",
    "        average_merit_pcts[sim_idx] = avg_merit_pct\n",
    "        total_merit_amounts[sim_idx] = total_merit_amount\n",
    "        within_budget[sim_idx] = (budget_lower_bound <= avg_merit_pct <= budget_upper_bound)\n",
    "\n",
    "print(\"Numba simulation function compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e75c0d-f897-48da-97d1-e32f7df835e6",
   "metadata": {},
   "source": [
    "## 8. FlexibleMeritAnalyzer Class\n",
    "\n",
    "### Центральный класс для анализа merit matrices\n",
    "\n",
    "Этот класс инкапсулирует всю логику анализа, работая с матрицами любого размера.\n",
    "Обеспечивает модульность и переиспользуемость кода для различных конфигураций.\n",
    "\n",
    "### Архитектура класса\n",
    "\n",
    "#### Инициализация `__init__()`\n",
    "**Входы:**\n",
    "- `merit_matrix`: NumPy array с процентами повышений\n",
    "- `cr_bin_edges`: Границы CR bins (например, [0, 0.85, 1.15, ∞])\n",
    "- `cr_bin_labels`: Текстовые метки для bins\n",
    "\n",
    "**Сохраняет:**\n",
    "- Конфигурацию матрицы (n_cr_bins, n_ratings)\n",
    "- Все параметры для последующих вычислений\n",
    "\n",
    "#### Ключевые методы\n",
    "\n",
    "**1. `calculate_cr_distribution()`**\n",
    "- Распределяет сотрудников по CR bins\n",
    "- Вычисляет два типа распределений:\n",
    "  - By count: процент сотрудников в каждом бине\n",
    "  - By base pay: процент фонда оплаты труда в каждом бине (weighted)\n",
    "- **Используется weighted distribution** для расчета бюджета (более точно)\n",
    "\n",
    "**2. `calculate_heuristic_budget()`**\n",
    "- Реализация **метода агрегированных распределений**\n",
    "- Формула: `Budget = Σᵢ Σⱼ P(CR_i) × P(Rating_j) × Merit(i,j)`\n",
    "- Предполагает независимость CR и рейтингов\n",
    "- **Это метод, точность которого мы валидируем**\n",
    "\n",
    "**3. `run_monte_carlo_for_group()`**\n",
    "- Запускает Monte Carlo для одной группы (Company × Function)\n",
    "- **Workflow:**\n",
    "  1. Подготовка данных (assign CR bins, normalize probabilities)\n",
    "  2. Pre-generation случайных чисел (Dirichlet samples + uniform RV)\n",
    "  3. Вызов Numba-оптимизированной функции симуляции\n",
    "  4. Вычисление метрик (success rate, percentiles, statistics)\n",
    "- **Возвращает:** Dictionary с полными результатами (mean, median, std, percentiles, etc.)\n",
    "\n",
    "**4. `process_dataframe()`**\n",
    "- Обрабатывает весь датасет (все Company × Function группы)\n",
    "- **Pipeline:**\n",
    "  1. Валидация входных данных (columns, distribution normalization)\n",
    "  2. Группировка по Company × Function\n",
    "  3. Фильтрация малых групп (< min_sample_size)\n",
    "  4. Для каждой группы:\n",
    "     - Расчет CR distribution\n",
    "     - Расчет heuristic budget\n",
    "     - Запуск Monte Carlo\n",
    "     - Сохранение результатов\n",
    "  5. Формирование результирующего DataFrame\n",
    "- **Возвращает:** Полная таблица результатов для всех групп\n",
    "\n",
    "### Валидация и обработка ошибок\n",
    "- Проверка наличия required columns (Company, Function, BP, CR)\n",
    "- Валидация rating_distribution (keys = 1 to n_ratings, sum = 100%)\n",
    "- Автоматический skip групп меньше min_sample_size\n",
    "- Подробный verbose output для мониторинга прогресса\n",
    "\n",
    "### Производительность\n",
    "- Оптимизирован через NumPy vectorization где возможно\n",
    "- Использует Numba для критичного simulation loop\n",
    "- Прогресс-репорты каждые 5 групп для длительных runs\n",
    "- Типичная скорость: ~200-300 групп в 10-15 минут (50K симуляций)\n",
    "\n",
    "### Модульность\n",
    "Класс полностью независим от:\n",
    "- Размера матрицы (работает с любыми n_cr_bins × n_ratings)\n",
    "- Типа распределения (принимает любое валидное распределение)\n",
    "- Параметров симуляции (configurable через аргументы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845b9ec-c225-450f-b907-6732edb374dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleMeritAnalyzer:\n",
    "    \"\"\"Merit analyzer that works with any matrix configuration.\"\"\"\n",
    "    \n",
    "    def __init__(self, merit_matrix, cr_bin_edges, cr_bin_labels):\n",
    "        self.merit_matrix = np.array(merit_matrix, dtype=np.float32)\n",
    "        self.cr_bin_edges = np.array(cr_bin_edges, dtype=np.float32)\n",
    "        self.cr_bin_labels = cr_bin_labels\n",
    "        self.n_cr_bins = len(cr_bin_labels)\n",
    "        self.n_ratings = merit_matrix.shape[1]\n",
    "    \n",
    "    def calculate_cr_distribution(self, cr_values, base_pays):\n",
    "        \"\"\"Calculate CR bin distribution weighted by base pay.\"\"\"\n",
    "        cr_bins = np.searchsorted(self.cr_bin_edges[1:-1], cr_values, side='right')\n",
    "        \n",
    "        cr_bin_counts = np.bincount(cr_bins, minlength=self.n_cr_bins)\n",
    "        cr_bin_percentages = (cr_bin_counts / len(cr_bins)) * 100\n",
    "        \n",
    "        total_bp = np.sum(base_pays)\n",
    "        cr_bin_bp = np.array([np.sum(base_pays[cr_bins == i]) for i in range(self.n_cr_bins)])\n",
    "        cr_bin_bp_pct = (cr_bin_bp / total_bp) * 100\n",
    "        \n",
    "        return cr_bin_counts, cr_bin_percentages, cr_bin_bp, cr_bin_bp_pct\n",
    "    \n",
    "    def calculate_heuristic_budget(self, cr_distribution_pct, rating_distribution):\n",
    "        \"\"\"Calculate heuristic budget.\"\"\"\n",
    "        cr_dist = np.array(cr_distribution_pct, dtype=np.float32) / 100\n",
    "        rating_dist = np.array([rating_distribution[i] for i in range(1, self.n_ratings + 1)], dtype=np.float32) / 100\n",
    "        \n",
    "        total_budget = 0.0\n",
    "        for i in range(self.n_cr_bins):\n",
    "            for j in range(self.n_ratings):\n",
    "                cell_probability = cr_dist[i] * rating_dist[j]\n",
    "                cell_increase = self.merit_matrix[i, j]\n",
    "                total_budget += cell_probability * cell_increase\n",
    "        \n",
    "        return total_budget\n",
    "    \n",
    "    def run_monte_carlo_for_group(self, cr_values, base_pays, target_merit_pool_pct,\n",
    "                                   rating_distribution, concentration,\n",
    "                                   n_simulations=10000, budget_tolerance_lower=0.05,\n",
    "                                   budget_tolerance_upper=0.0):\n",
    "        \"\"\"Run Monte Carlo simulation for a group.\"\"\"\n",
    "        n_employees = len(cr_values)\n",
    "        total_base_salary = np.sum(base_pays)\n",
    "        \n",
    "        cr_bins = np.searchsorted(self.cr_bin_edges[1:-1], cr_values, side='right').astype(np.int32)\n",
    "        \n",
    "        target_probs = np.array([rating_distribution[i] for i in range(1, self.n_ratings + 1)], dtype=np.float32)\n",
    "        \n",
    "        budget_lower_bound = target_merit_pool_pct * (1 - budget_tolerance_lower)\n",
    "        budget_upper_bound = target_merit_pool_pct * (1 + budget_tolerance_upper)\n",
    "        \n",
    "        average_merit_pcts = np.zeros(n_simulations, dtype=np.float32)\n",
    "        total_merit_amounts = np.zeros(n_simulations, dtype=np.float32)\n",
    "        within_budget = np.zeros(n_simulations, dtype=np.bool_)\n",
    "        \n",
    "        alpha = concentration * target_probs\n",
    "        all_sampled_probs = dirichlet.rvs(alpha, size=n_simulations).astype(np.float32)\n",
    "        all_random_values = np.random.random((n_simulations, n_employees)).astype(np.float32)\n",
    "        \n",
    "        _run_simulations_weighted(\n",
    "            n_simulations=n_simulations,\n",
    "            n_employees=n_employees,\n",
    "            base_salaries=base_pays,\n",
    "            cr_bins=cr_bins,\n",
    "            total_base_salary=total_base_salary,\n",
    "            all_sampled_probs=all_sampled_probs,\n",
    "            all_random_values=all_random_values,\n",
    "            merit_matrix=self.merit_matrix,\n",
    "            budget_lower_bound=budget_lower_bound,\n",
    "            budget_upper_bound=budget_upper_bound,\n",
    "            average_merit_pcts=average_merit_pcts,\n",
    "            total_merit_amounts=total_merit_amounts,\n",
    "            within_budget=within_budget\n",
    "        )\n",
    "        \n",
    "        success_rate = np.mean(within_budget) * 100\n",
    "        \n",
    "        return {\n",
    "            'n_employees': n_employees,\n",
    "            'total_base_salary': float(total_base_salary),\n",
    "            'target_budget': target_merit_pool_pct,\n",
    "            'budget_lower': budget_lower_bound,\n",
    "            'budget_upper': budget_upper_bound,\n",
    "            'mean': np.mean(average_merit_pcts),\n",
    "            'median': np.median(average_merit_pcts),\n",
    "            'std': np.std(average_merit_pcts),\n",
    "            'p10': np.percentile(average_merit_pcts, 10),\n",
    "            'p25': np.percentile(average_merit_pcts, 25),\n",
    "            'p50': np.percentile(average_merit_pcts, 50),\n",
    "            'p75': np.percentile(average_merit_pcts, 75),\n",
    "            'p90': np.percentile(average_merit_pcts, 90),\n",
    "            'min': np.min(average_merit_pcts),\n",
    "            'max': np.max(average_merit_pcts),\n",
    "            'p05': np.percentile(average_merit_pcts, 5),\n",
    "            'p95': np.percentile(average_merit_pcts, 95),\n",
    "            'iqr': np.percentile(average_merit_pcts, 75) - np.percentile(average_merit_pcts, 25),\n",
    "            'mean_merit_amount': np.mean(total_merit_amounts),\n",
    "            'median_merit_amount': np.median(total_merit_amounts),\n",
    "            'std_merit_amount': np.std(total_merit_amounts),\n",
    "            'success_rate': success_rate,\n",
    "            'n_simulations': n_simulations,\n",
    "            'n_within_budget': int(np.sum(within_budget)),\n",
    "            'n_outside_budget': int(n_simulations - np.sum(within_budget))\n",
    "        }\n",
    "    \n",
    "    def process_dataframe(self, df, rating_distribution, concentration=250,\n",
    "                         n_simulations=10000, min_sample_size=25,\n",
    "                         budget_tolerance_lower=0.05, budget_tolerance_upper=0.0,\n",
    "                         verbose=True):\n",
    "        \"\"\"Process dataframe for all Company+Function groups.\"\"\"\n",
    "        required_cols = ['Company', 'Function', 'BP', 'CR']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        if not isinstance(rating_distribution, dict) or set(rating_distribution.keys()) != set(range(1, self.n_ratings + 1)):\n",
    "            raise ValueError(f\"rating_distribution must be a dict with keys 1-{self.n_ratings}\")\n",
    "        if abs(sum(rating_distribution.values()) - 100) > 0.01:\n",
    "            raise ValueError(f\"rating_distribution must sum to 100\")\n",
    "        \n",
    "        results = []\n",
    "        total_groups = len(df.groupby(['Company', 'Function']))\n",
    "        processed_groups = 0\n",
    "        skipped_groups = 0\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Processing {total_groups} Company+Function combinations...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for (company, function), group_df in df.groupby(['Company', 'Function']):\n",
    "            n_employees = len(group_df)\n",
    "            \n",
    "            if n_employees < min_sample_size:\n",
    "                skipped_groups += 1\n",
    "                continue\n",
    "            \n",
    "            cr_values = group_df['CR'].values.astype(np.float32)\n",
    "            base_pays = group_df['BP'].values.astype(np.float32)\n",
    "            \n",
    "            cr_bin_counts, cr_bin_pct_count, cr_bin_bp, cr_bin_pct_bp = \\\n",
    "                self.calculate_cr_distribution(cr_values, base_pays)\n",
    "            \n",
    "            heuristic_budget = self.calculate_heuristic_budget(cr_bin_pct_bp, rating_distribution)\n",
    "            \n",
    "            mc_results = self.run_monte_carlo_for_group(\n",
    "                cr_values=cr_values,\n",
    "                base_pays=base_pays,\n",
    "                target_merit_pool_pct=heuristic_budget,\n",
    "                rating_distribution=rating_distribution,\n",
    "                concentration=concentration,\n",
    "                n_simulations=n_simulations,\n",
    "                budget_tolerance_lower=budget_tolerance_lower,\n",
    "                budget_tolerance_upper=budget_tolerance_upper\n",
    "            )\n",
    "            \n",
    "            result_row = {\n",
    "                'company': company,\n",
    "                'function': function,\n",
    "                'n_employees': n_employees,\n",
    "                'total_base_salary': mc_results['total_base_salary'],\n",
    "                'heuristic_budget_pct': heuristic_budget,\n",
    "                'target_budget_pct': mc_results['target_budget'],\n",
    "                'budget_lower_pct': mc_results['budget_lower'],\n",
    "                'budget_upper_pct': mc_results['budget_upper'],\n",
    "                'mc_mean_pct': mc_results['mean'],\n",
    "                'mc_median_pct': mc_results['median'],\n",
    "                'mc_std_pct': mc_results['std'],\n",
    "                'mc_p05_pct': mc_results['p05'],\n",
    "                'mc_p10_pct': mc_results['p10'],\n",
    "                'mc_p25_pct': mc_results['p25'],\n",
    "                'mc_p50_pct': mc_results['p50'],\n",
    "                'mc_p75_pct': mc_results['p75'],\n",
    "                'mc_p90_pct': mc_results['p90'],\n",
    "                'mc_p95_pct': mc_results['p95'],\n",
    "                'mc_min_pct': mc_results['min'],\n",
    "                'mc_max_pct': mc_results['max'],\n",
    "                'mc_iqr_pct': mc_results['iqr'],\n",
    "                'mc_mean_amount': mc_results['mean_merit_amount'],\n",
    "                'mc_median_amount': mc_results['median_merit_amount'],\n",
    "                'mc_std_amount': mc_results['std_merit_amount'],\n",
    "                'success_rate_pct': mc_results['success_rate'],\n",
    "                'n_within_budget': mc_results['n_within_budget'],\n",
    "                'n_outside_budget': mc_results['n_outside_budget'],\n",
    "                'n_simulations': mc_results['n_simulations'],\n",
    "            }\n",
    "            \n",
    "            for i in range(self.n_cr_bins):\n",
    "                result_row[f'cr_bin_{i}_count'] = int(cr_bin_counts[i])\n",
    "                result_row[f'cr_bin_{i}_pct_count'] = cr_bin_pct_count[i]\n",
    "                result_row[f'cr_bin_{i}_base_salary'] = float(cr_bin_bp[i])\n",
    "                result_row[f'cr_bin_{i}_pct_bp'] = cr_bin_pct_bp[i]\n",
    "            \n",
    "            results.append(result_row)\n",
    "            processed_groups += 1\n",
    "        \n",
    "        if verbose:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"  ✓ Processed: {processed_groups} | Skipped: {skipped_groups} | Time: {elapsed_time:.1f}s\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        if len(results_df) > 0:\n",
    "            results_df = results_df.sort_values(['company', 'function']).reset_index(drop=True)\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "print(\"FlexibleMeritAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0ea31-99a2-410a-b9d5-02ed2dbf1448",
   "metadata": {},
   "source": [
    "## 9. Load Data\n",
    "\n",
    "### Загрузка подготовленных данных\n",
    "\n",
    "Загружаем датасет Moscow.parquet.gzip, созданный в секции 2.\n",
    "Код поддерживает множественные форматы для гибкости:\n",
    "\n",
    "**Поддерживаемые форматы:**\n",
    "- `.parquet` / `.parquet.gzip` — рекомендуется (быстро, компактно)\n",
    "- `.xlsx` / `.xls` — Excel файлы\n",
    "- `.csv` — текстовые файлы\n",
    "\n",
    "### Валидация данных\n",
    "\n",
    "После загрузки проверяется:\n",
    "- Количество строк и столбцов\n",
    "- Количество сотрудников\n",
    "- Общий фонд базовых зарплат\n",
    "- Уникальные компании и функции\n",
    "- Количество групп Company × Function (единица анализа)\n",
    "- Статистика Compa Ratio (mean, median, range)\n",
    "\n",
    "### Критичность качества данных\n",
    "\n",
    "**Required columns:**\n",
    "- `Company`: Идентификатор компании (для группировки)\n",
    "- `Function`: Функциональная линия (для группировки)\n",
    "- `BP`: Базовая зарплата (для расчета бюджета)\n",
    "- `CR`: Compa Ratio (для классификации по bins)\n",
    "\n",
    "**Проверка здоровья данных:**\n",
    "- CR должен быть в разумном диапазоне (типично 0.6-1.6)\n",
    "- BP должен быть положительным\n",
    "- Нет missing values в критичных колонках\n",
    "\n",
    "### Ожидаемый результат\n",
    "После успешной загрузки должны увидеть:\n",
    "- Loaded message с именем файла\n",
    "- Shape информацию (rows × columns)\n",
    "- Статистику по компаниям и функциям\n",
    "- CR статистику для понимания распределения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb80d32-f8fa-42aa-aacf-091c4f4acdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "try:\n",
    "    if INPUT_FILE.endswith('.xlsx') or INPUT_FILE.endswith('.xls'):\n",
    "        df = pd.read_excel(INPUT_FILE)\n",
    "    elif INPUT_FILE.endswith('.csv'):\n",
    "        df = pd.read_csv(INPUT_FILE)\n",
    "    elif INPUT_FILE.endswith('.parquet.gzip') or INPUT_FILE.endswith('.parquet'):\n",
    "        df = pd.read_parquet(INPUT_FILE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {INPUT_FILE}\")\n",
    "    \n",
    "    print(f\"✅ Loaded: {INPUT_FILE}\")\n",
    "    print(f\"   Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    print(f\"   Total employees: {len(df):,}\")\n",
    "    print(f\"   Total base salary: ${df['BP'].sum():,.2f}\")\n",
    "    print(f\"   Companies: {df['Company'].nunique()}\")\n",
    "    print(f\"   Functions: {df['Function'].nunique()}\")\n",
    "    print(f\"   Company+Function combinations: {df.groupby(['Company', 'Function']).ngroups}\")\n",
    "    \n",
    "    print(f\"\\nCR Statistics:\")\n",
    "    print(f\"   Mean: {df['CR'].mean():.3f}\")\n",
    "    print(f\"   Median: {df['CR'].median():.3f}\")\n",
    "    print(f\"   Min: {df['CR'].min():.3f}, Max: {df['CR'].max():.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2404e-2679-46a5-b9d1-3879bbdbe9f3",
   "metadata": {},
   "source": [
    "## 10. Run Multi-Configuration Analysis\n",
    "\n",
    "### Главный цикл исследования\n",
    "\n",
    "**ВНИМАНИЕ: Длительная операция!**  \n",
    "Для 120 конфигураций с 50,000 симуляций каждая ожидайте **2-4 часа** выполнения на стандартном laptop.\n",
    "\n",
    "### Структура цикла\n",
    "\n",
    "**Тройной вложенный цикл:**\n",
    "```\n",
    "For each n_cr_bins in [2, 3, 4, 5, 6, 7]:                    # 6 вариантов\n",
    "  For each n_ratings in [3, 4, 5, 6, 7]:                    # 5 вариантов\n",
    "    For each distribution in [normal, skewed_high, ...]:    # 4 варианта\n",
    "      → Создать конфигурацию\n",
    "      → Запустить анализ для всех групп\n",
    "      → Сохранить результаты\n",
    "```\n",
    "**Итого:** 6 × 5 × 4 = **120 конфигураций**\n",
    "\n",
    "### Workflow для каждой конфигурации\n",
    "\n",
    "**1. Подготовка**\n",
    "- Генерация merit matrix нужного размера\n",
    "- Генерация CR bin edges\n",
    "- Получение целевого rating distribution\n",
    "- Создание уникального имени конфигурации (например, `CR5_R5_normal`)\n",
    "\n",
    "**2. Инициализация**\n",
    "- Создание экземпляра FlexibleMeritAnalyzer\n",
    "- Конфигурирование параметров симуляции\n",
    "\n",
    "**3. Выполнение анализа**\n",
    "- Вызов `analyzer.process_dataframe()`:\n",
    "  - Обработка всех Company × Function групп\n",
    "  - 50,000 Monte Carlo итераций на группу\n",
    "  - Фильтрация групп < MIN_SAMPLE_SIZE\n",
    "- Измерение времени выполнения\n",
    "\n",
    "**4. Сохранение результатов**\n",
    "- **Формат:** Parquet (быстрый, компактный)\n",
    "- **Naming:** `merit_analysis_{config_name}_{timestamp}.parquet`\n",
    "- **Metadata:** Добавляются столбцы config_name, n_cr_bins, n_ratings, distribution_type\n",
    "- **Location:** `merit_analysis_results/` директория\n",
    "\n",
    "**5. Сводная статистика**\n",
    "Для каждой конфигурации сохраняется:\n",
    "- Количество обработанных групп\n",
    "- Общее количество сотрудников\n",
    "- Средний heuristic budget\n",
    "- Средний Monte Carlo budget\n",
    "- **Средний success rate** (ключевая метрика!)\n",
    "- Время обработки\n",
    "\n",
    "### Мониторинг прогресса\n",
    "\n",
    "**Output в консоли:**\n",
    "```\n",
    "[1/120] CR2_R3_normal\n",
    "────────────────────────────────────────────────────────────────\n",
    "  Processing 287 Company+Function combinations...\n",
    "  ✓ Processed: 243 | Skipped: 44 | Time: 124.3s\n",
    "    Saved: merit_analysis_results/merit_analysis_CR2_R3_normal_20250518_143022.parquet\n",
    "     Mean budget: 10.23%\n",
    "     Mean success rate: 52.3%\n",
    "     Time: 124.3s\n",
    "```\n",
    "\n",
    "### Обработка пропущенных групп\n",
    "Группы пропускаются если `n_employees < MIN_SAMPLE_SIZE`:\n",
    "- Причина: Высокая вариативность в малых выборках\n",
    "- Типично: ~10-20% групп пропускаются (очень малые функции)\n",
    "- Не критично: Фокус на статистически значимых группах\n",
    "\n",
    "### Итоговая статистика\n",
    "После завершения всех 120 конфигураций:\n",
    "- Общее время выполнения\n",
    "- Количество обработанных конфигураций\n",
    "- Среднее время на конфигурацию\n",
    "- Путь к сохраненным файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c56988-6310-4b2f-aca5-dd435d6bb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RUNNING MULTI-CONFIGURATION ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "overall_start = time.time()\n",
    "config_counter = 0\n",
    "all_summaries = []\n",
    "\n",
    "for n_cr in CR_BINS_RANGE:\n",
    "    for n_ratings in RATINGS_RANGE:\n",
    "        for dist_name, dist_configs in DISTRIBUTIONS.items():\n",
    "            config_counter += 1\n",
    "            \n",
    "            # Get configuration\n",
    "            merit_matrix = generate_merit_matrix(n_cr, n_ratings)\n",
    "            cr_bin_edges, cr_bin_labels = generate_cr_bins(n_cr)\n",
    "            rating_distribution = dist_configs[n_ratings]\n",
    "            \n",
    "            config_name = f\"CR{n_cr}_R{n_ratings}_{dist_name}\"\n",
    "            \n",
    "            print(f\"\\n[{config_counter}/{total_configs}] {config_name}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            # Initialize analyzer\n",
    "            analyzer = FlexibleMeritAnalyzer(merit_matrix, cr_bin_edges, cr_bin_labels)\n",
    "            \n",
    "            # Run analysis\n",
    "            config_start = time.time()\n",
    "            \n",
    "            results_df = analyzer.process_dataframe(\n",
    "                df=df,\n",
    "                rating_distribution=rating_distribution,\n",
    "                concentration=CONCENTRATION,\n",
    "                n_simulations=N_SIMULATIONS,\n",
    "                min_sample_size=MIN_SAMPLE_SIZE,\n",
    "                budget_tolerance_lower=BUDGET_TOLERANCE_LOWER,\n",
    "                budget_tolerance_upper=BUDGET_TOLERANCE_UPPER,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            config_time = time.time() - config_start\n",
    "            \n",
    "            if len(results_df) > 0:\n",
    "                # Add metadata\n",
    "                results_df['config_name'] = config_name\n",
    "                results_df['n_cr_bins'] = n_cr\n",
    "                results_df['n_ratings'] = n_ratings\n",
    "                results_df['distribution_type'] = dist_name\n",
    "                \n",
    "                # Save results\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_file = f\"{OUTPUT_DIR}/merit_analysis_{config_name}_{timestamp}.parquet\"\n",
    "                results_df.to_parquet(output_file, index=False, compression='snappy')\n",
    "                \n",
    "                # Summary statistics\n",
    "                summary = {\n",
    "                    'config_name': config_name,\n",
    "                    'n_cr_bins': n_cr,\n",
    "                    'n_ratings': n_ratings,\n",
    "                    'distribution_type': dist_name,\n",
    "                    'n_groups': len(results_df),\n",
    "                    'total_employees': results_df['n_employees'].sum(),\n",
    "                    'total_base_salary': results_df['total_base_salary'].sum(),\n",
    "                    'mean_heuristic_budget': results_df['heuristic_budget_pct'].mean(),\n",
    "                    'mean_mc_budget': results_df['mc_mean_pct'].mean(),\n",
    "                    'mean_success_rate': results_df['success_rate_pct'].mean(),\n",
    "                    'processing_time_sec': config_time,\n",
    "                    'output_file': output_file\n",
    "                }\n",
    "                all_summaries.append(summary)\n",
    "                \n",
    "                print(f\"  ✅ Saved: {output_file}\")\n",
    "                print(f\"     Mean budget: {summary['mean_mc_budget']:.2f}%\")\n",
    "                print(f\"     Mean success rate: {summary['mean_success_rate']:.1f}%\")\n",
    "                print(f\"     Time: {config_time:.1f}s\")\n",
    "            else:\n",
    "                print(f\"     No groups met minimum sample size\")\n",
    "\n",
    "overall_time = time.time() - overall_start\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Total time: {overall_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3807e5d-fdf8-474d-9a4c-0b39ad7b90dd",
   "metadata": {},
   "source": [
    "## 11. Save and Display Summary\n",
    "\n",
    "### Агрегация результатов всех конфигураций\n",
    "\n",
    "После завершения анализа 120 конфигураций создается сводная таблица \n",
    "для сравнения performance различных настроек.\n",
    "\n",
    "### Сохранение summary\n",
    "\n",
    "**Файл:** `analysis_summary_{timestamp}.csv`\n",
    "\n",
    "**Содержит для каждой конфигурации:**\n",
    "- `config_name`: Уникальный идентификатор (например, CR5_R5_normal)\n",
    "- `n_cr_bins`, `n_ratings`: Размеры матрицы\n",
    "- `distribution_type`: Тип распределения рейтингов\n",
    "- `n_groups`: Количество обработанных групп\n",
    "- `mean_mc_budget`: Средний бюджет по Monte Carlo\n",
    "- `mean_success_rate`: **Ключевая метрика** — средний success rate\n",
    "- `processing_time_sec`: Время выполнения конфигурации\n",
    "\n",
    "### Интерактивное отображение\n",
    "\n",
    "**Jupyter display():** Показывает отфильтрованную версию summary для быстрого overview:\n",
    "- Только основные столбцы для читаемости\n",
    "- Отсортировано по config_name для группировки похожих конфигураций\n",
    "\n",
    "### Использование summary\n",
    "\n",
    "**Этот файл критичен для последующего анализа:**\n",
    "1. Сравнение success rates между конфигурациями\n",
    "2. Выявление паттернов: какие параметры влияют на точность?\n",
    "3. Идентификация оптимальных конфигураций\n",
    "4. Анализ времени выполнения (performance profiling)\n",
    "\n",
    "### Структура для следующих шагов\n",
    "\n",
    "Summary DataFrame сохраняется в переменной `results_summary` для:\n",
    "- Секции 12 (Visualization) — создание heatmaps и графиков\n",
    "- Дальнейшего статистического анализа\n",
    "- Экспорта в презентации и отчеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057e940-486e-41eb-8265-b6c58e77662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_summaries:\n",
    "    summary_df = pd.DataFrame(all_summaries)\n",
    "    summary_file = f\"{OUTPUT_DIR}/analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    print(f\"✅ Summary saved: {summary_file}\")\n",
    "    print(f\"\\nTotal configurations processed: {len(all_summaries)}\")\n",
    "    print(f\"Average time per configuration: {overall_time/len(all_summaries):.1f}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SUMMARY RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    display(summary_df[['config_name', 'n_groups', 'mean_mc_budget', 'mean_success_rate', 'processing_time_sec']])\n",
    "    \n",
    "    # Store summary_df for visualization\n",
    "    results_summary = summary_df\n",
    "else:\n",
    "    print(\"No results generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022da1d3-534d-4ddf-8e4f-0abe96b7d3a0",
   "metadata": {},
   "source": [
    "## 12. Visualization of Results\n",
    "\n",
    "### Визуальный анализ результатов\n",
    "\n",
    "Создание 4 ключевых визуализаций для понимания паттернов в данных.\n",
    "Все графики сохраняются в высоком разрешении (300 DPI) для использования \n",
    "в презентациях и публикациях.\n",
    "\n",
    "### График 1: Mean Monte Carlo Budget by Matrix Size (Heatmap)\n",
    "\n",
    "**Что показывает:** Как средний бюджет зависит от размера матрицы\n",
    "- **X-axis:** Количество рейтингов (3-7)\n",
    "- **Y-axis:** Количество CR bins (2-7)\n",
    "- **Color:** Средний бюджет (%) — агрегация по всем типам распределений\n",
    "\n",
    "**Интерпретация:**\n",
    "- Более теплые цвета (green) = выше бюджет\n",
    "- Более холодные цвета (red) = ниже бюджет\n",
    "- Ожидание: относительно стабильные значения (если размер матрицы не влияет)\n",
    "\n",
    "### График 2: Mean Success Rate by Matrix Size (Heatmap)\n",
    "\n",
    "**Что показывает:** Как точность метода зависит от размера матрицы\n",
    "- **X-axis:** Количество рейтингов\n",
    "- **Y-axis:** Количество CR bins\n",
    "- **Color:** Средний success rate (%) — ключевая метрика исследования\n",
    "\n",
    "**Интерпретация:**\n",
    "- Более теплые цвета (green) = выше точность\n",
    "- Более холодные цвета (red) = ниже точность\n",
    "- **Ключевой вопрос:** Есть ли systematic pattern или значения стабильны?\n",
    "\n",
    "### График 3: Mean Budget by Distribution Type (Bar Chart)\n",
    "\n",
    "**Что показывает:** Как тип распределения рейтингов влияет на средний бюджет\n",
    "- **Bars:** 4 типа распределений (normal, skewed_high, skewed_low, uniform)\n",
    "- **Sorted:** От наименьшего к наибольшему для наглядности\n",
    "\n",
    "**Интерпретация:**\n",
    "- Skewed high → обычно выше бюджет (больше высоких рейтингов)\n",
    "- Skewed low → обычно ниже бюджет (больше низких рейтингов)\n",
    "- Разброс показывает sensitivity к типу распределения\n",
    "\n",
    "### График 4: Mean Success Rate by Distribution Type (Bar Chart)\n",
    "\n",
    "**Что показывает:** Как тип распределения влияет на точность метода\n",
    "- **Bars:** 4 типа распределений\n",
    "- **Sorted:** От наименьшего к наибольшему success rate\n",
    "\n",
    "**Интерпретация:**\n",
    "- Если разброс **малый** (2-5%) → метод robust к типу распределения\n",
    "- Если разброс **большой** (>10%) → тип распределения — значимый фактор\n",
    "- **Ключевой вопрос:** Влияет ли shape распределения на точность?\n",
    "\n",
    "### Сохранение и использование\n",
    "\n",
    "**Файл:** `analysis_summary_charts.png` (300 DPI, высокое качество)\n",
    "\n",
    "**Применение:**\n",
    "- Включение в README.md\n",
    "- Использование в презентации защиты\n",
    "- Публикация в статье\n",
    "- Обсуждение на встречах с HR-командой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3de8e4-aa11-4091-9415-c08419f5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_summaries:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Mean budget by configuration\n",
    "    ax1 = axes[0, 0]\n",
    "    summary_pivot = results_summary.pivot_table(\n",
    "        values='mean_mc_budget', \n",
    "        index='n_cr_bins', \n",
    "        columns='n_ratings'\n",
    "    )\n",
    "    sns.heatmap(summary_pivot, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax1)\n",
    "    ax1.set_title('Mean Monte Carlo Budget (%) by Matrix Size')\n",
    "    ax1.set_xlabel('Number of Ratings')\n",
    "    ax1.set_ylabel('Number of CR Bins')\n",
    "    \n",
    "    # Plot 2: Success rate by configuration\n",
    "    ax2 = axes[0, 1]\n",
    "    success_pivot = results_summary.pivot_table(\n",
    "        values='mean_success_rate', \n",
    "        index='n_cr_bins', \n",
    "        columns='n_ratings'\n",
    "    )\n",
    "    sns.heatmap(success_pivot, annot=True, fmt='.1f', cmap='RdYlGn', ax=ax2)\n",
    "    ax2.set_title('Mean Success Rate (%) by Matrix Size')\n",
    "    ax2.set_xlabel('Number of Ratings')\n",
    "    ax2.set_ylabel('Number of CR Bins')\n",
    "    \n",
    "    # Plot 3: Budget by distribution type\n",
    "    ax3 = axes[1, 0]\n",
    "    dist_summary = results_summary.groupby('distribution_type')['mean_mc_budget'].mean().sort_values()\n",
    "    dist_summary.plot(kind='barh', ax=ax3, color='steelblue')\n",
    "    ax3.set_title('Mean Budget by Distribution Type')\n",
    "    ax3.set_xlabel('Mean MC Budget (%)')\n",
    "    \n",
    "    # Plot 4: Success rate by distribution type\n",
    "    ax4 = axes[1, 1]\n",
    "    dist_success = results_summary.groupby('distribution_type')['mean_success_rate'].mean().sort_values()\n",
    "    dist_success.plot(kind='barh', ax=ax4, color='coral')\n",
    "    ax4.set_title('Mean Success Rate by Distribution Type')\n",
    "    ax4.set_xlabel('Mean Success Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/analysis_summary_charts.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Charts saved to: {OUTPUT_DIR}/analysis_summary_charts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4f0dc-484a-4cb0-9f4d-aaabf69f7363",
   "metadata": {},
   "source": [
    "## 13. Quick Analysis Functions\n",
    "\n",
    "### Утилиты для быстрого анализа результатов\n",
    "\n",
    "Этот модуль предоставляет helper functions для интерактивного исследования \n",
    "сохраненных результатов без необходимости перезапуска всего анализа.\n",
    "\n",
    "### Функция `analyze_specific_config(config_name)`\n",
    "\n",
    "**Назначение:** Детальный анализ конкретной конфигурации\n",
    "\n",
    "**Использование:**\n",
    "```python\n",
    "df = analyze_specific_config('CR5_R5_normal')\n",
    "```\n",
    "\n",
    "**Что делает:**\n",
    "1. Ищет parquet файл для указанной конфигурации\n",
    "2. Загружает последнюю версию (если несколько runs)\n",
    "3. Выводит сводную статистику:\n",
    "   - Количество проанализированных групп\n",
    "   - Общее количество сотрудников\n",
    "   - Средний heuristic budget\n",
    "   - Средний Monte Carlo budget\n",
    "   - Средний success rate\n",
    "   - Распределение success rate (через describe())\n",
    "4. Возвращает полный DataFrame для дальнейшего анализа\n",
    "\n",
    "**Возвращает:** DataFrame с результатами для всех групп или None если не найдено\n",
    "\n",
    "**Применение:**\n",
    "- Глубокий dive в конкретную конфигурацию\n",
    "- Анализ outliers (группы с необычно низким/высоким success rate)\n",
    "- Проверка гипотез о конкретных настройках\n",
    "\n",
    "### Функция `compare_distributions(n_cr, n_ratings)`\n",
    "\n",
    "**Назначение:** Сравнение всех 4 типов распределений для фиксированного размера матрицы\n",
    "\n",
    "**Использование:**\n",
    "```python\n",
    "comp_df = compare_distributions(5, 5)  # Сравнить для матрицы 5×5\n",
    "```\n",
    "\n",
    "**Что делает:**\n",
    "1. Загружает результаты для всех 4 distributions (normal, skewed_high, skewed_low, uniform)\n",
    "2. Вычисляет средние метрики для каждого типа\n",
    "3. Выводит comparison таблицу\n",
    "4. Возвращает DataFrame для дальнейшего анализа\n",
    "\n",
    "**Возвращает:** DataFrame с 4 строками (по одной на distribution) или None\n",
    "\n",
    "**Применение:**\n",
    "- Понять, насколько sensitive метод к типу распределения\n",
    "- Идентифицировать \"worst case\" и \"best case\" распределения\n",
    "- Quantify разброс success rate между распределениями\n",
    "\n",
    "### Примеры использования\n",
    "\n",
    "**Пример 1: Анализ \"проблемной\" конфигурации**\n",
    "```python\n",
    "# Из summary видим, что CR7_R7_skewed_low имеет низкий success rate\n",
    "df = analyze_specific_config('CR7_R7_skewed_low')\n",
    "\n",
    "# Детальный анализ: какие группы особенно страдают?\n",
    "low_success = df[df['success_rate_pct'] < 40]\n",
    "print(low_success[['company', 'function', 'n_employees', 'success_rate_pct']])\n",
    "```\n",
    "\n",
    "**Пример 2: Сравнение эффекта распределений**\n",
    "```python\n",
    "# Для стандартной матрицы 5×5\n",
    "comp = compare_distributions(5, 5)\n",
    "\n",
    "# Вычислить разброс\n",
    "spread = comp['mean_success_rate'].max() - comp['mean_success_rate'].min()\n",
    "print(f\"Success rate varies by {spread:.1f}% across distributions\")\n",
    "```\n",
    "\n",
    "### Расширяемость\n",
    "\n",
    "Эти функции служат шаблонами для создания дополнительных utility functions:\n",
    "- `analyze_by_group_size()` — группировка по размеру групп\n",
    "- `compare_matrix_sizes()` — сравнение разных размеров матриц\n",
    "- `identify_outliers()` — поиск аномальных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d1fb9-92c8-47f1-9a44-a737e7311d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_specific_config(config_name):\n",
    "    \"\"\"Load and analyze a specific configuration result.\"\"\"\n",
    "    matching_files = list(Path(OUTPUT_DIR).glob(f\"merit_analysis_{config_name}_*.parquet\"))\n",
    "    if not matching_files:\n",
    "        print(f\"❌ No files found for config: {config_name}\")\n",
    "        return None\n",
    "    \n",
    "    latest_file = max(matching_files, key=lambda p: p.stat().st_mtime)\n",
    "    df = pd.read_parquet(latest_file)\n",
    "    \n",
    "    print(f\"Configuration: {config_name}\")\n",
    "    print(f\"=\"*80)\n",
    "    print(f\"Groups analyzed: {len(df)}\")\n",
    "    print(f\"Total employees: {df['n_employees'].sum():,}\")\n",
    "    print(f\"Mean heuristic budget: {df['heuristic_budget_pct'].mean():.2f}%\")\n",
    "    print(f\"Mean MC budget: {df['mc_mean_pct'].mean():.2f}%\")\n",
    "    print(f\"Mean success rate: {df['success_rate_pct'].mean():.1f}%\")\n",
    "    \n",
    "    # Show distribution\n",
    "    print(\"\\nSuccess Rate Distribution:\")\n",
    "    print(df['success_rate_pct'].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_distributions(n_cr, n_ratings):\n",
    "    \"\"\"Compare all distribution types for a specific matrix size.\"\"\"\n",
    "    results = []\n",
    "    for dist_name in DISTRIBUTIONS.keys():\n",
    "        config_name = f\"CR{n_cr}_R{n_ratings}_{dist_name}\"\n",
    "        matching_files = list(Path(OUTPUT_DIR).glob(f\"merit_analysis_{config_name}_*.parquet\"))\n",
    "        if matching_files:\n",
    "            latest_file = max(matching_files, key=lambda p: p.stat().st_mtime)\n",
    "            df = pd.read_parquet(latest_file)\n",
    "            results.append({\n",
    "                'distribution': dist_name,\n",
    "                'mean_budget': df['mc_mean_pct'].mean(),\n",
    "                'mean_success_rate': df['success_rate_pct'].mean()\n",
    "            })\n",
    "    \n",
    "    if results:\n",
    "        comp_df = pd.DataFrame(results)\n",
    "        print(f\"\\nComparison for {n_cr}×{n_ratings} Matrix:\")\n",
    "        print(\"=\"*80)\n",
    "        print(comp_df.to_string(index=False))\n",
    "        return comp_df\n",
    "    else:\n",
    "        print(f\"No results found for {n_cr}×{n_ratings} matrix\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Analysis helper functions defined\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  - analyze_specific_config('CR5_R5_normal')\")\n",
    "print(\"  - compare_distributions(5, 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07f8ac-b669-4816-8333-b7ff9f68ec15",
   "metadata": {},
   "source": [
    "### 14. Собираем все результаты экспериментов в единый файл для дальнейшего анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f835ada1-9dd3-4653-9538-0d1a82f91d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(Path(OUTPUT_DIR).glob(\"merit_analysis_*.parquet\"))\n",
    "combined = pd.concat((pd.read_parquet(p) for p in all_files), ignore_index=True)\n",
    "\n",
    "# If the same group/config was saved multiple times, keep the last (newest) row\n",
    "combined['__ts'] = pd.to_datetime(combined['config_name'].str.extract(r'_(\\d{8}_\\d{6})$')[0],\n",
    "                                  format=\"%Y%m%d_%H%M%S\", errors='coerce')\n",
    "combined = (combined\n",
    "            .sort_values(['company','function','config_name','__ts'])\n",
    "            .drop_duplicates(['company','function','config_name'], keep='last')\n",
    "            .drop(columns='__ts'))\n",
    "\n",
    "combined.to_parquet(f\"ALL_results.parquet\", index=False, compression='gzip')\n",
    "\n",
    "df = pd.read_parquet('ALL_results.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
