{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf119c1-abba-4784-8209-3e29c1fcae8a",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Merit Matrix Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acfa4e-ac2e-4908-9a36-698b70ff7370",
   "metadata": {},
   "source": [
    "## Цель оптимизации\n",
    "\n",
    "Найти оптимальную merit increase matrix (матрицу повышений зарплат), которая:\n",
    "1. Соответствует бюджету — итоговые затраты попадают в диапазон [target - lower_tol%, target + upper_tol%]\n",
    "2. Устойчива к вариациям — корректно работает при разных распределениях performance ratings от менеджеров\n",
    "3. Соблюдает структурные ограничения — монотонность, минимальные/максимальные шаги, anchor cells\n",
    "4. Дифференцирует performance — заметная разница между high/low performers\n",
    "\n",
    "---\n",
    "\n",
    "## Ключевые особенности\n",
    "\n",
    "Гибкая конфигурация:\n",
    "- Поддержка произвольного количества ratings (2+) и CR bins (2+)\n",
    "- Custom target distributions с возможностью hard zeros (исключение рейтингов из Monte Carlo)\n",
    "- Custom CR bin edges для нестандартной сегментации\n",
    "- Asymmetric budget tolerance — разные пороги для under/overspend\n",
    "\n",
    "Продвинутая валидация:\n",
    "- Strict zero enforcement — принудительное обнуление выбранных ячеек матрицы\n",
    "- Anchor cells — фиксация угловых ячеек (best/worst performers) на точных значениях\n",
    "- Auto-adaptive constraints на основе размера merit pool\n",
    "\n",
    "Оптимизация производительности:\n",
    "- Векторизованный fitness evaluation через pre-stacked scenarios\n",
    "- Эффективное построение salary matrix с groupby (O(N) вместо O(N×I×J))\n",
    "- JIT-компиляция критичных функций для больших датасетов\n",
    "\n",
    "---\n",
    "\n",
    "## Методология\n",
    "\n",
    "Genetic Algorithm:\n",
    "1. Initialization — создание начальной популяции структурированных матриц\n",
    "2. Evolution — tournament selection, crossover, mutation в течение N поколений\n",
    "3. Fitness Evaluation — быстрая оценка на subset сценариев (quick eval)\n",
    "4. Full Evaluation — детальная оценка топ-кандидатов на полном наборе сценариев\n",
    "5. Local Refinement — оптимизация лучших решений через L-BFGS-B\n",
    "\n",
    "Monte Carlo Simulation:\n",
    "- Генерация тысяч сценариев распределения ratings через Dirichlet perturbation\n",
    "- Stress testing — включение экстремальных распределений (inflated, harsh, forced curve)\n",
    "- Budget validation — проверка попадания в диапазон для каждого сценария\n",
    "\n",
    "Constraint System:\n",
    "- Cell bounds — глобальные min/max для любой ячейки\n",
    "- Monotonicity — ratings растут слева направо, CR уменьшается сверху вниз\n",
    "- Step sizes — минимальные/максимальные изменения между соседними ячейками\n",
    "- Multipliers — ratio-требования между разными ratings\n",
    "- Fixed cells — strict zeros и anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebcdb25-e515-4afb-83dd-2c9fc94ad77b",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "### Библиотеки для оптимизации\n",
    "\n",
    "**Научные вычисления:**\n",
    "- `numpy` — векторизованные операции, массивы для матриц и сценариев\n",
    "- `pandas` — обработка employee data, группировка для salary matrices\n",
    "- `scipy.optimize.minimize` — L-BFGS-B для local refinement\n",
    "- `scipy.stats.norm` — генерация bell curve distributions, Dirichlet perturbation\n",
    "\n",
    "**Структуры данных:**\n",
    "- `dataclasses` — type-safe структуры для MatrixCandidate, PolicyGuidance\n",
    "- `typing` — аннотации типов для повышения читаемости кода\n",
    "\n",
    "**Утилиты:**\n",
    "- `json` — экспорт конфигурации\n",
    "- `warnings` — подавление RuntimeWarnings при работе с NaN/inf\n",
    "- `os` — работа с файловой системой для экспорта\n",
    "\n",
    "**Design Note:** код использует функциональный стиль и чистые функции для репродуцируемости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9b14c-c8a2-467f-a19a-8ed455e7d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe2354-7c81-45a3-90ac-ac069cf57fc0",
   "metadata": {},
   "source": [
    "## User Configuration Section\n",
    "\n",
    "КРИТИЧЕСКАЯ СЕКЦИЯ — все параметры оптимизации задаются здесь.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Budget Configuration\n",
    "\n",
    "**MERIT_POOL_VALUE:**\n",
    "- Целевой средний процент повышения по компании (например, 0.08 = 8%)\n",
    "- Используется для расчета total merit budget = MERIT_POOL_VALUE × total_payroll\n",
    "\n",
    "**BUDGET_TOLERANCE_LOWER / UPPER (Asymmetric):**\n",
    "- Допустимые отклонения от target budget\n",
    "- Lower: сколько можно НЕ ПОТРАТИТЬ (например, 0.05 = допустимо -5% от бюджета)\n",
    "- Upper: сколько можно ПЕРЕРАСХОДОВАТЬ (например, 0.015 = допустимо +1.5% от бюджета)\n",
    "- Asymmetry отражает бизнес-реальность: underspend часто более приемлем, чем overspend\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Matrix Structure\n",
    "\n",
    "**NUM_RATINGS:**\n",
    "- Количество уровней performance ratings (минимум 2)\n",
    "- Типичные значения: 3 (Below/Meets/Exceeds), 5 (стандарт), 7 (детальная система)\n",
    "\n",
    "**NUM_CR_BINS:**\n",
    "- Количество групп по Compa-Ratio (минимум 2)\n",
    "- Игнорируется, если задан CUSTOM_CR_BINS\n",
    "- Больше bins = более детальная дифференциация, но выше риск overfitting\n",
    "\n",
    "**CR_BIN_FIRST / CR_BIN_LAST:**\n",
    "- Границы для auto-generation bins\n",
    "- Например: 0.75 to 1.25 создает bins вокруг рыночного уровня (CR=1.0)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Target Distribution\n",
    "\n",
    "**CUSTOM_TARGET_DISTRIBUTION:**\n",
    "- `None` — автоматическая bell curve генерация\n",
    "- `Dict[int, float]` — точное распределение по ratings\n",
    "- Должно суммироваться в 1.0\n",
    "- Может содержать zeros для исключения ratings\n",
    "\n",
    "**HARD_ZERO_RATINGS:**\n",
    "- `False` — zero-probability ratings могут появляться в Monte Carlo с epsilon-вероятностью\n",
    "- `True` — zero-probability ratings полностью исключаются из всех сценариев\n",
    "- Применяется только если CUSTOM_TARGET_DISTRIBUTION содержит zeros\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Monte Carlo Settings\n",
    "\n",
    "**SCENARIO_CONCENTRATION:**\n",
    "- Контролирует variance в Dirichlet perturbation\n",
    "- Выше значение → сценарии ближе к target distribution (меньше variance)\n",
    "- Ниже значение → больше разброс (stress testing)\n",
    "- Типичное: ~166 (5%/0.03) для ±10% отклонений от target\n",
    "- Для peaky distributions автоматически увеличивается\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Custom CR Bins\n",
    "\n",
    "**CUSTOM_CR_BINS:**\n",
    "- `None` — автоматическая генерация на основе NUM_CR_BINS\n",
    "- `List[float]` — явное задание границ (начинается с 0.0, заканчивается np.inf)\n",
    "- Минимум 3 edges (даёт ≥2 bins)\n",
    "- Пример: [0.0, 0.80, 0.90, 1.10, 1.20, np.inf] → 5 bins с custom ranges\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Strict Zero Enforcement\n",
    "\n",
    "**FORCE_ZERO_CELLS:**\n",
    "- Принудительное обнуление выбранных ячеек матрицы\n",
    "- Формат: {cr_bin_index: [list of rating indices]}\n",
    "- Пример: {4: [0, 1]} — CR bin 4, ratings 1–2 всегда 0%\n",
    "- `None` или `{}` — отключено, используется только ANCHOR_CELL контроль\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Anchor Cell Controls\n",
    "\n",
    "**ANCHOR_CELL_MAX:**\n",
    "- Точное значение merit % для best performers (CR bin 0, highest rating)\n",
    "- `None` — свободно, `float` — фиксируется\n",
    "- Пример: 0.10 = 10% для top performers\n",
    "\n",
    "**ANCHOR_CELL_MIN:**\n",
    "- Точное значение merit % для worst performers (highest CR bin, lowest rating)\n",
    "- `None` — свободно, `0.0` — zero merit, `float` — другое значение\n",
    "- Anchor cells PINNED на протяжении всей оптимизации\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Constraint Configuration\n",
    "\n",
    "**CONSTRAINT_CONFIG:**\n",
    "- Auto-adaptive constraints на основе merit pool и matrix size\n",
    "- `None` значения → автоматический расчет\n",
    "- Можно вручную override для экспериментов\n",
    "\n",
    "**Key constraints:**\n",
    "- `cell_min/max` — bounds для любой ячейки\n",
    "- `min/max_step_rating` — шаги между ratings\n",
    "- `min/max_step_cr` — шаги между CR bins\n",
    "- `rating_multiplier` — ratio-требования (например, Rating 5 ≥ 1.4× Rating 1)\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Genetic Algorithm Parameters\n",
    "\n",
    "**GA_CONFIG:**\n",
    "- `population_size` — размер популяции (больше = лучше exploration)\n",
    "- `num_generations` — максимум итераций (может сойтись ранее)\n",
    "- `elite_size` — сколько лучших сохраняются без изменений\n",
    "- `tournament_size` — размер турнира для selection\n",
    "- `mutation_rate` — вероятность мутации ячейки (0.25 = 25%)\n",
    "- `crossover_rate` — вероятность crossover vs клонирования\n",
    "- `convergence_patience` — остановка при стагнации fitness\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Fitness Weights\n",
    "\n",
    "**FITNESS_WEIGHTS:**\n",
    "- `budget` — вес budget score (попадание в tolerance band)\n",
    "- `constraints` — вес constraint satisfaction (monotonicity, steps, etc.)\n",
    "- Суммарно = 1.0\n",
    "\n",
    "**DIFF_WEIGHT:**\n",
    "- Доп. вес для видимой дифференциации\n",
    "- 0.0 = отключено\n",
    "- 0.10–0.15 = лёгкий nudge\n",
    "- 0.30+ = сильное влияние\n",
    "- Поощряет steeper slopes между ratings для visibility\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Evaluation Strategy\n",
    "\n",
    "**EVAL_CONFIG:**\n",
    "- `quick_eval_scenarios` — сценариев для быстрой GA оценки (2000–5000)\n",
    "- `full_eval_scenarios` — сценариев для финальной оценки (10000+)\n",
    "- `num_top_candidates` — сколько лучших идут в full evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Data & Seeds\n",
    "\n",
    "**DATA_FILE:**\n",
    "- Путь к Excel с employee data (`base_salary`, `CR`)\n",
    "- `None` — сгенерировать synthetic data\n",
    "\n",
    "**SEED_*:**\n",
    "- Random seeds для репродуцируемости\n",
    "- Разные seeds для population, scenarios, GA → независимость\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e6261-65e8-40bc-82d0-f671fbca9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# USER CONFIGURATION\n",
    "# ======================\n",
    "\n",
    "# Merit pool configuration\n",
    "MERIT_POOL_VALUE = 13/100\n",
    "\n",
    "# Budget tolerance (asymmetric)\n",
    "# Lower tolerance: how much UNDER budget is acceptable (underspending)\n",
    "# Upper tolerance: how much OVER budget is acceptable (overspending)\n",
    "# Example: LOWER=0.05, UPPER=0.015 means -5% to +1.5% from target is acceptable\n",
    "BUDGET_TOLERANCE_LOWER = 0.05  # 6% underspend allowed\n",
    "BUDGET_TOLERANCE_UPPER = 0.05 # 1.5% overspend allowed\n",
    "\n",
    "# Rating structure\n",
    "NUM_RATINGS = 5  # Can be any integer >= 2\n",
    "NUM_CR_BINS = 5   # Can be any integer >= 2 (ignored if CUSTOM_CR_BINS is set)\n",
    "CR_BIN_FIRST = 0.75\n",
    "CR_BIN_LAST = 1.25\n",
    "\n",
    "# Custom target rating distribution (Optional)\n",
    "# Set to None for automatic bell curve generation based on NUM_RATINGS\n",
    "# Set to dict to specify custom distribution (must sum to 1.0, can include zeros)\n",
    "# Example: CUSTOM_TARGET_DISTRIBUTION = {1: 0.05, 2: 0.15, 3: 0.40, 4: 0.30, 5: 0.10}\n",
    "# Example with zeros: CUSTOM_TARGET_DISTRIBUTION = {1: 0.0, 2: 0.1, 3: 0.6, 4: 0.2, 5: 0.1}\n",
    "# Keys must match rating scale (1 to NUM_RATINGS)\n",
    "CUSTOM_TARGET_DISTRIBUTION = {1: 0.10, 2: 0.15, 3: 0.50, 4: 0.15, 5: 0.10}\n",
    "\n",
    "# Hard zero ratings (applies only when custom distribution contains zeros)\n",
    "# False: Zero-probability ratings can still appear in Monte Carlo with tiny epsilon mass\n",
    "# True: Zero-probability ratings are completely excluded from Monte Carlo scenarios\n",
    "# Example: If rating 1 has 0% target and HARD_ZERO_RATINGS=True, rating 1 never appears\n",
    "HARD_ZERO_RATINGS = False\n",
    "\n",
    "# Monte Carlo scenario variance\n",
    "# Higher values = scenarios stay closer to target distribution\n",
    "# Lower values = more variance in rating distributions across scenarios\n",
    "# Default ~66.67 keeps scenarios within ~10% of target percentages\n",
    "SCENARIO_CONCENTRATION = 5 / 0.03\n",
    "\n",
    "# Custom CR bin edges (Optional)\n",
    "# Set to None for automatic bin generation based on NUM_CR_BINS, CR_BIN_FIRST, CR_BIN_LAST\n",
    "# Set to list of edges to use custom bins (must start with 0.0 and end with np.inf)\n",
    "# Example: CUSTOM_CR_BINS = [0.0, 0.80, 0.90, 1.00, 1.10, 1.20, np.inf]\n",
    "# When custom bins are used, NUM_CR_BINS is automatically set to len(CUSTOM_CR_BINS) - 1\n",
    "# REQUIRES at least 3 edges (defines at least 2 bins)\n",
    "CUSTOM_CR_BINS = [0.0, 0.80, 0.90, 1.10, 1.20, np.inf]\n",
    "\n",
    "# STRICT ZERO ENFORCEMENT (Optional - for multiple cells)\n",
    "# Force zero merit for multiple cells beyond just the worst performer corner\n",
    "# Format: {cr_bin_index: [list of rating indices to zero]}\n",
    "# Example: {4: [0, 1], 3: [0]} means CR bin 4 ratings 1-2 get 0%, CR bin 3 rating 1 gets 0%\n",
    "# \n",
    "# Set to None or {} to disable and use ANCHOR_CELL_MIN instead for corner control\n",
    "# Use this when you need zeros in MULTIPLE cells, not just the worst corner\n",
    "FORCE_ZERO_CELLS = None  # Disabled - using ANCHOR_CELL controls instead\n",
    "\n",
    "\n",
    "# FORCE_ZERO_CELLS = {\n",
    "#     NUM_CR_BINS - 1: [0],  # Highest CR bin (worst positioned), lowest rating\n",
    "#     NUM_CR_BINS - 2: [0],  # Second highest CR bin, lowest rating\n",
    "# }\n",
    "\n",
    "\n",
    "# ANCHOR CELL CONTROLS (Recommended for corner control)\n",
    "# Set exact values for corner cells of the matrix\n",
    "# anchor_max: Exact merit % for best performers (lowest CR bin, highest rating)\n",
    "# anchor_min: Exact merit % for worst performers (highest CR bin, lowest rating)\n",
    "# When set to specific values, these cells are PINNED throughout optimization\n",
    "# When set to None, optimizer is free to explore within normal constraints\n",
    "ANCHOR_CELL_MAX = None  # e.g., 0.10 to pin best performers at exactly 10%\n",
    "ANCHOR_CELL_MIN = None   # e.g., 0.01 to pin worst performers at exactly 1%, or 0.0 for zero\n",
    "\n",
    "# Data source\n",
    "DATA_FILE = 'Misha.xlsx'  # Set to None for synthetic data\n",
    "\n",
    "# Random seeds\n",
    "SEED_BASE_POPULATION = 42\n",
    "SEED_SCENARIOS = 2025\n",
    "SEED_GA = 89\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"artifacts\"\n",
    "\n",
    "# Constraint configuration\n",
    "CONSTRAINT_CONFIG = {\n",
    "    'cell_min': 0,\n",
    "    'cell_max': None,\n",
    "    'min_step_rating': None,\n",
    "    'step_max_rating': None,\n",
    "    'min_step_cr': None,\n",
    "    'step_max_cr': None,\n",
    "    'rating_multiplier': None,\n",
    "}\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "GA_CONFIG = {\n",
    "    'population_size': 1000,\n",
    "    'num_generations': 500,\n",
    "    'elite_size': 100,\n",
    "    'tournament_size': 5,\n",
    "    'mutation_rate': 0.25,\n",
    "    'crossover_rate': 0.7,\n",
    "    'convergence_patience': 50,\n",
    "    'convergence_threshold': 1e-5,\n",
    "}\n",
    "\n",
    "# Fitness weights\n",
    "FITNESS_WEIGHTS = {\n",
    "    'budget': 0.70,\n",
    "    'constraints': 0.30\n",
    "}\n",
    "\n",
    "# Extra weight to reward visible rating differentiation (0..1)\n",
    "# Set to 0.10–0.15 for a noticeable nudge without blowing up budget risk.\n",
    "DIFF_WEIGHT = 0.30\n",
    "\n",
    "# Evaluation strategy\n",
    "EVAL_CONFIG = {\n",
    "    'quick_eval_scenarios': 2000,\n",
    "    'full_eval_scenarios': 10000,\n",
    "    'num_top_candidates': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e487a-5853-440a-ab89-3af94f2c6bfa",
   "metadata": {},
   "source": [
    "## Auto-Generated Configuration\n",
    "\n",
    "**Автоматическая генерация параметров на основе пользовательских настроек.**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Генерация целевого распределения (Target Distribution Generation)\n",
    "\n",
    "**generate_target_distribution():**\n",
    "- Создаёт нормальное распределение (bell curve) для `NUM_RATINGS`\n",
    "- Центрируется на среднем рейтинге: `loc = (NUM_RATINGS - 1) / 2`\n",
    "- `scale` адаптируется к количеству рейтингов: `scale = NUM_RATINGS / 4`\n",
    "- Используется, если `CUSTOM_TARGET_DISTRIBUTION = None`\n",
    "\n",
    "**Пример для 5 ratings:**\n",
    "- Rating 1: ~10% (хвосты)\n",
    "- Rating 2: ~20%\n",
    "- Rating 3: ~40% (центр)\n",
    "- Rating 4: ~20%\n",
    "- Rating 5: ~10% (хвосты)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Валидация пользовательского распределения (Custom Distribution Validation)\n",
    "\n",
    "**validate_custom_target_distribution():**\n",
    "- ДОЛЖНА быть вызвана перед использованием custom distribution\n",
    "- Проверяет:\n",
    "  - Тип = `dict`\n",
    "  - Ключи соответствуют диапазону рейтингов (1…NUM_RATINGS)\n",
    "  - Значения числовые, ≥0, ≤1.0\n",
    "  - Сумма = 1.0 (с допуском 1e-6)\n",
    "- Подход “fail fast” — при ошибке сразу выбрасывает `ValueError` (быстрое завершение при некорректных данных)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Вычисление параметров Дирихле (Dirichlet Alpha Computation)\n",
    "\n",
    "**compute_dirichlet_alphas():**\n",
    "- Преобразует вероятности целевого распределения в параметры Дирихле (`alpha`)\n",
    "- Обработка нулей: `epsilon = 1e-12`, чтобы все `alpha` были строго > 0\n",
    "- Масштабирование на основе энтропии (entropy-based scaling):\n",
    "  - Узкие/пиковые распределения (peaky distributions) → увеличиваем `concentration`, чтобы снизить разброс (variance)\n",
    "- Формула:  \n",
    "  `alpha = (probs / sum(probs)) × concentration × (1 + peakiness_factor)`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Семплирование из Дирихле (Dirichlet Sampling)\n",
    "\n",
    "**dirichlet_sample_from_target():**\n",
    "- Генерирует “возмущённое” (perturbed) распределение вокруг target\n",
    "- **Hard zeros mode (жёсткие нули):** если `HARD_ZERO_RATINGS=True`:\n",
    "  - Семплируется только из рейтингов с >0\n",
    "  - Полное распределение восстанавливается с нулями\n",
    "- **Soft zeros mode (мягкие нули):** применяется `epsilon` ко всем ratings\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Маскирование нулей в стресс-сценариях (Zero Masking for Stress Scenarios)\n",
    "\n",
    "**mask_zeros_in_distribution():**\n",
    "- Применяет zero constraints к стресс-сценариям\n",
    "- Обнуляет рейтинги, которые имеют 0% в target\n",
    "- Нормализует оставшиеся рейтинги до sum=1.0\n",
    "- Важно для консистентности при `HARD_ZERO_RATINGS=True`\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Генерация CR-бинов (CR Bin Generation)\n",
    "\n",
    "**generate_cr_bin_edges():**\n",
    "- Автоматически генерирует равномерно распределённые bins\n",
    "- Формат: `[0.0, ..., ..., np.inf]`\n",
    "- Промежуточные границы: `linspace(CR_BIN_FIRST, CR_BIN_LAST, NUM_CR_BINS - 1)`\n",
    "\n",
    "**validate_custom_cr_bins():**\n",
    "- Проверяет корректность пользовательских границ\n",
    "- Требования:\n",
    "  - Минимум 3 границы (даёт ≥2 bins)\n",
    "  - Первая граница = `0.0` (ТОЧНО, для совместимости с `pd.cut`)\n",
    "  - Последняя граница = `np.inf`\n",
    "  - Строго возрастающие значения\n",
    "  - Без отрицательных значений\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Генерация стресс-сценариев (Stress Scenario Generation)\n",
    "\n",
    "**generate_stress_scenarios():**\n",
    "- Создаёт экстремальные распределения для устойчивости (robust testing)\n",
    "- Типы:\n",
    "  - `inflated` — смещение к высоким рейтингам (grade inflation — “раздувание оценок”)\n",
    "  - `harsh` — смещение к низким рейтингам (строгие менеджеры)\n",
    "  - `forced_curve` — искусственная bell curve независимо от target\n",
    "  - `top_heavy` — концентрация в верхней половине\n",
    "- **honor_zeros:** если True, применяет маскирование нулей (zero masking) ко всем stress scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Обработка фиксированных ячеек (Fixed Cell Processing)\n",
    "\n",
    "**process_force_zero_cells():**\n",
    "- Конвертирует `FORCE_ZERO_CELLS` в boolean mask\n",
    "- `Mask[i, j] = True` → ячейка `[i, j]` ОБЯЗАТЕЛЬНО = 0\n",
    "- Валидация индексов, предупреждения (warnings) при выходе за диапазон\n",
    "\n",
    "**get_anchor_cells():**\n",
    "- Извлекает координаты и значения anchor cells\n",
    "- Возвращает словарь: `{'max': (i, j, value), 'min': (i, j, value)}`\n",
    "- Используется для жёсткого применения (enforcement) и отчётности (reporting)\n",
    "\n",
    "**enforce_anchor_cells() / enforce_strict_zeros():**\n",
    "- Принудительно применяют фиксированные значения к матрице\n",
    "- Вызываются после КАЖДОЙ модификации (mutation, crossover, repair)\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Объекты конфигурации (Configuration Objects)\n",
    "\n",
    "После валидации создаются глобальные объекты:\n",
    "- `TARGET_RATING_DISTRIBUTION` — финализированное распределение\n",
    "- `CR_BIN_EDGES` — итоговые границы CR-бинов\n",
    "- `NUM_CR_BINS` — обновляется при использовании CUSTOM_CR_BINS\n",
    "- `CONSTRAINTS` — автоматически сгенерированные ограничения\n",
    "- `STRESS_SCENARIOS` — предвычисленные стресс-сценарии\n",
    "- `STRICT_ZERO_MASK` — boolean mask для принудительных нулей\n",
    "\n",
    "---\n",
    "\n",
    "### Принципы проектирования (Design Philosophy)\n",
    "\n",
    "- **Проверяй раннее, завершай быстро (validate early, fail fast):**  \n",
    "  Ошибки лучше ловить на входе, чем отлавливать последствия позже.\n",
    "\n",
    "- **Автоматически адаптируйся к входным данным (auto-adapt to inputs):**  \n",
    "  Логика подстраивается под конфигурацию пользователя, вместо жёстких значений.\n",
    "\n",
    "- **Явное лучше, чем неявное (explicit over implicit):**  \n",
    "  Все ключевые решения должны быть заданы напрямую, без скрытой логики.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8fb68-4f89-4819-9fb7-9c5f816df553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# AUTO-GENERATED CONFIG\n",
    "# ======================\n",
    "\n",
    "RATING_ORDER = list(range(1, NUM_RATINGS + 1))\n",
    "\n",
    "\n",
    "def generate_target_distribution(num_ratings: int) -> Dict[int, float]:\n",
    "    \"\"\"Auto-generate target distribution based on NUM_RATINGS (bell curve pattern)\"\"\"\n",
    "    \n",
    "    ratings = np.arange(num_ratings)\n",
    "    \n",
    "    # Use bell curve centered on middle rating\n",
    "    # Scale parameter adapts to number of ratings for natural spread\n",
    "    probs = norm.pdf(ratings, loc=(num_ratings-1)/2, scale=num_ratings/4)\n",
    "    probs = probs / probs.sum()\n",
    "    \n",
    "    # Convert to dict with 1-indexed ratings\n",
    "    return {i+1: float(p) for i, p in enumerate(probs)}\n",
    "\n",
    "\n",
    "def validate_custom_target_distribution(dist: Optional[Dict], num_ratings: int) -> None:\n",
    "    \"\"\"Validate custom target distribution - MUST be called before using distribution\"\"\"\n",
    "    if dist is None:\n",
    "        return\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Check it's a dict\n",
    "    if not isinstance(dist, dict):\n",
    "        errors.append(\"CUSTOM_TARGET_DISTRIBUTION must be a dictionary\")\n",
    "        raise ValueError(\"Custom target distribution validation failed:\\n  \" + \"\\n  \".join(errors))\n",
    "    \n",
    "    # Check keys match rating order\n",
    "    expected_keys = set(range(1, num_ratings + 1))\n",
    "    actual_keys = set(dist.keys())\n",
    "    \n",
    "    if actual_keys != expected_keys:\n",
    "        errors.append(f\"CUSTOM_TARGET_DISTRIBUTION keys must be {expected_keys}, got {actual_keys}\")\n",
    "    \n",
    "    # Check all values are numeric and non-negative\n",
    "    for rating, prob in dist.items():\n",
    "        if not isinstance(prob, (int, float)):\n",
    "            errors.append(f\"Rating {rating} probability must be numeric, got {type(prob)}\")\n",
    "        elif prob < 0:\n",
    "            errors.append(f\"Rating {rating} probability must be non-negative, got {prob}\")\n",
    "        elif prob > 1:\n",
    "            errors.append(f\"Rating {rating} probability must be <= 1.0, got {prob}\")\n",
    "    \n",
    "    # Check probabilities sum to 1.0 (with tolerance)\n",
    "    if not errors:  # Only check sum if individual values are valid\n",
    "        total = sum(dist.values())\n",
    "        if abs(total - 1.0) > 1e-6:\n",
    "            errors.append(f\"CUSTOM_TARGET_DISTRIBUTION must sum to 1.0, got {total:.8f}\")\n",
    "    \n",
    "    if errors:\n",
    "        raise ValueError(\"Custom target distribution validation failed:\\n  \" + \"\\n  \".join(errors))\n",
    "\n",
    "\n",
    "def compute_dirichlet_alphas(base_probs: np.ndarray, concentration: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute Dirichlet alpha parameters from target probabilities, handling zeros.\n",
    "    \n",
    "    Args:\n",
    "        base_probs: Target probability distribution (may contain zeros)\n",
    "        concentration: Controls variance around target (higher = less variance)\n",
    "    \n",
    "    Returns:\n",
    "        Alpha parameters suitable for np.random.dirichlet (all strictly positive)\n",
    "    \"\"\"\n",
    "    # Ensure strictly positive alphas (Dirichlet requires alpha > 0)\n",
    "    eps = 1e-12\n",
    "    alphas = np.clip(base_probs, eps, None)\n",
    "    \n",
    "    # Calculate entropy to detect peaky distributions\n",
    "    entropy = -np.sum(base_probs * np.log(np.clip(base_probs, eps, 1.0)))\n",
    "    max_entropy = np.log(len(base_probs))\n",
    "    \n",
    "    # Peakiness factor: 0 = uniform, 1 = extremely peaked\n",
    "    peakiness_factor = (max_entropy - entropy) / max_entropy if max_entropy > 0 else 0.0\n",
    "    \n",
    "    # Scale up concentration for peaky targets to reduce variance\n",
    "    scale = 1.0 + 1.0 * peakiness_factor\n",
    "    \n",
    "    # Renormalize to maintain total concentration \"mass\"\n",
    "    alphas = alphas / alphas.sum() * concentration * scale\n",
    "    \n",
    "    return alphas\n",
    "\n",
    "\n",
    "def dirichlet_sample_from_target(base_probs: np.ndarray, concentration: float, rng) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample from Dirichlet distribution, respecting hard zeros if enabled.\n",
    "    \n",
    "    Args:\n",
    "        base_probs: Target probability distribution (may contain zeros)\n",
    "        concentration: Controls variance around target\n",
    "        rng: Random number generator\n",
    "    \n",
    "    Returns:\n",
    "        Perturbed probability distribution\n",
    "    \"\"\"\n",
    "    if HARD_ZERO_RATINGS and np.any(base_probs == 0):\n",
    "        # Hard zeros: exclude zero-probability ratings entirely\n",
    "        nz_idx = np.flatnonzero(base_probs > 0)\n",
    "        sub_probs = base_probs[nz_idx] / base_probs[nz_idx].sum()\n",
    "        sub_alphas = compute_dirichlet_alphas(sub_probs, concentration)\n",
    "        sub_draw = rng.dirichlet(sub_alphas)\n",
    "        \n",
    "        # Reconstruct full distribution with zeros\n",
    "        draw = np.zeros_like(base_probs)\n",
    "        draw[nz_idx] = sub_draw\n",
    "        return draw\n",
    "    else:\n",
    "        # Soft zeros: use epsilon for zero probabilities\n",
    "        alphas = compute_dirichlet_alphas(base_probs, concentration)\n",
    "        return rng.dirichlet(alphas)\n",
    "\n",
    "\n",
    "def mask_zeros_in_distribution(dist: Dict[int, float], target: Dict[int, float]) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Force zero probabilities in dist where target has zeros, then renormalize.\n",
    "    \n",
    "    Args:\n",
    "        dist: Distribution to mask\n",
    "        target: Target distribution (determines which ratings to zero)\n",
    "    \n",
    "    Returns:\n",
    "        Masked and renormalized distribution\n",
    "    \"\"\"\n",
    "    masked = {k: (0.0 if target[k] == 0 else v) for k, v in dist.items()}\n",
    "    total = sum(masked.values())\n",
    "    \n",
    "    if total > 0:\n",
    "        return {k: v / total for k, v in masked.items()}\n",
    "    else:\n",
    "        # Degenerate case: all ratings were zero, distribute uniformly among non-zero targets\n",
    "        non_zero_count = sum(1 for v in target.values() if v > 0)\n",
    "        if non_zero_count > 0:\n",
    "            return {k: (1.0 / non_zero_count if target[k] > 0 else 0.0) for k in dist.keys()}\n",
    "        else:\n",
    "            # All targets are zero - shouldn't happen with valid config\n",
    "            return {k: 1.0 / len(dist) for k in dist.keys()}\n",
    "\n",
    "\n",
    "def process_force_zero_cells(force_zero_config, num_cr_bins: int, num_ratings: int) -> np.ndarray:\n",
    "    \"\"\"Convert FORCE_ZERO_CELLS config to boolean mask\"\"\"\n",
    "    mask = np.zeros((num_cr_bins, num_ratings), dtype=bool)\n",
    "    \n",
    "    if force_zero_config is None or not force_zero_config:\n",
    "        return mask\n",
    "    \n",
    "    for cr_bin, rating_indices in force_zero_config.items():\n",
    "        if cr_bin < 0 or cr_bin >= num_cr_bins:\n",
    "            print(f\"Warning: CR bin {cr_bin} out of range [0, {num_cr_bins-1}], skipping\")\n",
    "            continue\n",
    "        for rating_idx in rating_indices:\n",
    "            if rating_idx < 0 or rating_idx >= num_ratings:\n",
    "                print(f\"Warning: Rating index {rating_idx} out of range [0, {num_ratings-1}], skipping\")\n",
    "                continue\n",
    "            mask[cr_bin, rating_idx] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_anchor_cells() -> Dict[str, Tuple[int, int, float]]:\n",
    "    \"\"\"Get anchor cell coordinates and values if specified\"\"\"\n",
    "    anchors = {}\n",
    "    \n",
    "    if ANCHOR_CELL_MAX is not None:\n",
    "        # Best performers: CR bin 0 (lowest CR), highest rating\n",
    "        anchors['max'] = (0, NUM_RATINGS - 1, ANCHOR_CELL_MAX)\n",
    "    \n",
    "    if ANCHOR_CELL_MIN is not None:\n",
    "        # Worst performers: highest CR bin, rating 0 (lowest rating)\n",
    "        anchors['min'] = (NUM_CR_BINS - 1, 0, ANCHOR_CELL_MIN)\n",
    "    \n",
    "    return anchors\n",
    "\n",
    "\n",
    "def enforce_anchor_cells(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Enforce exact values for anchor cells\"\"\"\n",
    "    matrix = matrix.copy()\n",
    "    anchors = get_anchor_cells()\n",
    "    \n",
    "    for anchor_type, (i, j, value) in anchors.items():\n",
    "        matrix[i, j] = value\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def generate_cr_bin_edges(num_bins: int, first: float, last: float) -> List[float]:\n",
    "    \"\"\"Generate CR bin edges\"\"\"\n",
    "    if num_bins < 2:\n",
    "        raise ValueError(\"NUM_CR_BINS must be at least 2\")\n",
    "    intermediate = np.linspace(first, last, num_bins - 1)\n",
    "    return [0.0] + list(intermediate) + [np.inf]\n",
    "\n",
    "\n",
    "def validate_custom_cr_bins(bins) -> None:\n",
    "    \"\"\"Validate custom CR bin edges - MUST be called before using bins\"\"\"\n",
    "    if bins is None:\n",
    "        return\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Check it's a list or array\n",
    "    if not isinstance(bins, (list, tuple, np.ndarray)):\n",
    "        errors.append(\"CUSTOM_CR_BINS must be a list, tuple, or numpy array\")\n",
    "        raise ValueError(\"Custom CR bins validation failed:\\n  \" + \"\\n  \".join(errors))\n",
    "    \n",
    "    bins_list = list(bins)\n",
    "    \n",
    "    # REQUIRE AT LEAST 3 EDGES (i.e., >= 2 bins)\n",
    "    if len(bins_list) < 3:\n",
    "        errors.append(\"CUSTOM_CR_BINS must have at least 3 edges (defines >= 2 bins)\")\n",
    "    \n",
    "    # First edge must be EXACTLY 0.0 (pd.cut requires this for include_lowest=True)\n",
    "    if len(bins_list) > 0 and bins_list[0] != 0.0:\n",
    "        errors.append(f\"CUSTOM_CR_BINS must start with exactly 0.0, got {bins_list[0]}\")\n",
    "    \n",
    "    # Last edge must be np.inf\n",
    "    if len(bins_list) > 0 and not np.isinf(bins_list[-1]):\n",
    "        errors.append(f\"CUSTOM_CR_BINS must end with np.inf, got {bins_list[-1]}\")\n",
    "    \n",
    "    # Must be strictly increasing\n",
    "    for i in range(len(bins_list) - 1):\n",
    "        if not (bins_list[i] < bins_list[i+1]):\n",
    "            errors.append(\n",
    "                f\"CUSTOM_CR_BINS must be strictly increasing, but \"\n",
    "                f\"bins[{i}]={bins_list[i]} >= bins[{i+1}]={bins_list[i+1]}\"\n",
    "            )\n",
    "    \n",
    "    # All finite values must be non-negative\n",
    "    for i, edge in enumerate(bins_list[:-1]):  # Exclude last (inf)\n",
    "        if edge < 0:\n",
    "            errors.append(f\"CUSTOM_CR_BINS edges must be non-negative, but bins[{i}]={edge}\")\n",
    "    \n",
    "    if errors:\n",
    "        raise ValueError(\"Custom CR bins validation failed:\\n  \" + \"\\n  \".join(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f30f55-6273-4c1e-bce6-4c24fed94b64",
   "metadata": {},
   "source": [
    "## Auto-Adaptive Constraint Configuration\n",
    "\n",
    "КРИТИЧЕСКАЯ ФУНКЦИЯ для создания ограничений, которые одновременно реализуемы (feasible) и содержательно обоснованы (meaningful).\n",
    "\n",
    "---\n",
    "\n",
    "### Design Philosophy (Принципиальный подход)\n",
    "\n",
    "Старый подход (проблемный):\n",
    "- Ограничения строились на теоретическом диапазоне (0% до max_possible%)\n",
    "- Требовали слишком широкие границы → решения становились нереализуемыми\n",
    "- Пример: при merit pool 8% требовали span 0–24% → физически невозможно\n",
    "\n",
    "Новый подход (adaptive):\n",
    "- Ограничения строятся на реальном размере MERIT_POOL, а не на теоретическом max\n",
    "- Ограничения направляют к хорошим решениям, а не блокируют их\n",
    "- Баланс между видимостью различий (visibility) и выполнимостью (feasibility)\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Границы ячеек (Cell Bounds, глобальные)\n",
    "\n",
    "cell_min:\n",
    "- По умолчанию: 0.0 (разрешает 0% для худших исполнителей)\n",
    "- Можно переопределить для гарантированного минимума\n",
    "\n",
    "cell_max:\n",
    "- Адаптивный множитель, зависящий от размера merit pool\n",
    "- Логика:\n",
    "  - Малый pool (≤3%) → multiplier 4.0× (сильная дифференциация)\n",
    "  - Средний pool (5–8%) → 3.0×\n",
    "  - Большой pool (12–20%) → 2.0×\n",
    "- Это потолок (ceiling), а не target → оптимизатор может использовать меньше\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Горизонтальные шаги по рейтингам (Rating Step Sizes)\n",
    "\n",
    "Принцип: рассчитывать от размера merit pool, а не от теоретического span\n",
    "\n",
    "min_step_rating:\n",
    "- Базово: 15% от merit pool на 1 шаг\n",
    "- Пример: 8% pool → минимум 1.2% между соседними рейтингами\n",
    "- Корректировки:\n",
    "  - 7+ ratings → уменьшить на 25%\n",
    "  - Минимум (floor): 0.5%\n",
    "  - Максимум (ceiling): 3.0%\n",
    "\n",
    "step_max_rating:\n",
    "- 3.5× от минимального шага\n",
    "- Жёсткий лимит: 8%\n",
    "\n",
    "Обоснование:\n",
    "- Гарантирует видимую дифференциацию performance\n",
    "- Не перегружает оптимизатор\n",
    "- Масштабируется с размером pool и количеством rating уровней\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Вертикальные шаги по CR (CR Step Sizes)\n",
    "\n",
    "Принцип: CR — вторичный фактор, поэтому шаги меньше\n",
    "\n",
    "min_step_cr:\n",
    "- 50% от min_step_rating\n",
    "- Корректировки:\n",
    "  - 7+ bins → уменьшить на 25%\n",
    "  - Минимум: 0.3%\n",
    "  - Максимум: 2.0%\n",
    "\n",
    "step_max_cr:\n",
    "- 3.0× от минимального шага\n",
    "- Жёсткий лимит: 5%\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Ограничения-множители (Multiplier Constraints / Ratios)\n",
    "\n",
    "Цель: обеспечить логичный порядок между рейтингами\n",
    "\n",
    "rating_multiplier:\n",
    "- Формат: {low_rating_idx: (high_rating_idx, minimum_ratio)}\n",
    "- Смягчение требований:\n",
    "  - Старое правило: Top ≥1.8× Bottom → слишком жёстко\n",
    "  - Новое правило: Top ≥1.4× Bottom → реализуемо\n",
    "- Если ≥4 ratings: второй сверху ≥1.25× Bottom\n",
    "\n",
    "Примечание: Multipliers обеспечивают порядок, а не экстремальную разницу\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Диагностика реализуемости (Feasibility Diagnostics)\n",
    "\n",
    "Автоматические проверки:\n",
    "\n",
    "1. Range utilization (использование диапазона):\n",
    "   - Сколько % доступного span занимают constraints?\n",
    "   - >90% → Warning (слишком жёсткие ограничения)\n",
    "\n",
    "2. Anchor compatibility (совместимость anchor cells):\n",
    "   - Проверка, хватает ли разницы между anchor cells для требуемых шагов\n",
    "   - Если нет — предупреждение + рекомендации\n",
    "\n",
    "3. Step size capping:\n",
    "   - Если шаг был уменьшен из-за нехватки диапазона — это отмечается\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Результат (Output)\n",
    "\n",
    "Функция возвращает словарь CONSTRAINT_CONFIG с финализированными значениями:\n",
    "\n",
    "{\n",
    "    'cell_min': 0.0,\n",
    "    'cell_max': 0.24,               # Adaptive\n",
    "    'min_step_rating': 0.012,       # Merit pool based\n",
    "    'step_max_rating': 0.042,\n",
    "    'min_step_cr': 0.006,\n",
    "    'step_max_cr': 0.018,\n",
    "    'rating_multiplier': {0: (4, 1.4)}  # Soft requirements\n",
    "}\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Интерактивный отчёт (Interactive Reporting)\n",
    "\n",
    "В консоль выводится:\n",
    "- Размер merit pool\n",
    "- Диапазон ячеек (cell range span)\n",
    "- Минимальные требуемые шаги по рейтингам / CR\n",
    "- Статус реализуемости (Good / Warning)\n",
    "- Процент использования диапазона\n",
    "- Проверка совместимости anchor cells\n",
    "\n",
    "Design Goal: Полная прозрачность — пользователь не только видит результаты, но и понимает, почему они такими получились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7557900c-a036-42b0-8b6d-1ea6ca546ab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_configure_constraints\u001b[39m(num_ratings: \u001b[38;5;28mint\u001b[39m, num_cr_bins: \u001b[38;5;28mint\u001b[39m, merit_pool_pct: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Auto-generate adaptive constraints that balance differentiation with feasibility.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m        Dictionary of constraint parameters\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     config \u001b[38;5;241m=\u001b[39m CONSTRAINT_CONFIG\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "def auto_configure_constraints(num_ratings: int, num_cr_bins: int, merit_pool_pct: float) -> Dict:\n",
    "    \"\"\"\n",
    "    Auto-generate adaptive constraints that balance differentiation with feasibility.\n",
    "    \n",
    "    KEY PRINCIPLE: Constraints should guide toward good solutions, not prevent them.\n",
    "    \n",
    "    Design Philosophy:\n",
    "    - Start with SMALL minimum steps to ensure visibility (not maximal differentiation)\n",
    "    - Let cell_max be generous (optimizer will find the right values)\n",
    "    - Step requirements should create clear ordering, not force huge gaps\n",
    "    - Budget feasibility is paramount - constraints should help, not hinder\n",
    "    \n",
    "    Args:\n",
    "        num_ratings: Number of rating levels (e.g., 5)\n",
    "        num_cr_bins: Number of CR bins (e.g., 5)\n",
    "        merit_pool_pct: Average merit pool as decimal (e.g., 0.08 for 8%)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of constraint parameters\n",
    "    \"\"\"\n",
    "    config = CONSTRAINT_CONFIG.copy()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # CELL BOUNDS (Global Min/Max for any cell in the matrix)\n",
    "    # ============================================================================\n",
    "    \n",
    "    # Minimum: Default to 0% unless user overrides\n",
    "    if config['cell_min'] is None:\n",
    "        config['cell_min'] = 0.0\n",
    "    \n",
    "    # Maximum: Should be generous but realistic\n",
    "    # This is an UPPER BOUND, not a target - optimizer can use less\n",
    "    if config['cell_max'] is None:\n",
    "        # Scale based on merit pool size\n",
    "        # Smaller pools need higher multipliers for any differentiation\n",
    "        # But keep it reasonable - this is a ceiling, not a requirement\n",
    "        if merit_pool_pct <= 0.03:      # ≤3% pools (very tight)\n",
    "            multiplier = 4.0\n",
    "        elif merit_pool_pct <= 0.05:    # 3-5% pools\n",
    "            multiplier = 3.5\n",
    "        elif merit_pool_pct <= 0.08:    # 5-8% pools\n",
    "            multiplier = 3.0 \n",
    "        elif merit_pool_pct <= 0.12:    # 8-12% pools\n",
    "            multiplier = 2.5 # 2.5\n",
    "        elif merit_pool_pct <= 0.20:    # 12-20% pools\n",
    "            multiplier = 2 # 2\n",
    "        else:                           # >20% pools\n",
    "            multiplier = 1.5 # 1.5\n",
    "        \n",
    "        config['cell_max'] = merit_pool_pct * multiplier\n",
    "    \n",
    "    # ============================================================================\n",
    "    # STEP SIZES: Based on MERIT POOL, not theoretical span\n",
    "    # ============================================================================\n",
    "    # \n",
    "    # Key Insight: If average merit is 8%, we might want something like:\n",
    "    #   Rating 1: 2%,  Rating 2: 5%,  Rating 3: 8%,  Rating 4: 11%,  Rating 5: 14%\n",
    "    # \n",
    "    # That's about 3% steps (0.03) with a total range of 12% (0.12)\n",
    "    # This is MUCH smaller than the theoretical span of (0% to 24% = 0.24)\n",
    "    # \n",
    "    # The old approach would force steps based on 0.24, creating impossible constraints.\n",
    "    # New approach: Base steps on merit_pool_pct for realistic, achievable targets.\n",
    "    # ============================================================================\n",
    "    \n",
    "    num_rating_steps = max(num_ratings - 1, 1)\n",
    "    num_cr_steps = max(num_cr_bins - 1, 1)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # RATING STEP SIZES (Horizontal: across ratings within same CR bin)\n",
    "    # ============================================================================\n",
    "    \n",
    "    if config['min_step_rating'] is None:\n",
    "        # Base calculation: Use merit pool as reference, not theoretical span\n",
    "        # \n",
    "        # For visibility, we want at least 10-15% of the merit pool per step\n",
    "        # Example: 8% pool → 0.8% to 1.2% minimum step\n",
    "        # This ensures Rating 5 is clearly better than Rating 1, but doesn't over-constrain\n",
    "        \n",
    "        # Base step as percentage of merit pool\n",
    "        base_step_factor = 0.15  # 15% of merit pool per step (modest)\n",
    "        \n",
    "        config['min_step_rating'] = merit_pool_pct * base_step_factor\n",
    "        \n",
    "        # Adjust for number of ratings - more ratings need smaller steps\n",
    "        if num_ratings >= 7:\n",
    "            config['min_step_rating'] *= 0.75  # 25% smaller for 7+ ratings\n",
    "        \n",
    "        # Absolute floor: Never less than 0.5% for visibility\n",
    "        config['min_step_rating'] = max(config['min_step_rating'], 0.005)\n",
    "        \n",
    "        # Absolute ceiling: Never more than 3% (prevents excessive differentiation)\n",
    "        config['min_step_rating'] = min(config['min_step_rating'], 0.03)\n",
    "    \n",
    "    if config['step_max_rating'] is None:\n",
    "        # Maximum step: Allow some flexibility but prevent spiky matrices\n",
    "        # Roughly 3-4x the minimum step\n",
    "        config['step_max_rating'] = config['min_step_rating'] * 3.5\n",
    "        \n",
    "        # Hard cap: Never more than 8% in a single step\n",
    "        config['step_max_rating'] = min(config['step_max_rating'], 0.08)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # CR STEP SIZES (Vertical: across CR bins within same rating)\n",
    "    # ============================================================================\n",
    "    \n",
    "    if config['min_step_cr'] is None:\n",
    "        # CR steps should be somewhat smaller than rating steps\n",
    "        # Rationale: Performance (rating) is primary differentiator, CR is secondary\n",
    "        # Typically 40-60% of rating step size\n",
    "        \n",
    "        config['min_step_cr'] = config['min_step_rating'] * 0.5\n",
    "        \n",
    "        # Adjust for number of bins\n",
    "        if num_cr_bins >= 7:\n",
    "            config['min_step_cr'] *= 0.75\n",
    "        \n",
    "        # Floor: Never less than 0.3% for visibility\n",
    "        config['min_step_cr'] = max(config['min_step_cr'], 0.003)\n",
    "        \n",
    "        # Ceiling: Never more than 2%\n",
    "        config['min_step_cr'] = min(config['min_step_cr'], 0.02)\n",
    "    \n",
    "    if config['step_max_cr'] is None:\n",
    "        # Maximum CR step\n",
    "        config['step_max_cr'] = config['min_step_cr'] * 3.0\n",
    "        \n",
    "        # Hard cap: Never more than 5%\n",
    "        config['step_max_cr'] = min(config['step_max_cr'], 0.05)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MULTIPLIER CONSTRAINTS (Rating-to-rating ratio requirements)\n",
    "    # ============================================================================\n",
    "    \n",
    "    if config['rating_multiplier'] is None:\n",
    "        multipliers = {}\n",
    "        \n",
    "        # Soften multiplier requirements - just ensure clear ordering\n",
    "        if num_ratings >= 2:\n",
    "            # Top rating should be notably higher than bottom, but not extreme\n",
    "            # Old: 1.8x, New: 1.4x (more achievable)\n",
    "            lowest_idx = 0\n",
    "            highest_idx = num_ratings - 1\n",
    "            multipliers[lowest_idx] = (highest_idx, 1.4)\n",
    "        \n",
    "        if num_ratings >= 4:\n",
    "            # If we have at least 4 ratings, ensure second-from-top is clearly above bottom\n",
    "            # Old: (1, highest, 1.4), New: (0, second_highest, 1.25)\n",
    "            multipliers[0] = (num_ratings - 2, 1.25)\n",
    "        \n",
    "        config['rating_multiplier'] = multipliers\n",
    "    \n",
    "    # ============================================================================\n",
    "    # VALIDATION & DIAGNOSTICS\n",
    "    # ============================================================================\n",
    "    \n",
    "    # Calculate what the constraints imply about total range\n",
    "    min_range_rating = config['min_step_rating'] * num_rating_steps\n",
    "    min_range_cr = config['min_step_cr'] * num_cr_steps\n",
    "    max_theoretical_range = config['cell_max'] - config['cell_min']\n",
    "    \n",
    "    print(f\"\\nConstraint Analysis:\")\n",
    "    print(f\"  Merit Pool: {merit_pool_pct*100:.2f}%\")\n",
    "    print(f\"  Cell Range: {config['cell_min']*100:.2f}% to {config['cell_max']*100:.2f}% (span: {max_theoretical_range*100:.2f}%)\")\n",
    "    print(f\"  Min Rating Step: {config['min_step_rating']*100:.2f}% → Total: {min_range_rating*100:.2f}%\")\n",
    "    print(f\"  Min CR Step: {config['min_step_cr']*100:.2f}% → Total: {min_range_cr*100:.2f}%\")\n",
    "    print(f\"  Feasibility Check: \", end=\"\")\n",
    "    \n",
    "    # Check if constraints are achievable\n",
    "    if min_range_rating > max_theoretical_range * 0.9:\n",
    "        print(\"⚠ WARNING: Rating step requirements are very tight!\")\n",
    "        print(f\"    Required range: {min_range_rating*100:.2f}%, Available: {max_theoretical_range*100:.2f}%\")\n",
    "        print(f\"    Consider: reducing min_step_rating or increasing cell_max\")\n",
    "    elif min_range_cr > max_theoretical_range * 0.9:\n",
    "        print(\"⚠ WARNING: CR step requirements are very tight!\")\n",
    "        print(f\"    Required range: {min_range_cr*100:.2f}%, Available: {max_theoretical_range*100:.2f}%\")\n",
    "    else:\n",
    "        # Calculate utilization percentage\n",
    "        utilization = max(min_range_rating, min_range_cr) / max_theoretical_range * 100\n",
    "        print(f\"✓ Good ({utilization:.0f}% utilization of available range)\")\n",
    "    \n",
    "    # Check anchor cell compatibility\n",
    "    if ANCHOR_CELL_MIN is not None and ANCHOR_CELL_MAX is not None:\n",
    "        anchor_span = ANCHOR_CELL_MAX - ANCHOR_CELL_MIN\n",
    "        required_span = max(min_range_rating, min_range_cr)\n",
    "        \n",
    "        if anchor_span < required_span * 0.9:\n",
    "            print(f\"\\n⚠ WARNING: Anchor cells define span of {anchor_span*100:.2f}%\")\n",
    "            print(f\"    but constraints require {required_span*100:.2f}%\")\n",
    "            print(f\"    This WILL cause infeasibility!\")\n",
    "            print(f\"    Solutions:\")\n",
    "            print(f\"      1. Widen anchor range (min={ANCHOR_CELL_MIN}, max={ANCHOR_CELL_MAX})\")\n",
    "            print(f\"      2. Set min_step_rating={required_span/num_rating_steps*0.8:.4f}\")\n",
    "            print(f\"      3. Set min_step_cr={required_span/num_cr_steps*0.8:.4f}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def generate_stress_scenarios(num_ratings: int, target_dist: Dict, honor_zeros: bool = False) -> Dict[str, Dict[int, float]]:\n",
    "    \"\"\"Generate stress test scenarios dynamically\"\"\"\n",
    "    scenarios = {'target': target_dist}\n",
    "    \n",
    "    ratings = list(range(1, num_ratings + 1))\n",
    "    \n",
    "    # Inflated: skew toward high ratings\n",
    "    inflated = {}\n",
    "    for i, r in enumerate(ratings):\n",
    "        weight = (i + 1) ** 2\n",
    "        inflated[r] = weight\n",
    "    total = sum(inflated.values())\n",
    "    inflated = {r: v/total for r, v in inflated.items()}\n",
    "    \n",
    "    # Harsh: skew toward low ratings\n",
    "    harsh = {}\n",
    "    for i, r in enumerate(ratings):\n",
    "        weight = (num_ratings - i) ** 2\n",
    "        harsh[r] = weight\n",
    "    total = sum(harsh.values())\n",
    "    harsh = {r: v/total for r, v in harsh.items()}\n",
    "    \n",
    "    # Forced curve: bell curve\n",
    "    forced = {}\n",
    "    for i, r in enumerate(ratings):\n",
    "        forced[r] = norm.pdf(i, loc=(num_ratings-1)/2, scale=num_ratings/4)\n",
    "    total = sum(forced.values())\n",
    "    forced = {r: v/total for r, v in forced.items()}\n",
    "    \n",
    "    # Top heavy: more in upper half\n",
    "    top_heavy = {}\n",
    "    for i, r in enumerate(ratings):\n",
    "        if i >= num_ratings // 2:\n",
    "            top_heavy[r] = 0.7 / (num_ratings - num_ratings // 2)\n",
    "        else:\n",
    "            top_heavy[r] = 0.3 / (num_ratings // 2)\n",
    "    \n",
    "    scenarios.update({\n",
    "        'inflated': inflated,\n",
    "        'harsh': harsh,\n",
    "        'forced_curve': forced,\n",
    "        'top_heavy': top_heavy\n",
    "    })\n",
    "    \n",
    "    # If honoring zeros, mask and renormalize all stress scenarios\n",
    "    if honor_zeros:\n",
    "        scenarios = {k: mask_zeros_in_distribution(v, target_dist) for k, v in scenarios.items()}\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "\n",
    "def validate_scenario_distributions(scenarios_dict: Dict[str, Dict[int, float]]) -> None:\n",
    "    \"\"\"Validate that scenario distributions are properly formatted\"\"\"\n",
    "    expect = set(RATING_ORDER)\n",
    "    for name, dist in scenarios_dict.items():\n",
    "        if set(dist.keys()) != expect:\n",
    "            raise ValueError(f\"Scenario '{name}' keys {set(dist.keys())} must match RATING_ORDER {expect}\")\n",
    "        if abs(sum(dist.values()) - 1.0) > 1e-9:\n",
    "            raise ValueError(f\"Scenario '{name}' must sum to 1.0, got {sum(dist.values())}\")\n",
    "\n",
    "\n",
    "# Generate configuration - VALIDATE CUSTOM INPUTS FIRST (fail fast)\n",
    "\n",
    "# Validate custom target distribution BEFORE using it\n",
    "validate_custom_target_distribution(CUSTOM_TARGET_DISTRIBUTION, NUM_RATINGS)\n",
    "\n",
    "# Generate or use custom target distribution\n",
    "if CUSTOM_TARGET_DISTRIBUTION is not None:\n",
    "    TARGET_RATING_DISTRIBUTION = CUSTOM_TARGET_DISTRIBUTION.copy()\n",
    "    print(f\"Using custom target distribution\")\n",
    "    # Check if any zeros exist and HARD_ZERO_RATINGS is enabled\n",
    "    if HARD_ZERO_RATINGS and any(v == 0 for v in TARGET_RATING_DISTRIBUTION.values()):\n",
    "        zero_ratings = [k for k, v in TARGET_RATING_DISTRIBUTION.items() if v == 0]\n",
    "        print(f\"  Hard zeros enabled: ratings {zero_ratings} will never appear in Monte Carlo\")\n",
    "else:\n",
    "    TARGET_RATING_DISTRIBUTION = generate_target_distribution(NUM_RATINGS)\n",
    "\n",
    "# Validate custom CR bins BEFORE using them\n",
    "validate_custom_cr_bins(CUSTOM_CR_BINS)\n",
    "\n",
    "# Handle CR bin configuration\n",
    "if CUSTOM_CR_BINS is not None:\n",
    "    # Use custom bins and update NUM_CR_BINS accordingly\n",
    "    CR_BIN_EDGES = list(CUSTOM_CR_BINS)\n",
    "    NUM_CR_BINS = len(CR_BIN_EDGES) - 1\n",
    "    print(f\"Using custom CR bins: {NUM_CR_BINS} bins defined\")\n",
    "else:\n",
    "    # Auto-generate bins based on NUM_CR_BINS, CR_BIN_FIRST, CR_BIN_LAST\n",
    "    CR_BIN_EDGES = generate_cr_bin_edges(NUM_CR_BINS, CR_BIN_FIRST, CR_BIN_LAST)\n",
    "\n",
    "CONSTRAINTS = auto_configure_constraints(NUM_RATINGS, NUM_CR_BINS, MERIT_POOL_VALUE)\n",
    "STRESS_SCENARIOS = generate_stress_scenarios(NUM_RATINGS, TARGET_RATING_DISTRIBUTION, honor_zeros=HARD_ZERO_RATINGS)\n",
    "STRICT_ZERO_MASK = process_force_zero_cells(FORCE_ZERO_CELLS, NUM_CR_BINS, NUM_RATINGS)\n",
    "\n",
    "# Check if step sizes were capped due to tight constraints\n",
    "STEP_SIZE_CAPPED = False\n",
    "span = CONSTRAINTS['cell_max'] - CONSTRAINTS['cell_min']\n",
    "uncapped_min_rating = CONSTRAINTS['cell_max'] * 0.08 / max(NUM_RATINGS - 1, 1)\n",
    "if NUM_RATINGS > 5:\n",
    "    uncapped_min_rating *= 0.7\n",
    "uncapped_min_cr = uncapped_min_rating * 0.45\n",
    "if NUM_CR_BINS > 5:\n",
    "    uncapped_min_cr *= 0.8\n",
    "\n",
    "if CONSTRAINTS['min_step_rating'] < uncapped_min_rating * 0.99:  # Small tolerance for rounding\n",
    "    STEP_SIZE_CAPPED = True\n",
    "if CONSTRAINTS['min_step_cr'] < uncapped_min_cr * 0.99:\n",
    "    STEP_SIZE_CAPPED = True\n",
    "\n",
    "# Validate scenarios\n",
    "validate_scenario_distributions(STRESS_SCENARIOS)\n",
    "\n",
    "# ======================\n",
    "# VALIDATION\n",
    "# ======================\n",
    "\n",
    "def validate_configuration():\n",
    "    \"\"\"Validate user configuration\"\"\"\n",
    "    errors = []\n",
    "    warnings_list = []\n",
    "    \n",
    "    if NUM_RATINGS < 2:\n",
    "        errors.append(\"NUM_RATINGS must be at least 2\")\n",
    "    \n",
    "    if abs(sum(TARGET_RATING_DISTRIBUTION.values()) - 1.0) > 1e-8:\n",
    "        errors.append(f\"TARGET_RATING_DISTRIBUTION must sum to 1.0\")\n",
    "    \n",
    "    # Validate CR bin configuration consistency (only if auto-generating)\n",
    "    if CUSTOM_CR_BINS is None:\n",
    "        if CR_BIN_FIRST >= CR_BIN_LAST:\n",
    "            errors.append(f\"CR_BIN_FIRST must be < CR_BIN_LAST\")\n",
    "        if NUM_CR_BINS < 2:\n",
    "            errors.append(\"NUM_CR_BINS must be at least 2\")\n",
    "    \n",
    "    if MERIT_POOL_VALUE <= 0:\n",
    "        errors.append(\"MERIT_POOL_VALUE must be positive\")\n",
    "    \n",
    "    if BUDGET_TOLERANCE_LOWER <= 0 or BUDGET_TOLERANCE_LOWER >= 1:\n",
    "        errors.append(\"BUDGET_TOLERANCE_LOWER must be between 0 and 1\")\n",
    "    \n",
    "    if BUDGET_TOLERANCE_UPPER <= 0 or BUDGET_TOLERANCE_UPPER >= 1:\n",
    "        errors.append(\"BUDGET_TOLERANCE_UPPER must be between 0 and 1\")\n",
    "    \n",
    "    if SCENARIO_CONCENTRATION <= 0:\n",
    "        errors.append(\"SCENARIO_CONCENTRATION must be positive\")\n",
    "    \n",
    "    # Validate anchor cells\n",
    "    if ANCHOR_CELL_MAX is not None:\n",
    "        if ANCHOR_CELL_MAX <= 0:\n",
    "            errors.append(\"ANCHOR_CELL_MAX must be positive if specified\")\n",
    "        if ANCHOR_CELL_MAX > 1.0:\n",
    "            warnings_list.append(f\"ANCHOR_CELL_MAX of {ANCHOR_CELL_MAX:.2%} is above 100% - this is unusual\")\n",
    "    \n",
    "    if ANCHOR_CELL_MIN is not None:\n",
    "        if ANCHOR_CELL_MIN < 0:\n",
    "            errors.append(\"ANCHOR_CELL_MIN cannot be negative\")\n",
    "        if ANCHOR_CELL_MAX is not None and ANCHOR_CELL_MIN >= ANCHOR_CELL_MAX:\n",
    "            errors.append(f\"ANCHOR_CELL_MIN ({ANCHOR_CELL_MIN}) must be < ANCHOR_CELL_MAX ({ANCHOR_CELL_MAX})\")\n",
    "    \n",
    "    if errors:\n",
    "        raise ValueError(\"Configuration errors:\\n  \" + \"\\n  \".join(errors))\n",
    "    \n",
    "    print(\"Configuration validated\")\n",
    "    \n",
    "    # Print zero enforcement info\n",
    "    num_forced_zeros = STRICT_ZERO_MASK.sum()\n",
    "    if num_forced_zeros > 0:\n",
    "        print(f\"Strict zero enforcement enabled for {num_forced_zeros} cells:\")\n",
    "        for i in range(NUM_CR_BINS):\n",
    "            for j in range(NUM_RATINGS):\n",
    "                if STRICT_ZERO_MASK[i, j]:\n",
    "                    print(f\"  - CR bin {i}, Rating {j+1}: FORCED to 0%\")\n",
    "    \n",
    "    # Print anchor cell info\n",
    "    anchors = get_anchor_cells()\n",
    "    if anchors:\n",
    "        print(f\"Anchor cells PINNED to exact values:\")\n",
    "        for anchor_type, (i, j, value) in anchors.items():\n",
    "            if anchor_type == 'max':\n",
    "                print(f\"  - CR bin {i}, Rating {j+1} (best performers): PINNED at {value*100:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  - CR bin {i}, Rating {j+1} (worst performers): PINNED at {value*100:.2f}%\")\n",
    "    \n",
    "    if warnings_list:\n",
    "        print(\"\\nConfiguration warnings:\")\n",
    "        for w in warnings_list:\n",
    "            print(f\"  - {w}\")\n",
    "    \n",
    "    # Warn about step size capping\n",
    "    if STEP_SIZE_CAPPED:\n",
    "        print(\"\\nStep sizes capped: The range between ANCHOR_CELL_MIN/MAX or small cell_max\")\n",
    "        print(\"    required reducing min_step_rating or min_step_cr to prevent infeasibility.\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# UTILITY FUNCTIONS\n",
    "# ======================\n",
    "\n",
    "def round_matrix(matrix: np.ndarray, decimals: int = 4) -> np.ndarray:\n",
    "    \"\"\"Round matrix values to human-readable percentages\"\"\"\n",
    "    return np.round(matrix, decimals)\n",
    "\n",
    "\n",
    "def enforce_strict_zeros(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Enforce strict zero values for specified cells\"\"\"\n",
    "    matrix = matrix.copy()\n",
    "    matrix[STRICT_ZERO_MASK] = 0.0\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def enforce_all_fixed_cells(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Enforce both strict zeros and anchor cells\"\"\"\n",
    "    matrix = enforce_strict_zeros(matrix)\n",
    "    matrix = enforce_anchor_cells(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8956ef2-580d-4051-b150-0c81df6d23c8",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "\n",
    "---\n",
    "\n",
    "### MatrixCandidate\n",
    "\n",
    "**Назначение:** Полное представление одного решения матрицы.\n",
    "\n",
    "**Поля:**\n",
    "- `matrix` — numpy array [I×J] с процентами merit increase\n",
    "- `fitness` — итоговый композитный скор (взвешенная сумма budget + constraints + diff)\n",
    "- `budget_score` — 0..1, насколько хорошо решение попадает в допустимый бюджетный диапазон\n",
    "- `constraint_score` — 0..1, штраф за нарушения ограничений (монотонность, шаги, границы)\n",
    "- `success_rate` — % сценариев, в которых бюджет попадает в допустимый диапазон\n",
    "- `mean_deviation` — среднее |actual - target| / target по всем сценариям\n",
    "- `generation` — поколение GA, в котором кандидат был создан или улучшен\n",
    "\n",
    "**Использование:**\n",
    "- Возвращается из GA evolution\n",
    "- Сортируется по `fitness` для ранжирования\n",
    "- Используется для экспорта и аналитики\n",
    "\n",
    "---\n",
    "\n",
    "### PolicyGuidance\n",
    "\n",
    "**Назначение:** Управленческие рекомендации для одного уровня рейтинга.\n",
    "\n",
    "**Поля:**\n",
    "- `rating` — номер рейтинга (от 1 до NUM_RATINGS)\n",
    "- `target_pct` — целевой % сотрудников на этом рейтинге (из TARGET_RATING_DISTRIBUTION)\n",
    "- `hard_min_pct` — P10 успешных распределений (консервативный нижний порог)\n",
    "- `hard_max_pct` — P90 успешных распределений (консервативный верхний порог)\n",
    "\n",
    "**Интерпретация:**\n",
    "- Руководитель должен стремиться к `target_pct`\n",
    "- Диапазон `[hard_min_pct, hard_max_pct]` задаёт «зону безопасности» с учётом вариативности\n",
    "- Если фактическое распределение выходит за границы → повышенный риск превышения бюджета\n",
    "\n",
    "**Пример:**\n",
    "Rating 3: target=50%, hard_min=45%, hard_max=55%  \n",
    "→ Руководители должны стремиться к ~50%, допустимый диапазон 45–55%\n",
    "\n",
    "**Как генерируется:**\n",
    "- Рассчитывается после оптимизации для лучшей матрицы\n",
    "- Использует 200 Monte Carlo сценариев\n",
    "- Учитывает только успешные сценарии (бюджет в допустимом диапазоне)\n",
    "- P10 / P90 применяются для устойчивости к выбросам и вариативности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e564eb-c8be-4b4a-ac8f-1c4f004e7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# DATA STRUCTURES\n",
    "# ======================\n",
    "\n",
    "@dataclass\n",
    "class MatrixCandidate:\n",
    "    matrix: np.ndarray\n",
    "    fitness: float\n",
    "    budget_score: float\n",
    "    constraint_score: float\n",
    "    success_rate: float\n",
    "    mean_deviation: float\n",
    "    generation: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PolicyGuidance:\n",
    "    rating: int\n",
    "    target_pct: float\n",
    "    hard_min_pct: float\n",
    "    hard_max_pct: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3f465-c699-402d-95a3-89eb3a0e6463",
   "metadata": {},
   "source": [
    "## Загрузка данных (Data Loading)\n",
    "\n",
    "### load_employee_data()\n",
    "\n",
    "**Назначение:** Загрузить популяцию сотрудников для построения salary matrix.\n",
    "\n",
    "**Варианты входных данных:**\n",
    "\n",
    "**1. Excel-файл (если filepath указан):**\n",
    "- Обязательные столбцы: `base_salary`, `CR`\n",
    "- Необязательные: `employee_id`, другие метаданные\n",
    "- Переименование: `CR` → `compa_ratio` для единообразия\n",
    "\n",
    "**2. Синтетические данные (если filepath=None или файл не найден):**\n",
    "- Генерируется N=1200 сотрудников\n",
    "- `base_salary` — логнормальное распределение (mean=11.1, sigma=0.35)  \n",
    "  → реалистичное распределение зарплат с «правым хвостом»\n",
    "- `compa_ratio` — normal(1.0, 0.10), обрезка до [0.6, 1.4]  \n",
    "  → центрировано на значение рынка (CR=1.0)\n",
    "\n",
    "**Обработка:**\n",
    "1. Загрузка или генерация данных\n",
    "2. Создание столбца `cr_bin` через `pd.cut`:\n",
    "   - Используются `CR_BIN_EDGES`\n",
    "   - `include_lowest=True` — включает минимальное значение в первый bin\n",
    "   - `right=False` — интервалы в формате [low, high)\n",
    "3. Нумерация bin’ов: 0, 1, ..., NUM_CR_BINS - 1\n",
    "\n",
    "**Вывод:**\n",
    "- DataFrame со столбцами:  \n",
    "  `employee_id`, `base_salary`, `compa_ratio`, `cr_bin`\n",
    "- Готов для генерации сценариев\n",
    "\n",
    "**Design Note:**\n",
    "- Синтетические данные используются для тестов и демо\n",
    "- В продакшене ожидаются реальные данные\n",
    "- Биннинг по CR должен соответствовать структуре матрицы\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095562fa-45bd-4d2d-b6b8-20d5eb71c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# DATA LOADING\n",
    "# ======================\n",
    "\n",
    "def load_employee_data(filepath: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Load employee data from Excel or generate synthetic\"\"\"\n",
    "    if filepath is not None:\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Warning: File '{filepath}' not found. Using synthetic data.\")\n",
    "            filepath = None\n",
    "        else:\n",
    "            try:\n",
    "                df = pd.read_excel(filepath)\n",
    "                if 'base_salary' not in df.columns or 'CR' not in df.columns:\n",
    "                    raise ValueError(\"Excel must contain 'base_salary' and 'CR' columns\")\n",
    "                df = df.rename(columns={'CR': 'compa_ratio'})\n",
    "                print(f\"Loaded data from '{filepath}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading '{filepath}': {e}. Using synthetic data.\")\n",
    "                filepath = None\n",
    "    \n",
    "    if filepath is None:\n",
    "        np.random.seed(SEED_BASE_POPULATION)\n",
    "        n = 1200\n",
    "        df = pd.DataFrame({\n",
    "            'employee_id': np.arange(n) + 1,\n",
    "            'base_salary': np.random.lognormal(mean=11.1, sigma=0.35, size=n),\n",
    "            'compa_ratio': np.clip(np.random.normal(loc=1.0, scale=0.10, size=n), 0.6, 1.4),\n",
    "        })\n",
    "        print(f\"Generated synthetic data\")\n",
    "    \n",
    "    df['cr_bin'] = pd.cut(df['compa_ratio'], bins=CR_BIN_EDGES,\n",
    "                          labels=np.arange(NUM_CR_BINS),\n",
    "                          include_lowest=True, right=False).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0183e6-bc27-4616-bd55-17001d18710c",
   "metadata": {},
   "source": [
    "## Генерация сценариев (Monte Carlo Simulation)\n",
    "\n",
    "### generate_rating_scenarios()\n",
    "\n",
    "**Назначение:**  \n",
    "Создать множество возможных сценариев распределения рейтингов сотрудников и построить по ним salary-матрицы, чтобы протестировать устойчивость merit matrix.\n",
    "\n",
    "**Входные параметры:**\n",
    "- `df` — данные сотрудников  \n",
    "- `num_scenarios` — сколько сценариев сгенерировать  \n",
    "- `include_stress` — добавлять ли заранее подготовленные стресс-сценарии\n",
    "\n",
    "**Процесс:**\n",
    "1. Если `include_stress=True`, добавляются экстремальные сценарии (`inflated`, `harsh`, `forced_curve`, `top_heavy`), чтобы покрыть крайние случаи.\n",
    "2. Остальные сценарии создаются через Dirichlet-семплирование вокруг `TARGET_RATING_DISTRIBUTION`.\n",
    "   - Параметр `SCENARIO_CONCENTRATION` управляет вариативностью:\n",
    "     - Выше → ближе к target (меньше разброс)\n",
    "     - Ниже → больше разброс (стресс-тест)\n",
    "3. Если `HARD_ZERO_RATINGS=True`, рейтинги с нулевой вероятностью полностью исключаются из семплирования.  \n",
    "   Если False, им дается очень малая (epsilon) вероятность.\n",
    "\n",
    "**Результат:**  \n",
    "Список salary-матриц (по одной на сценарий), готовых для векторной оценки fitness.\n",
    "\n",
    "---\n",
    "\n",
    "### create_salary_matrix()\n",
    "\n",
    "**Назначение:**  \n",
    "Преобразовать одно распределение рейтингов в salary matrix размером `[CR bins × Ratings]`.\n",
    "\n",
    "**Используемый (оптимизированный) подход:**\n",
    "- Каждому сотруднику присваивается рейтинг вероятностно (векторно).\n",
    "- Рейтинг преобразуется в индекс столбца матрицы.\n",
    "- Выполняется groupby по `cr_bin` и `rating_idx` с суммированием `base_salary`.\n",
    "- Результат заполняет соответствующие ячейки матрицы.\n",
    "\n",
    "**Преимущества:**\n",
    "- Один проход по данным (O(N))\n",
    "- Без вложенных циклов\n",
    "- Векторные операции + groupby\n",
    "- ~100–500× быстрее на больших данных\n",
    "\n",
    "**Интерпретация результата:**\n",
    "- `mat[i, j]` = общая сумма base_salary сотрудников с CR bin `i` и rating `j`\n",
    "- `0` в ячейке означает отсутствие сотрудников в этой комбинации\n",
    "\n",
    "---\n",
    "\n",
    "### Zero Support Mask\n",
    "\n",
    "**compute_zero_support_mask():**\n",
    "- Находит ячейки, где зарплата равна 0 во всех сценариях.\n",
    "- Такие ячейки можно зафиксировать в 0%, так как они не влияют на бюджет.\n",
    "\n",
    "**combined_zero_mask = zero_support_mask OR STRICT_ZERO_MASK**\n",
    "- Объединяет:\n",
    "  - нули, основанные на данных (нет сотрудников),\n",
    "  - принудительные нули от пользователя.\n",
    "- Применяется ко всем матрицам для консистентности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d452639-e5fd-46a4-afb7-23e194948879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# SCENARIO GENERATION\n",
    "# ======================\n",
    "\n",
    "def generate_rating_scenarios(df: pd.DataFrame, num_scenarios: int, \n",
    "                             include_stress: bool = True) -> List[np.ndarray]:\n",
    "    \"\"\"Generate Monte Carlo rating scenarios\"\"\"\n",
    "    rng = np.random.default_rng(SEED_SCENARIOS)\n",
    "    scenarios = []\n",
    "    \n",
    "    if include_stress:\n",
    "        for dist in STRESS_SCENARIOS.values():\n",
    "            S = create_salary_matrix(df, dist, rng)\n",
    "            scenarios.append(S)\n",
    "    \n",
    "    remaining = max(0, num_scenarios - len(scenarios))\n",
    "    base_probs = np.array([TARGET_RATING_DISTRIBUTION[r] for r in sorted(RATING_ORDER)])\n",
    "    \n",
    "    for _ in range(remaining):\n",
    "        perturbed = dirichlet_sample_from_target(base_probs, SCENARIO_CONCENTRATION, rng)\n",
    "        perturbed_dist = {r: p for r, p in zip(sorted(RATING_ORDER), perturbed)}\n",
    "        S = create_salary_matrix(df, perturbed_dist, rng)\n",
    "        scenarios.append(S)\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "\n",
    "def create_salary_matrix(df: pd.DataFrame, rating_dist: Dict, rng) -> np.ndarray:\n",
    "    \"\"\"Create salary matrix for a specific rating distribution (optimized with groupby)\"\"\"\n",
    "    df_temp = df.copy()\n",
    "    df_temp['rating'] = rng.choice(\n",
    "        RATING_ORDER,\n",
    "        size=len(df_temp),\n",
    "        p=[rating_dist[r] for r in sorted(RATING_ORDER)]\n",
    "    )\n",
    "    rating_to_idx = {r: i for i, r in enumerate(sorted(RATING_ORDER))}\n",
    "    df_temp['rating_idx'] = df_temp['rating'].map(rating_to_idx)\n",
    "    \n",
    "    # Fast aggregate using groupby (O(N) instead of O(N*I*J))\n",
    "    agg = (df_temp\n",
    "           .groupby(['cr_bin', 'rating_idx'], as_index=False)['base_salary']\n",
    "           .sum())\n",
    "    \n",
    "    mat = np.zeros((NUM_CR_BINS, NUM_RATINGS))\n",
    "    mat[agg['cr_bin'].values, agg['rating_idx'].values] = agg['base_salary'].values\n",
    "    \n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0d2d6-9e05-408e-bc4d-03426f0240c5",
   "metadata": {},
   "source": [
    "## Оценка пригодности (Fitness Evaluation) — векторизованное скорингование\n",
    "\n",
    "### evaluate_fitness()\n",
    "\n",
    "**Назначение:**  \n",
    "Оценить качество (fitness) матрицы повышений, протестировав её на множестве сценариев зарплат в векторизованном виде (быстро и без циклов).\n",
    "\n",
    "**Ключевая оптимизация:**  \n",
    "Все сценарии заранее объединены в один 3D-массив. Это позволяет вычислять итоговую стоимость для всех сценариев одной векторной операцией (без K отдельных циклов), что радикально ускоряет работу.\n",
    "\n",
    "**Вход:**\n",
    "- Матрица повышений\n",
    "- Набор salary-матриц по сценариям\n",
    "- Целевой бюджет (merit_pool)\n",
    "- Нижняя и верхняя границы допустимого отклонения бюджета (асимметричные)\n",
    "\n",
    "**Выход:**\n",
    "- total_fitness — итоговый скоринг\n",
    "- budget_score — точность попадания в бюджет\n",
    "- constraint_score — соблюдение ограничений\n",
    "- success_rate — % сценариев внутри допустимого бюджета\n",
    "- mean_deviation — среднее отклонение от бюджета\n",
    "\n",
    "---\n",
    "\n",
    "## Компоненты Fitness\n",
    "\n",
    "### 1. Budget Score (учет асимметричного бюджета)\n",
    "\n",
    "Для каждого сценария вычисляется отклонение от целевого бюджета в процентах и проверяется, лежит ли оно в допустимом диапазоне.  \n",
    "Затем применяется асимметричная штрафная функция:\n",
    "- перерасход наказывается сильнее, чем недорасход (если так задано),\n",
    "- внутри диапазона штраф = 0,\n",
    "- вне диапазона штраф растет пропорционально величине нарушения.\n",
    "\n",
    "Далее штрафы усредняются, и итоговый `budget_score` рассчитывается по формуле:\n",
    "\n",
    "**1 / (1 + 20 × средний штраф)**  \n",
    "→ от 1 (идеально) до 0 (очень плохо)\n",
    "\n",
    "### 2. Constraint Score (структурные ограничения)\n",
    "\n",
    "Проверяются все заложенные ограничения. Каждое нарушение добавляет штраф с разным весом.\n",
    "\n",
    "Типы ограничений:\n",
    "- **Строгие нули** — ячейки, которые должны быть = 0. Любое отклонение штрафуется максимально.\n",
    "- **Anchor cells** — фиксированные значения (например, лучшие и худшие ячейки). Любое отклонение = огромный штраф.\n",
    "- **Монотонность по рейтингам (горизонталь)** — значения должны расти слева направо.\n",
    "- **Монотонность по CR (вертикаль)** — значения должны уменьшаться сверху вниз.\n",
    "- **Границы ячеек** — не ниже минимума и не выше максимума.\n",
    "- **Шаги по рейтингам и CR** — между соседними ячейками шаг должен быть не слишком маленьким и не слишком большим.\n",
    "\n",
    "После суммирования штрафов итоговый `constraint_score` =  \n",
    "**1 / (1 + total_penalty)**\n",
    "\n",
    "### 3. Differentiation Score (видимая дифференциация)\n",
    "\n",
    "Матрица должна создавать **заметную разницу** между низкой и высокой эффективностью.\n",
    "\n",
    "Логика:\n",
    "- Для каждой строки считаются средние положительные шаги между рейтингами.\n",
    "- Хорошо, если шаги **чуть выше минимума**, но **не слишком большие** (избегаем резких скачков).\n",
    "- Нижние CR (основная масса сотрудников) получают больший вес.\n",
    "\n",
    "Результат: значение от 0 до 1 (чем выше — тем лучше дифференциация).\n",
    "\n",
    "### 4. Итоговый Fitness\n",
    "\n",
    "Финальный скоринг — это **взвешенная сумма всех трёх компонентов**:\n",
    "\n",
    "- Бюджет (основной вес, обычно ~70%)\n",
    "- Ограничения (важность структуры, ~30%)\n",
    "- Дифференциация (дополнительный бонус, если включен DIFF_WEIGHT)\n",
    "\n",
    "Такой подход обеспечивает баланс между:\n",
    "- точностью соблюдения бюджета,\n",
    "- корректной структурой матрицы,\n",
    "- видимой разницей между уровнями производительности.\n",
    "\n",
    "**Итог:** fitness ∈ [0, 1]  \n",
    "Чем ближе к 1 — тем лучше решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe65c4-4b98-40f9-8c45-14f88fb2e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# FITNESS EVALUATION\n",
    "# ======================\n",
    "\n",
    "def compute_zero_support_mask(scenarios: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Identify cells with zero payroll across all scenarios\"\"\"\n",
    "    S_stack = np.stack(scenarios)\n",
    "    return (np.abs(S_stack) <= 1e-12).all(axis=0)\n",
    "\n",
    "\n",
    "def evaluate_fitness(matrix: np.ndarray, S_stack: np.ndarray, \n",
    "                    merit_pool: float, budget_tol_lower: float, budget_tol_upper: float) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Vectorized fitness evaluation across pre-stacked scenarios\n",
    "    \n",
    "    Args:\n",
    "        matrix: Merit increase matrix [I, J]\n",
    "        S_stack: Pre-stacked salary matrices [K, I, J]\n",
    "        merit_pool: Target budget\n",
    "        budget_tol_lower: Lower tolerance (underspend allowed)\n",
    "        budget_tol_upper: Upper tolerance (overspend allowed)\n",
    "    \n",
    "    Returns: (total_fitness, budget_score, constraint_score, success_rate, mean_deviation)\n",
    "    \"\"\"\n",
    "    # Vectorized cost computation\n",
    "    costs = (S_stack * matrix).sum(axis=(1, 2))\n",
    "    deviations = (costs - merit_pool) / merit_pool  # Keep sign for asymmetric check\n",
    "    \n",
    "    # Asymmetric budget check: -lower_tol <= deviation <= +upper_tol\n",
    "    within_budget = ((deviations >= -budget_tol_lower) & (deviations <= budget_tol_upper)).sum()\n",
    "    success_rate = within_budget / len(S_stack)\n",
    "    mean_deviation = np.abs(deviations).mean()  # For reporting only\n",
    "    \n",
    "    # Asymmetric band-aware budget score (zero penalty inside band, scaled outside)\n",
    "    def _band_penalty(dev, low, up):\n",
    "        \"\"\"Calculate penalty for deviation outside allowed band\"\"\"\n",
    "        if dev < -low:   # underspend beyond allowed\n",
    "            return (-dev - low) / max(low, 1e-9)\n",
    "        if dev > up:     # overspend beyond allowed\n",
    "            return (dev - up) / max(up, 1e-9)\n",
    "        return 0.0       # inside band → no penalty\n",
    "    \n",
    "    penalties = np.array([_band_penalty(d, budget_tol_lower, budget_tol_upper) for d in deviations])\n",
    "    mean_penalty = penalties.mean()\n",
    "    budget_score = 1.0 / (1.0 + 20.0 * mean_penalty)\n",
    "    \n",
    "    constraint_score = evaluate_constraints(matrix)\n",
    "    \n",
    "    # Reward visible rating differentiation (robust slope) alongside budget & constraints\n",
    "    diff_sc = differentiation_score(matrix)\n",
    "\n",
    "    total_fitness = (\n",
    "        FITNESS_WEIGHTS['budget'] * budget_score +\n",
    "        FITNESS_WEIGHTS['constraints'] * constraint_score +\n",
    "        DIFF_WEIGHT * diff_sc\n",
    "    )\n",
    "\n",
    "    return total_fitness, budget_score, constraint_score, success_rate, mean_deviation\n",
    "\n",
    "\n",
    "def evaluate_constraints(matrix: np.ndarray) -> float:\n",
    "    \"\"\"Evaluate constraint satisfaction with strict zero and anchor cell enforcement\"\"\"\n",
    "    penalties = []\n",
    "    I, J = matrix.shape\n",
    "    \n",
    "    # Small epsilon for floating point comparison\n",
    "    EPS = 1e-9\n",
    "    \n",
    "    # Get anchor cells and precompute positions\n",
    "    anchors = get_anchor_cells()\n",
    "    anchor_positions = {(i, j) for _, (i, j, _) in anchors.items()}\n",
    "    \n",
    "    # CRITICAL: Heavily penalize violations of strict zero cells\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if STRICT_ZERO_MASK[i, j] and abs(matrix[i, j]) > EPS:\n",
    "                penalties.append(abs(matrix[i, j]) * 1000)  # Massive penalty\n",
    "    \n",
    "    # CRITICAL: Heavily penalize deviations from anchor cells\n",
    "    for anchor_type, (i, j, target_value) in anchors.items():\n",
    "        if abs(matrix[i, j] - target_value) > EPS:\n",
    "            penalties.append(abs(matrix[i, j] - target_value) * 1000)  # Massive penalty\n",
    "    \n",
    "    # Monotonicity violations (rating increases)\n",
    "    for i in range(I):\n",
    "        for j in range(J - 1):\n",
    "            # Skip monotonicity check across forced zeros\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i, j+1]:\n",
    "                continue\n",
    "            if matrix[i, j+1] < matrix[i, j]:\n",
    "                penalties.append((matrix[i, j] - matrix[i, j+1]) * 10)\n",
    "    \n",
    "    # Monotonicity violations (CR decreases)\n",
    "    for i in range(I - 1):\n",
    "        for j in range(J):\n",
    "            # Skip monotonicity check across forced zeros\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i+1, j]:\n",
    "                continue\n",
    "            if matrix[i+1, j] > matrix[i, j]:\n",
    "                penalties.append((matrix[i+1, j] - matrix[i, j]) * 10)\n",
    "    \n",
    "    # Cell bounds\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if STRICT_ZERO_MASK[i, j]:\n",
    "                continue  # Skip bound checks for forced zeros\n",
    "            # Skip bound checks for anchor cells (they have exact values)\n",
    "            if (i, j) in anchor_positions:\n",
    "                continue\n",
    "            if matrix[i, j] < CONSTRAINTS['cell_min']:\n",
    "                penalties.append((CONSTRAINTS['cell_min'] - matrix[i, j]) * 20)\n",
    "            if matrix[i, j] > CONSTRAINTS['cell_max']:\n",
    "                penalties.append((matrix[i, j] - CONSTRAINTS['cell_max']) * 20)\n",
    "    \n",
    "    # Rating step violations\n",
    "    for i in range(I):\n",
    "        for j in range(J - 1):\n",
    "            # Skip step check across forced zeros\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i, j+1]:\n",
    "                continue\n",
    "            step = matrix[i, j+1] - matrix[i, j]\n",
    "            if step < CONSTRAINTS['min_step_rating']:\n",
    "                penalties.append((CONSTRAINTS['min_step_rating'] - step) * 5)\n",
    "            if step > CONSTRAINTS['step_max_rating']:\n",
    "                penalties.append((step - CONSTRAINTS['step_max_rating']) * 5)\n",
    "    \n",
    "    # CR step violations\n",
    "    for i in range(I - 1):\n",
    "        for j in range(J):\n",
    "            # Skip step check across forced zeros\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i+1, j]:\n",
    "                continue\n",
    "            step = matrix[i, j] - matrix[i+1, j]\n",
    "            if step < CONSTRAINTS['min_step_cr']:\n",
    "                penalties.append((CONSTRAINTS['min_step_cr'] - step) * 5)\n",
    "            if step > CONSTRAINTS['step_max_cr']:\n",
    "                penalties.append((step - CONSTRAINTS['step_max_cr']) * 5)\n",
    "    \n",
    "    total_penalty = sum(penalties)\n",
    "    score = 1.0 / (1.0 + total_penalty)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def differentiation_score(matrix: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Reward steeper (but reasonable) increases across ratings per CR row.\n",
    "    Returns 0..1 where higher means more visible, well-behaved differentiation.\n",
    "    Design:\n",
    "      - Uses average positive step across ratings (skip forced zeros).\n",
    "      - Targets slightly above min_step_rating; caps to avoid spikes.\n",
    "      - Weights lower-CR rows a bit more (visibility to core population).\n",
    "    \"\"\"\n",
    "    I, J = matrix.shape\n",
    "    per_row_scores = []\n",
    "\n",
    "    for i in range(I):\n",
    "        steps = []\n",
    "        for j in range(J - 1):\n",
    "            # skip around forced zeros (they break smoothness by design)\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i, j + 1]:\n",
    "                continue\n",
    "            step = matrix[i, j + 1] - matrix[i, j]\n",
    "            steps.append(max(step, 0.0))  # only reward upward steps\n",
    "\n",
    "        if not steps:\n",
    "            per_row_scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        mean_step = float(np.mean(steps))\n",
    "\n",
    "        # Gentle target and cap:\n",
    "        target = CONSTRAINTS['min_step_rating'] * 1.15  # ask a bit more than minimum\n",
    "        cap    = CONSTRAINTS['step_max_rating'] * 0.5   # avoid spiky rows\n",
    "\n",
    "        # Normalize: 0 at 0 step; ~1 when at/above target (clipped by cap)\n",
    "        norm = min(mean_step, cap) / max(target, 1e-9)\n",
    "        per_row_scores.append(max(0.0, min(1.0, norm)))\n",
    "\n",
    "    # Slightly favor low-CR rows (more visible to business)\n",
    "    # Row 0 weight=1.0 → last row ~0.6\n",
    "    if I > 1:\n",
    "        weights = np.linspace(1.0, 0.6, I)\n",
    "        score = float(np.average(per_row_scores, weights=weights))\n",
    "    else:\n",
    "        score = float(np.mean(per_row_scores))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22c3c8-7c1e-4578-876e-6a3f99060d63",
   "metadata": {},
   "source": [
    "## Генетические операторы — механика эволюции\n",
    "\n",
    "### 1. Инициализация популяции\n",
    "\n",
    "**Стратегия:** комбинировать разные типы матриц, чтобы сразу получить разнообразие и избегать тупиков.\n",
    "\n",
    "- ~70% — структурированные матрицы (гладкие, соблюдают ограничения)\n",
    "- ~30% — структурированные, но с агрессивными нулями (исследуют политики «zero merit»)\n",
    "\n",
    "**Почему так:**\n",
    "- Полностью случайные матрицы → почти всегда нарушают ограничения и только тратят время\n",
    "- Только структурированные → высокий риск застрять в локальном оптимуме\n",
    "- Смешанный подход → баланс между исследованием (exploration) и улучшением (exploitation)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Создание структурированных матриц\n",
    "\n",
    "**Логика построения:**\n",
    "1. Начать с лучшей ячейки (низкий CR, высокий рейтинг).\n",
    "   - Если задан anchor — использовать его.\n",
    "   - Иначе взять случайное значение в верхнем диапазоне.\n",
    "2. Заполнить верхнюю строку слева направо, постепенно уменьшая значения.\n",
    "3. Заполнить остальные строки сверху вниз, также уменьшая значения.\n",
    "4. Привести значения к допустимым границам, округлить и применить фиксированные ячейки.\n",
    "\n",
    "**Почему это работает:**\n",
    "- Начинаем с максимального значения для лучших сотрудников.\n",
    "- Плавное и монотонное снижение даёт реалистичную форму.\n",
    "- Случайные шаги обеспечивают разнообразие.\n",
    "\n",
    "**Вариант с нулями:**\n",
    "- Использует ту же логику,\n",
    "- но дополнительно «приглушает» низкие рейтинги в высоких CR-бинах (например, 40% шанс обнулить).\n",
    "- Это исследует сценарии, где слабые исполнители получают 0%.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Селекция (выбор родителей)\n",
    "\n",
    "Используется **tournament selection**:\n",
    "- Берём k случайных кандидатов,\n",
    "- Выбираем лучшего из них.\n",
    "\n",
    "**Плюсы:**\n",
    "- Простая и быстрая стратегия,\n",
    "- Управляемое давление (чем больше k — тем агрессивнее отбор),\n",
    "- Сохраняет разнообразие, если k небольшое.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Кроссовер (смешивание родителей)\n",
    "\n",
    "**Принцип:** смешивание (blend), а не жесткое переключение.\n",
    "\n",
    "- Потомок = взвешенная комбинация двух родителей.\n",
    "- Это сохраняет форму обеих матриц и создаёт плавный результат.\n",
    "\n",
    "**Дополнительная обработка потомка:**\n",
    "- Сглаживание (убрать шум),\n",
    "- Округление (для читаемости),\n",
    "- Применение фиксированных ячеек (нельзя ломать нули или anchor’ы).\n",
    "\n",
    "**Почему смешивание лучше:**\n",
    "- Матрица — непрерывное пространство,\n",
    "- blend даёт реалистичную структуру,\n",
    "- дискретное наследование дало бы «ломаные» и хаотичные матрицы.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Мутация\n",
    "\n",
    "Вносит небольшие случайные изменения в ячейки.\n",
    "\n",
    "**Как работает:**\n",
    "- С вероятностью `mutation_rate` ячейка слегка изменяется (маленький Gaussian шум).\n",
    "- Никогда не изменяются:\n",
    "  - принудительные нули,\n",
    "  - anchor-ячейки.\n",
    "\n",
    "**После мутации:** всегда выполняется восстановление структуры (repair), чтобы не нарушать ограничения.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Repair (восстановление структуры)\n",
    "\n",
    "Исправляет нарушения после мутации или кроссовера.\n",
    "\n",
    "**Шаги восстановления:**\n",
    "1. Ограничить значения по минимальному/максимальному порогу.\n",
    "2. Обеспечить рост по рейтингам (слева направо).\n",
    "3. Обеспечить спад по CR (сверху вниз).\n",
    "4. Снова ограничить значения (если вышли за границы).\n",
    "5. Округлить и вернуть фиксированные ячейки в исходное состояние.\n",
    "\n",
    "**Важно:**  \n",
    "Проверки не выполняются через ячейки с принудительными нулями, так как они создают «разрывы» по дизайну.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Smoothing (сглаживание)\n",
    "\n",
    "- Убирает шум и резкие скачки,\n",
    "- Делает матрицу визуально и бизнес-логически приятнее,\n",
    "- Небольшое сглаживание (σ ≈ 0.5) сохраняет форму, но делает её более плавной.\n",
    "\n",
    "**Баланс:**\n",
    "- Слишком сильное сглаживание → потеря дифференциации,\n",
    "- Слишком слабое → много шума,\n",
    "- Подобран оптимальный уровень.\n",
    "\n",
    "---\n",
    "\n",
    "## Локальная донастройка (Local Refinement)\n",
    "\n",
    "### local_refinement()\n",
    "\n",
    "**Назначение:**  \n",
    "Дополировать лучшие матрицы после работы генетического алгоритма с помощью градиентного оптимизатора.\n",
    "\n",
    "**Когда применяется:**\n",
    "- Только к топ-5 кандидатов (чтобы не тратить время на слабые решения),\n",
    "- После завершения GA,\n",
    "- Используется небольшой набор сценариев (например, 100) для ускорения.\n",
    "\n",
    "**Метод:** L-BFGS-B  \n",
    "Почему:\n",
    "- Поддерживает границы для каждой ячейки,\n",
    "- Эффективен для больших задач,\n",
    "- Быстро сходится,\n",
    "- Не требует явного градиента (вычисляется численно).\n",
    "\n",
    "**Что происходит с матрицей внутри оптимизации:**\n",
    "- При каждом шаге матрица ремонтируется (repair),\n",
    "- Применяются фиксированные ячейки (anchor и strict zeros),\n",
    "- Вычисляется fitness,\n",
    "- Оптимизатор пытается максимизировать fitness (минимизируя его отрицание).\n",
    "\n",
    "**Ограничения:**\n",
    "- Принудительные нули → ячейка закреплена в 0,\n",
    "- Anchor ячейки → фиксированы на заданных значениях,\n",
    "- Остальные — в пределах `cell_min`/`cell_max`.\n",
    "\n",
    "**Безопасность:**\n",
    "- Максимум 100 итераций,\n",
    "- Если улучшения нет или оптимизация не удалась — оставляется исходная матрица.\n",
    "\n",
    "**Плюсы:**\n",
    "- Может улучшить fitness ещё на 0.5–2%,\n",
    "- Убирает мелкие артефакты после GA,\n",
    "- Извлекает максимум из найденной структуры.\n",
    "\n",
    "**Минусы:**\n",
    "- Дорого по времени,\n",
    "- Может переобучиться, если применять к слабым решениям.\n",
    "\n",
    "**Компромисс (идеальный):**\n",
    "- Применять только к лучшим кандидатам,\n",
    "- Использовать ограниченное число сценариев,\n",
    "- Сохранять исходную матрицу, если оптимизация не улучшила результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4142e4-de15-4214-9159-69308618b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# GENETIC OPERATORS\n",
    "# ======================\n",
    "\n",
    "def initialize_population(pop_size: int, rng) -> List[np.ndarray]:\n",
    "    \"\"\"Initialize population with structured matrices\"\"\"\n",
    "    population = []\n",
    "    num_with_zeros = int(pop_size * 0.3) if CONSTRAINTS['cell_min'] == 0 else 0\n",
    "\n",
    "    for i in range(pop_size):\n",
    "        if i < num_with_zeros:\n",
    "            matrix = create_structured_matrix_with_zeros(rng)\n",
    "        else:\n",
    "            matrix = create_structured_matrix(rng)\n",
    "        matrix = enforce_all_fixed_cells(matrix)  # Apply all fixed cell constraints\n",
    "        population.append(matrix)\n",
    "    return population\n",
    "\n",
    "\n",
    "def create_structured_matrix(rng) -> np.ndarray:\n",
    "    \"\"\"Create a matrix that approximately respects structure\"\"\"\n",
    "    I, J = NUM_CR_BINS, NUM_RATINGS\n",
    "    matrix = np.zeros((I, J))\n",
    "    \n",
    "    # Start from best performer cell (lowest CR, highest rating)\n",
    "    anchors = get_anchor_cells()\n",
    "    if 'max' in anchors:\n",
    "        _, _, value = anchors['max']\n",
    "        matrix[0, J-1] = value  # Use exact anchor value\n",
    "    else:\n",
    "        matrix[0, J-1] = rng.uniform(CONSTRAINTS['cell_max'] * 0.6, CONSTRAINTS['cell_max'])\n",
    "    \n",
    "    # Fill top row (lowest CR bin) from right to left\n",
    "    for j in range(J-2, -1, -1):\n",
    "        step = rng.uniform(CONSTRAINTS['min_step_rating'], CONSTRAINTS['step_max_rating'])\n",
    "        matrix[0, j] = max(CONSTRAINTS['cell_min'], matrix[0, j+1] - step)\n",
    "    \n",
    "    # Fill down columns (higher CR bins)\n",
    "    for i in range(1, I):\n",
    "        for j in range(J):\n",
    "            step = rng.uniform(CONSTRAINTS['min_step_cr'], CONSTRAINTS['step_max_cr'])\n",
    "            matrix[i, j] = max(CONSTRAINTS['cell_min'], matrix[i-1, j] - step)\n",
    "    \n",
    "    matrix = np.clip(matrix, CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])\n",
    "    matrix = round_matrix(matrix)\n",
    "    matrix = enforce_all_fixed_cells(matrix)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def create_structured_matrix_with_zeros(rng) -> np.ndarray:\n",
    "    \"\"\"Create matrix with strategic zeros\"\"\"\n",
    "    I, J = NUM_CR_BINS, NUM_RATINGS\n",
    "    matrix = np.zeros((I, J))\n",
    "    \n",
    "    # Start from best performer cell (lowest CR, highest rating)\n",
    "    anchors = get_anchor_cells()\n",
    "    if 'max' in anchors:\n",
    "        _, _, value = anchors['max']\n",
    "        matrix[0, J-1] = value  # Use exact anchor value\n",
    "    else:\n",
    "        matrix[0, J-1] = rng.uniform(CONSTRAINTS['cell_max'] * 0.6, CONSTRAINTS['cell_max'])\n",
    "    \n",
    "    # Fill top row (lowest CR bin) from right to left\n",
    "    for j in range(J-2, -1, -1):\n",
    "        step = rng.uniform(CONSTRAINTS['min_step_rating'], CONSTRAINTS['step_max_rating'])\n",
    "        matrix[0, j] = max(CONSTRAINTS['cell_min'], matrix[0, j+1] - step)\n",
    "    \n",
    "    # Fill down each column (higher CR bins)\n",
    "    for i in range(1, I):\n",
    "        for j in range(J):\n",
    "            step = rng.uniform(CONSTRAINTS['min_step_cr'], CONSTRAINTS['step_max_cr'])\n",
    "            matrix[i, j] = max(CONSTRAINTS['cell_min'], matrix[i-1, j] - step)\n",
    "            \n",
    "            # Aggressively push lowest performers at highest CR toward zero\n",
    "            if i >= I - 2 and j <= 1:\n",
    "                if rng.random() < 0.4:\n",
    "                    matrix[i, j] = 0.0\n",
    "    \n",
    "    matrix = np.clip(matrix, CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])\n",
    "    matrix = round_matrix(matrix)\n",
    "    matrix = enforce_all_fixed_cells(matrix)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def tournament_selection(population: List[MatrixCandidate], k: int, rng) -> MatrixCandidate:\n",
    "    \"\"\"Select best from k random candidates\"\"\"\n",
    "    k = min(k, len(population))\n",
    "    indices = rng.choice(len(population), k, replace=True)\n",
    "    tournament = [population[i] for i in indices]\n",
    "    return max(tournament, key=lambda x: x.fitness)\n",
    "\n",
    "\n",
    "def crossover(parent1: np.ndarray, parent2: np.ndarray, rng) -> np.ndarray:\n",
    "    \"\"\"Smart crossover that blends matrices\"\"\"\n",
    "    alpha = rng.uniform(0.3, 0.7)\n",
    "    child = alpha * parent1 + (1 - alpha) * parent2\n",
    "    child = smooth_matrix(child)\n",
    "    child = round_matrix(child)\n",
    "    child = enforce_all_fixed_cells(child)\n",
    "    return child\n",
    "\n",
    "\n",
    "def mutate(matrix: np.ndarray, mutation_rate: float, rng) -> np.ndarray:\n",
    "    \"\"\"Structure-aware mutation that preserves fixed cells\"\"\"\n",
    "    I, J = matrix.shape\n",
    "    mutated = matrix.copy()\n",
    "    \n",
    "    # Get anchor cell positions\n",
    "    anchors = get_anchor_cells()\n",
    "    anchor_positions = {(i, j) for _, (i, j, _) in anchors.items()}\n",
    "    \n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            # Never mutate forced zeros or anchor cells\n",
    "            if STRICT_ZERO_MASK[i, j] or (i, j) in anchor_positions:\n",
    "                continue\n",
    "            if rng.random() < mutation_rate:\n",
    "                delta = rng.normal(0, CONSTRAINTS['cell_max'] * 0.05)\n",
    "                mutated[i, j] += delta\n",
    "    \n",
    "    mutated = repair_matrix(mutated)\n",
    "    mutated = round_matrix(mutated)\n",
    "    mutated = enforce_all_fixed_cells(mutated)\n",
    "    \n",
    "    return mutated\n",
    "\n",
    "\n",
    "def smooth_matrix(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply smoothing to reduce noise\"\"\"\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    smoothed = gaussian_filter(matrix, sigma=0.5, mode='nearest')\n",
    "    smoothed = np.clip(smoothed, CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])\n",
    "    smoothed = enforce_all_fixed_cells(smoothed)\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def repair_matrix(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Repair matrix to satisfy monotonicity\"\"\"\n",
    "    I, J = matrix.shape\n",
    "    repaired = matrix.copy()\n",
    "    \n",
    "    repaired = np.clip(repaired, CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])\n",
    "    \n",
    "    # Enforce rating monotonicity\n",
    "    for i in range(I):\n",
    "        for j in range(1, J):\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i, j-1]:\n",
    "                continue  # Don't repair around forced zeros\n",
    "            if repaired[i, j] < repaired[i, j-1]:\n",
    "                if repaired[i, j-1] > CONSTRAINTS['cell_min']:\n",
    "                    repaired[i, j] = repaired[i, j-1] + CONSTRAINTS['min_step_rating'] * 0.5\n",
    "                else:\n",
    "                    repaired[i, j] = CONSTRAINTS['cell_min']\n",
    "    \n",
    "    # Enforce CR monotonicity\n",
    "    for i in range(1, I):\n",
    "        for j in range(J):\n",
    "            if STRICT_ZERO_MASK[i, j] or STRICT_ZERO_MASK[i-1, j]:\n",
    "                continue  # Don't repair around forced zeros\n",
    "            if repaired[i, j] > repaired[i-1, j]:\n",
    "                new_val = repaired[i-1, j] - CONSTRAINTS['min_step_cr'] * 0.5\n",
    "                repaired[i, j] = max(CONSTRAINTS['cell_min'], new_val)\n",
    "    \n",
    "    repaired = np.clip(repaired, CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])\n",
    "    repaired = round_matrix(repaired)\n",
    "    repaired = enforce_all_fixed_cells(repaired)\n",
    "    \n",
    "    return repaired\n",
    "\n",
    "\n",
    "# ======================\n",
    "# LOCAL REFINEMENT\n",
    "# ======================\n",
    "\n",
    "def local_refinement(matrix: np.ndarray, S_stack: np.ndarray, \n",
    "                    merit_pool: float, budget_tol_lower: float, budget_tol_upper: float) -> np.ndarray:\n",
    "    \"\"\"Apply local optimization with fixed cell constraints\"\"\"\n",
    "    \n",
    "    def objective(x):\n",
    "        mat = repair_matrix(x.reshape(NUM_CR_BINS, NUM_RATINGS))\n",
    "        mat = enforce_all_fixed_cells(mat)\n",
    "        fitness, _, _, _, _ = evaluate_fitness(mat, S_stack, merit_pool, budget_tol_lower, budget_tol_upper)\n",
    "        return -fitness\n",
    "    \n",
    "    x0 = matrix.flatten()\n",
    "    bounds = [(CONSTRAINTS['cell_min'], CONSTRAINTS['cell_max'])] * len(x0)\n",
    "    \n",
    "    # Override bounds for forced zero cells\n",
    "    for i in range(NUM_CR_BINS):\n",
    "        for j in range(NUM_RATINGS):\n",
    "            idx = i * NUM_RATINGS + j\n",
    "            if STRICT_ZERO_MASK[i, j]:\n",
    "                bounds[idx] = (0.0, 0.0)  # Force to stay at 0\n",
    "    \n",
    "    # Override bounds for anchor cells\n",
    "    anchors = get_anchor_cells()\n",
    "    for _, (i, j, value) in anchors.items():\n",
    "        idx = i * NUM_RATINGS + j\n",
    "        bounds[idx] = (value, value)  # Force to stay at exact value\n",
    "    \n",
    "    result = minimize(objective, x0, method='L-BFGS-B', bounds=bounds,\n",
    "                     options={'maxiter': 100, 'disp': False})\n",
    "    \n",
    "    if result.success:\n",
    "        refined = result.x.reshape(NUM_CR_BINS, NUM_RATINGS)\n",
    "        refined = repair_matrix(refined)\n",
    "        refined = enforce_all_fixed_cells(refined)\n",
    "        return refined\n",
    "    \n",
    "    return enforce_all_fixed_cells(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006654a-af41-4906-b88a-c139e238079e",
   "metadata": {},
   "source": [
    "## Основной цикл генетического алгоритма (Main Genetic Algorithm Loop)\n",
    "\n",
    "### run_genetic_algorithm()\n",
    "\n",
    "**Главная функция**, которая координирует весь эволюционный процесс: от подготовки данных до формирования финального набора лучших матриц.\n",
    "\n",
    "---\n",
    "\n",
    "## Фаза 1: Подготовка и инициализация\n",
    "\n",
    "### 1.1. Генерация сценариев (Quick Eval)\n",
    "Создаются сценарии распределения рейтингов (обычно ~2000), включая стресс-сценарии.  \n",
    "Они используются для быстрой оценки во время эволюции, чтобы не тратить время на полный набор (10k+).\n",
    "\n",
    "### 1.2. Вычисление Zero Mask\n",
    "Определяются ячейки, в которых **во всех сценариях** зарплата равна 0.  \n",
    "Эти ячейки объединяются с **принудительными нулями** (STRICT_ZERO_MASK), формируя `combined_zero_mask`.\n",
    "\n",
    "### 1.3. Анализ фиксированных ячеек\n",
    "Система сообщает пользователю:\n",
    "- Сколько ячеек принудительно зафиксировано (нули + anchor).\n",
    "- Есть ли конфликт: anchor ячейка, но в данных там нет сотрудников.\n",
    "Это добавляет прозрачность и предупреждает о потенциальных проблемах.\n",
    "\n",
    "### 1.4. Инициализация популяции\n",
    "Создаётся начальный набор матриц по стратегии «структурированные + с нулями».  \n",
    "К каждой матрице сразу применяется `combined_zero_mask` и все фиксированные ячейки.\n",
    "\n",
    "### 1.5. Первая оценка fitness\n",
    "Каждая матрица превращается в объект `MatrixCandidate`  \n",
    "(содержит матрицу + все метрики fitness).  \n",
    "Расчитываются:\n",
    "- fitness,\n",
    "- budget_score,\n",
    "- constraint_score,\n",
    "- success_rate,\n",
    "- mean_deviation.\n",
    "\n",
    "---\n",
    "\n",
    "## Фаза 2: Эволюционный цикл\n",
    "\n",
    "Алгоритм повторяет поколения, пока не достигнет лимита или не сойдётся.\n",
    "\n",
    "В каждом поколении выполняется:\n",
    "\n",
    "### 1. Сортировка по fitness (лучшие — сверху)\n",
    "Позволяет отслеживать прогресс и выбирать элиту.\n",
    "\n",
    "### 2. Проверка сходимости (convergence)\n",
    "Если улучшение fitness меньше порога в течение нескольких поколений подряд → досрочно остановиться (экономия времени).\n",
    "\n",
    "### 3. Вывод прогресса\n",
    "Каждые N поколений выводится лучший fitness, success rate и отклонения бюджета.\n",
    "\n",
    "### 4. Формирование следующего поколения\n",
    "Создаётся пустой список будущей популяции.\n",
    "\n",
    "### 5. Элитизм\n",
    "Лучшие `elite_size` решений копируются **без изменений**.  \n",
    "Это гарантирует, что хорошие решения не потеряются.\n",
    "\n",
    "### 6. Создание потомков (offspring)\n",
    "Пока популяция нового поколения не заполнена:\n",
    "- **Выбор родителей:** tournament selection.\n",
    "- **Кроссовер или копирование:** по вероятности `crossover_rate`.\n",
    "- **Мутация:** случайное изменение отдельных ячеек.\n",
    "- **Санитизация:** исправление NaN/inf, восстановление структуры (repair).\n",
    "- **Применение фиксированных ячеек:** zeros и anchors.\n",
    "- **Оценка fitness:** рассчитываются все компоненты.\n",
    "- **Добавление в популяцию:** offspring сохраняется как MatrixCandidate.\n",
    "\n",
    "### 7. Замена популяции\n",
    "Текущее поколение полностью заменяется новым.\n",
    "\n",
    "---\n",
    "\n",
    "## Ключевые механизмы\n",
    "\n",
    "### Элитизм\n",
    "- Сохраняет лучшие решения.\n",
    "- Ускоряет эволюцию.\n",
    "- Гарантирует, что прогресс не будет потерян.\n",
    "\n",
    "### Обнаружение сходимости\n",
    "- Если улучшений нет — ранняя остановка.\n",
    "- Экономия вычислений.\n",
    "- Обычно сходимость за 50–200 поколений.\n",
    "\n",
    "### Принудительное применение фиксированных ячеек\n",
    "- После **каждой** операции (crossover, mutation, repair).\n",
    "- Нельзя нарушить anchor или strict zeros.\n",
    "- Обеспечивает корректность структуры.\n",
    "\n",
    "### Санитизация\n",
    "- Если в матрице появились NaN или бесконечности → заменяем валидными значениями.\n",
    "- Затем выполняем repair.\n",
    "- Это делает алгоритм устойчивым к числовым артефактам.\n",
    "\n",
    "---\n",
    "\n",
    "## Фаза 3: Финальный вывод\n",
    "\n",
    "После завершения цикла:\n",
    "\n",
    "- Популяция сортируется по fitness.\n",
    "- Возвращаются **топ-N лучших матриц** (обычно 20).\n",
    "- Эти матрицы идут в **full evaluation** (строгий финальный тест).\n",
    "\n",
    "---\n",
    "\n",
    "## Производительность\n",
    "\n",
    "### Временная сложность:\n",
    "- Одно поколение: O(population_size × num_scenarios)\n",
    "- Полная эволюция: O(population_size × num_generations × num_scenarios)\n",
    "- Пример: 1000 × 500 × 2000 = 1 млрд вычислений (но оптимизировано!)\n",
    "\n",
    "### Оптимизации:\n",
    "- Векторизованная fitness-оценка (скорость ×100)\n",
    "- Предварительное объединение сценариев (нет повторного стэкинга)\n",
    "- Ранняя остановка по сходимости\n",
    "- Малый набор сценариев в quick evaluation (2k вместо 10k)\n",
    "\n",
    "### Память:\n",
    "- Хранится только **текущая популяция**, нет истории.\n",
    "- Сценарии создаются один раз и переиспользуются.\n",
    "- Подходит даже для больших популяций.\n",
    "\n",
    "---\n",
    "\n",
    "**Итог:**  \n",
    "`run_genetic_algorithm()` — это «двигатель» оптимизации, который:\n",
    "- создаёт стартовую популяцию,\n",
    "- эволюционирует матрицы,\n",
    "- гарантирует соблюдение всех ограничений,\n",
    "- отслеживает прогресс,\n",
    "- завершает работу при сходимости,\n",
    "- возвращает лучшие решения для финальной проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67923f54-1d5f-4f7e-b4f1-b240ebce8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# GENETIC ALGORITHM\n",
    "# ======================\n",
    "\n",
    "def run_genetic_algorithm(df: pd.DataFrame, merit_pool: float) -> List[MatrixCandidate]:\n",
    "    \"\"\"Main GA loop\"\"\"\n",
    "    rng = np.random.default_rng(SEED_GA)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GENETIC ALGORITHM EVOLUTION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nMatrix: {NUM_CR_BINS} CR bins × {NUM_RATINGS} ratings\")\n",
    "    print(\"Orientation: Rows = CR bins (0=lowest CR), Cols = ratings (1..N)\")\n",
    "    \n",
    "    # Runtime safeguard for large runs\n",
    "    total_evals = GA_CONFIG['population_size'] * GA_CONFIG['num_generations']\n",
    "    if len(df) > 5000 and total_evals > 60_000:\n",
    "        print(f\"\\nLarge run detected ({len(df)} employees, {total_evals:,} evaluations).\")\n",
    "        print(\"Consider reducing population_size or num_generations for faster runtime.\")\n",
    "    \n",
    "    print(f\"\\nGenerating {EVAL_CONFIG['quick_eval_scenarios']} evaluation scenarios...\")\n",
    "    quick_scenarios = generate_rating_scenarios(df, EVAL_CONFIG['quick_eval_scenarios'], True)\n",
    "    S_quick = np.stack(quick_scenarios)\n",
    "    print(f\"Scenarios ready\")\n",
    "    \n",
    "    zero_mask = compute_zero_support_mask(quick_scenarios)\n",
    "    combined_zero_mask = zero_mask | STRICT_ZERO_MASK\n",
    "    \n",
    "    # Get anchor cells for reporting\n",
    "    anchors = get_anchor_cells()\n",
    "    anchor_positions = {(i, j) for _, (i, j, _) in anchors.items()}\n",
    "    \n",
    "    # Warn if anchors overlap with zero-support cells\n",
    "    for anchor_type, (i, j, value) in anchors.items():\n",
    "        if zero_mask[i, j]:\n",
    "            print(f\"Warning: Anchor cell at CR bin {i}, Rating {j+1} has zero payroll in all scenarios\")\n",
    "            print(f\"    Pinning to {value*100:.2f}% will not affect budget since no employees in this cell\")\n",
    "    \n",
    "    num_frozen = combined_zero_mask.sum()\n",
    "    num_anchored = len(anchor_positions)\n",
    "    total_fixed = num_frozen + num_anchored\n",
    "    \n",
    "    if total_fixed > 0:\n",
    "        print(f\"Fixed cells in matrix:\")\n",
    "        if num_frozen > 0:\n",
    "            print(f\"  - Zero cells: {num_frozen} (zero payroll: {zero_mask.sum()}, strict: {STRICT_ZERO_MASK.sum()})\")\n",
    "        if num_anchored > 0:\n",
    "            print(f\"  - Anchor cells: {num_anchored}\")\n",
    "            for anchor_type, (i, j, value) in anchors.items():\n",
    "                print(f\"    • CR bin {i}, Rating {j+1} = {value*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nInitializing population of {GA_CONFIG['population_size']} matrices...\")\n",
    "    population_matrices = initialize_population(GA_CONFIG['population_size'], rng)\n",
    "    \n",
    "    # Apply zero mask to all matrices and re-enforce all fixed cells\n",
    "    for idx, mat in enumerate(population_matrices):\n",
    "        mat[combined_zero_mask] = 0.0\n",
    "        population_matrices[idx] = enforce_all_fixed_cells(mat) \n",
    "    \n",
    "    population = []\n",
    "    for mat in population_matrices:\n",
    "        fitness, budget_sc, constraint_sc, success_rate, mean_dev = evaluate_fitness(\n",
    "            mat, S_quick, merit_pool, BUDGET_TOLERANCE_LOWER, BUDGET_TOLERANCE_UPPER\n",
    "        )\n",
    "        population.append(MatrixCandidate(\n",
    "            matrix=mat, fitness=fitness, budget_score=budget_sc,\n",
    "            constraint_score=constraint_sc, success_rate=success_rate,\n",
    "            mean_deviation=mean_dev, generation=0\n",
    "        ))\n",
    "    \n",
    "    print(f\"Initial population evaluated\")\n",
    "    print(f\"  Best fitness: {max(p.fitness for p in population):.6f}\")\n",
    "    \n",
    "    # Check for low initial success rate\n",
    "    best_initial = max(population, key=lambda x: x.fitness)\n",
    "    if best_initial.success_rate < 0.3:\n",
    "        print(f\"\\nWarning: Low initial success rate ({best_initial.success_rate:.1%}).\")\n",
    "        print(\"Consider: (1) relaxing budget tolerances, or\")\n",
    "        print(\"          (2) increasing SCENARIO_CONCENTRATION to reduce variance.\")\n",
    "    \n",
    "    best_fitness_history = []\n",
    "    generations_without_improvement = 0\n",
    "    \n",
    "    for gen in range(GA_CONFIG['num_generations']):\n",
    "        population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        \n",
    "        best_fitness = population[0].fitness\n",
    "        best_fitness_history.append(best_fitness)\n",
    "        \n",
    "        if len(best_fitness_history) > 1:\n",
    "            improvement = best_fitness - best_fitness_history[-2]\n",
    "            if improvement < GA_CONFIG['convergence_threshold']:\n",
    "                generations_without_improvement += 1\n",
    "            else:\n",
    "                generations_without_improvement = 0\n",
    "        \n",
    "        if generations_without_improvement >= GA_CONFIG['convergence_patience']:\n",
    "            print(f\"\\nConverged at generation {gen+1}\")\n",
    "            break\n",
    "        \n",
    "        if (gen + 1) % 10 == 0 or gen == 0:\n",
    "            print(f\"\\nGeneration {gen+1}/{GA_CONFIG['num_generations']}\")\n",
    "            print(f\"  Best fitness: {best_fitness:.6f}\")\n",
    "            print(f\"  Success rate: {population[0].success_rate:.1%}\")\n",
    "            print(f\"  Mean deviation: {population[0].mean_deviation:.4f}\")\n",
    "        \n",
    "        next_generation = []\n",
    "        \n",
    "        elite = population[:GA_CONFIG['elite_size']]\n",
    "        next_generation.extend([MatrixCandidate(\n",
    "            matrix=e.matrix.copy(), fitness=e.fitness, budget_score=e.budget_score,\n",
    "            constraint_score=e.constraint_score, success_rate=e.success_rate,\n",
    "            mean_deviation=e.mean_deviation, generation=gen+1\n",
    "        ) for e in elite])\n",
    "        \n",
    "        while len(next_generation) < GA_CONFIG['population_size']:\n",
    "            parent1 = tournament_selection(population, GA_CONFIG['tournament_size'], rng)\n",
    "            parent2 = tournament_selection(population, GA_CONFIG['tournament_size'], rng)\n",
    "            \n",
    "            if rng.random() < GA_CONFIG['crossover_rate']:\n",
    "                child_matrix = crossover(parent1.matrix, parent2.matrix, rng)\n",
    "            else:\n",
    "                child_matrix = parent1.matrix.copy()\n",
    "            \n",
    "            child_matrix = mutate(child_matrix, GA_CONFIG['mutation_rate'], rng)\n",
    "            \n",
    "            if not np.isfinite(child_matrix).all():\n",
    "                child_matrix = repair_matrix(np.nan_to_num(child_matrix, nan=CONSTRAINTS['cell_min']))\n",
    "            \n",
    "            # Apply zero mask and anchor cells\n",
    "            child_matrix[combined_zero_mask] = 0.0\n",
    "            child_matrix = enforce_all_fixed_cells(child_matrix)\n",
    "            \n",
    "            fitness, budget_sc, constraint_sc, success_rate, mean_dev = evaluate_fitness(\n",
    "                child_matrix, S_quick, merit_pool, BUDGET_TOLERANCE_LOWER, BUDGET_TOLERANCE_UPPER\n",
    "            )\n",
    "            \n",
    "            next_generation.append(MatrixCandidate(\n",
    "                matrix=child_matrix, fitness=fitness, budget_score=budget_sc,\n",
    "                constraint_score=constraint_sc, success_rate=success_rate,\n",
    "                mean_deviation=mean_dev, generation=gen+1\n",
    "            ))\n",
    "        \n",
    "        population = next_generation\n",
    "    \n",
    "    population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVOLUTION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Final best fitness: {population[0].fitness:.6f}\")\n",
    "    \n",
    "    return population[:EVAL_CONFIG['num_top_candidates']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b32e0-e12b-4f6d-a8a8-33f39a396584",
   "metadata": {},
   "source": [
    "## Финальная оценка (Full Evaluation) и удаление дубликатов (Deduplication)\n",
    "\n",
    "### Зачем нужен этап deduplication?\n",
    "\n",
    "Генетический алгоритм нередко приходит к очень похожим или даже одинаковым матрицам.  \n",
    "Если их не удалить:\n",
    "- Будет тратиться время на повторную оценку одинаковых решений,\n",
    "- В итоговом рейтинге одно и то же решение может появиться несколько раз.\n",
    "\n",
    "### deduplicate_candidates()\n",
    "\n",
    "**Что делает:**\n",
    "- Сравнивает каждую матрицу с уже встреченными,\n",
    "- Считает дубликатом, если значения совпадают почти полностью (порог очень строгий: 1e-6),\n",
    "- Удаляет дубли, оставляя только уникальные матрицы.\n",
    "\n",
    "**Когда применяется:**\n",
    "- Перед финальной (дорогой) оценкой,\n",
    "- Уменьшает количество матриц на 20–50%,\n",
    "- Снижает вычислительную нагрузку.\n",
    "\n",
    "---\n",
    "\n",
    "## Полная оценка (Full Evaluation)\n",
    "\n",
    "### Зачем она нужна?\n",
    "\n",
    "Во время эволюции используется **quick evaluation** (например, 2000 сценариев), чтобы работать быстро.  \n",
    "Но финальные решения должны быть проверены **точно** → используется **full evaluation** (например, 10 000 сценариев).\n",
    "\n",
    "**Компромисс:**\n",
    "- Быстрота во время обучения,\n",
    "- Максимальная точность при выборе лучших решений.\n",
    "\n",
    "---\n",
    "\n",
    "## Этапы full_evaluation()\n",
    "\n",
    "### 1. Генерация полного набора сценариев\n",
    "Создаётся большой набор (например, 10 000 сценариев), включая стресс-сценарии.\n",
    "\n",
    "### 2. Обновление zero mask\n",
    "На большем количестве сценариев некоторые ячейки могут стать постоянно нулевыми.  \n",
    "Создаётся новый `combined_zero_mask`, более точный и устойчивый.\n",
    "\n",
    "### 3. Локальная донастройка (опционально)\n",
    "Применяется **только к топ-5 матрицам**, потому что:\n",
    "- Локальная оптимизация дорогая,\n",
    "- Лучше дорабатывать сильные решения,\n",
    "- Нет смысла тратить ресурсы на слабые,\n",
    "- Избегается переобучение.\n",
    "\n",
    "Локальная донастройка использует небольшой поднабор сценариев (например, 100), чтобы ускорить расчёт.\n",
    "\n",
    "### 4. Полная переоценка\n",
    "Каждая матрица (после донастройки или как есть) заново вычисляет:\n",
    "- fitness,\n",
    "- budget_score,\n",
    "- constraint_score,\n",
    "- success_rate,\n",
    "- mean_deviation.\n",
    "\n",
    "Оценка проводится **по всем 10 000 сценариям**.\n",
    "\n",
    "### 5. Финальный рейтинг\n",
    "Матрицы сортируются по fitness (от лучшей к худшей).  \n",
    "Результат — окончательный список лучших решений, готовых к экспорту и использованию.\n",
    "\n",
    "---\n",
    "\n",
    "## Почему quick eval и full eval могут отличаться?\n",
    "\n",
    "**Обычно:**\n",
    "- Топ-3 остаются топ-3,\n",
    "- Success rate может отличаться на 5–10%,\n",
    "- Mean deviation обычно стабильнее.\n",
    "\n",
    "**Если порядок сильно изменился:**\n",
    "- Значит, матрица была «заточена» под quick-сценарии,\n",
    "- Full evaluation показывает «истинное» качество,\n",
    "- Это оправдывает необходимость финального этапа.\n",
    "\n",
    "---\n",
    "\n",
    "## Итого\n",
    "\n",
    "- **Deduplication** удаляет повторяющиеся решения → экономия времени.\n",
    "- **Full Evaluation** даёт точную картину производительности.\n",
    "- **Локальная донастройка** улучшает только лучшие решения, без перерасхода ресурсов.\n",
    "- **Финальный рейтинг** обеспечивает надёжный выбор матриц для бизнеса.\n",
    "\n",
    "---\n",
    "\n",
    "## Генерация политики (Policy Generation)\n",
    "\n",
    "### Зачем?\n",
    "\n",
    "Даже если матрица повышений идеальна, итоговый бюджет зависит от того, **как менеджеры распределят рейтинги**.  \n",
    "HR и менеджерам нужна **чёткая инструкция**: какие доли рейтингов безопасны для бюджета.\n",
    "\n",
    "### generate_policy_for_matrix()\n",
    "\n",
    "**Как работает:**\n",
    "\n",
    "#### Шаг 1. Монте-Карло семплирование\n",
    "- Генерируется ~200 возможных распределений рейтингов,\n",
    "- Для каждого считается бюджет с текущей матрицей,\n",
    "- Оставляются **только те**, где бюджет в пределах допустимого диапазона.\n",
    "\n",
    "→ Получаем набор **успешных** распределений.\n",
    "\n",
    "#### Шаг 2. Извлечение границ для каждого рейтинга\n",
    "Для каждого уровня рейтинга:\n",
    "- Берутся все успешные проценты,\n",
    "- Вычисляются:\n",
    "  - **Target %** — целевое значение (из MATR),\n",
    "  - **Hard Min % (P10)** — нижняя надёжная граница,\n",
    "  - **Hard Max % (P90)** — верхняя надёжная граница.\n",
    "\n",
    "Почему P10/P90?\n",
    "- Это устойчиво к выбросам,\n",
    "- 80% «безопасной зоны»,\n",
    "- Лучше, чем min/max (слишком экстремально).\n",
    "\n",
    "---\n",
    "\n",
    "## Как читать политику\n",
    "\n",
    "Пример:\n",
    "- Rating 3: target=50%, hard_min=45%, hard_max=55%\n",
    "\n",
    "Значит:\n",
    "- Цель — 50%\n",
    "- Можно 45–55% без риска\n",
    "- Выше или ниже — вероятность выхода из бюджета повышается\n",
    "\n",
    "---\n",
    "\n",
    "## Бизнес-применение\n",
    "\n",
    "**Калибровка менеджеров**  \n",
    "«У тебя Rating 5 = 25%, но максимум безопасный = 13% → бюджет под угрозой.»\n",
    "\n",
    "**Политики HR**  \n",
    "«Рейтинги должны распределяться в указанных диапазонах.»\n",
    "\n",
    "**Сценарное планирование**  \n",
    "«Что если все будут ставить высокие рейтинги?»\n",
    "\n",
    "---\n",
    "\n",
    "## Если viable-политик нет\n",
    "\n",
    "Это редкость, но возможно:\n",
    "- Бюджет слишком строгий,\n",
    "- Матрица слишком агрессивная.\n",
    "\n",
    "В этом случае:\n",
    "- Возвращается пустой список,\n",
    "- Пользователю выводится предупреждение,\n",
    "- Рекомендуется ослабить бюджет или уменьшить вариативность сценариев.\n",
    "\n",
    "---\n",
    "\n",
    "**Итог:**  \n",
    "Этот этап превращает техническую матрицу в **практические бизнес-правила**, которые помогает менеджерам удерживать бюджет под контролем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7af72-148b-45ad-88f3-8f29607ed66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# FINAL EVALUATION\n",
    "# ======================\n",
    "\n",
    "def deduplicate_candidates(candidates: List[MatrixCandidate], tolerance: float = 1e-6) -> List[MatrixCandidate]:\n",
    "    \"\"\"Remove duplicate matrices, keeping the best fitness for each unique matrix\"\"\"\n",
    "    if not candidates:\n",
    "        return []\n",
    "    \n",
    "    unique_candidates = []\n",
    "    seen_matrices = []\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        is_duplicate = False\n",
    "        for seen_matrix in seen_matrices:\n",
    "            # Check if matrices are identical within tolerance\n",
    "            if np.allclose(candidate.matrix, seen_matrix, atol=tolerance):\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        \n",
    "        if not is_duplicate:\n",
    "            unique_candidates.append(candidate)\n",
    "            seen_matrices.append(candidate.matrix.copy())\n",
    "    \n",
    "    return unique_candidates\n",
    "\n",
    "\n",
    "def full_evaluation(candidates: List[MatrixCandidate], df: pd.DataFrame, merit_pool: float) -> List[MatrixCandidate]:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"FULL EVALUATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    print(f\"\\nGenerating {EVAL_CONFIG['full_eval_scenarios']} scenarios...\")\n",
    "    full_scenarios = generate_rating_scenarios(df, EVAL_CONFIG['full_eval_scenarios'], True)\n",
    "    S_full = np.stack(full_scenarios)\n",
    "    zero_mask_full = compute_zero_support_mask(full_scenarios)\n",
    "    combined_zero_mask = zero_mask_full | STRICT_ZERO_MASK\n",
    "    print(f\"Full scenario set ready\")\n",
    "\n",
    "    refined_candidates = []\n",
    "    for i, candidate in enumerate(candidates):\n",
    "        mat = candidate.matrix.copy()\n",
    "        mat[combined_zero_mask] = 0.0\n",
    "        mat = enforce_all_fixed_cells(mat)\n",
    "\n",
    "        if i < 5:\n",
    "            refined_matrix = local_refinement(\n",
    "                mat, S_full[:100], merit_pool, BUDGET_TOLERANCE_LOWER, BUDGET_TOLERANCE_UPPER\n",
    "            )\n",
    "            refined_matrix[combined_zero_mask] = 0.0\n",
    "            refined_matrix = enforce_all_fixed_cells(refined_matrix)\n",
    "        else:\n",
    "            refined_matrix = mat\n",
    "\n",
    "        fitness, budget_sc, constraint_sc, success_rate, mean_dev = evaluate_fitness(\n",
    "            refined_matrix, S_full, merit_pool, BUDGET_TOLERANCE_LOWER, BUDGET_TOLERANCE_UPPER\n",
    "        )\n",
    "\n",
    "        refined_candidates.append(MatrixCandidate(\n",
    "            matrix=refined_matrix, fitness=fitness, budget_score=budget_sc,\n",
    "            constraint_score=constraint_sc, success_rate=success_rate,\n",
    "            mean_deviation=mean_dev, generation=candidate.generation\n",
    "        ))\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"  Evaluated {i+1}/{len(candidates)}\")\n",
    "\n",
    "    refined_candidates.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    print(f\"Full evaluation complete\")\n",
    "    return refined_candidates\n",
    "\n",
    "\n",
    "def generate_policy_for_matrix(matrix: np.ndarray, df: pd.DataFrame, \n",
    "                              merit_pool: float) -> List[PolicyGuidance]:\n",
    "    \"\"\"Generate management policy for a specific matrix\"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    successful_dists = []\n",
    "    \n",
    "    base_probs = np.array([TARGET_RATING_DISTRIBUTION[r] for r in sorted(RATING_ORDER)])\n",
    "    \n",
    "    for _ in range(200):\n",
    "        perturbed = dirichlet_sample_from_target(base_probs, SCENARIO_CONCENTRATION, rng)\n",
    "        dist = {r: p for r, p in zip(sorted(RATING_ORDER), perturbed)}\n",
    "        \n",
    "        S = create_salary_matrix(df, dist, rng)\n",
    "        cost = (S * matrix).sum()\n",
    "        deviation = (cost - merit_pool) / merit_pool\n",
    "        \n",
    "        # Asymmetric budget check\n",
    "        if deviation >= -BUDGET_TOLERANCE_LOWER and deviation <= BUDGET_TOLERANCE_UPPER:\n",
    "            successful_dists.append({r: dist[r] * 100 for r in RATING_ORDER})\n",
    "    \n",
    "    if not successful_dists:\n",
    "        return []\n",
    "    \n",
    "    policies = []\n",
    "    for rating in sorted(RATING_ORDER):\n",
    "        values = [d[rating] for d in successful_dists]\n",
    "        policies.append(PolicyGuidance(\n",
    "            rating=rating,\n",
    "            target_pct=TARGET_RATING_DISTRIBUTION[rating] * 100,\n",
    "            hard_min_pct=np.percentile(values, 10),\n",
    "            hard_max_pct=np.percentile(values, 90)\n",
    "        ))\n",
    "    \n",
    "    return policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f616ab-9572-43dd-9a6b-13957e985a9e",
   "metadata": {},
   "source": [
    "## Reporting & Export\n",
    "\n",
    "### **1. Summary Printing (print_summary)**\n",
    "\n",
    "Выводит компактную таблицу топ-кандидатов:\n",
    "\n",
    "* Rank (позиция)\n",
    "* Fitness (общий балл)\n",
    "* Success% (доля сценариев в бюджете)\n",
    "* Budget Score (качество попадания в бюджет)\n",
    "* Constraint Score (качество соблюдения ограничений)\n",
    "\n",
    "Показывает до 20 лучших решений.\n",
    "**Цель:** быстро понять, какие матрицы лидируют.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Экспорт в Excel (export_results)**\n",
    "\n",
    "Создаётся **один Excel-файл** с несколькими листами (1 лист = 1 матрица).\n",
    "\n",
    "#### **Структура листа:**\n",
    "\n",
    "**🟦 METADATA (первые строки)**\n",
    "Содержит ключевые метрики матрицы:\n",
    "\n",
    "* Fitness\n",
    "* Success Rate\n",
    "* Budget Score\n",
    "* Constraint Score\n",
    "* Differentiation Score (видимость различий между рейтингами)\n",
    "* Mean Deviation (среднее отклонение бюджета)\n",
    "\n",
    "**🟦 MERIT MATRIX (%)**\n",
    "\n",
    "* Строки = CR bins\n",
    "* Столбцы = Ratings\n",
    "* Значения = % повышения (0–100%)\n",
    "* Все округлено до 2 знаков\n",
    "\n",
    "CR bins подписаны:\n",
    "\n",
    "* Если custom – показываются диапазоны (например: `[0.90, 1.10)`).\n",
    "* Если auto – добавляется описание (например: `Lowest CR - Best Positioned`).\n",
    "\n",
    "**🟦 POLICY GUIDANCE**\n",
    "Для каждого рейтинга:\n",
    "\n",
    "* Target %\n",
    "* Hard Min %\n",
    "* Hard Max %\n",
    "\n",
    "Если невозможно построить политику — выводится сообщение.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Дополнительные файлы**\n",
    "\n",
    "#### ✅ Summary CSV\n",
    "\n",
    "CSV-файл с ключевыми метриками:\n",
    "\n",
    "* rank, fitness, success_rate, budget_score, constraint_score, mean_deviation\n",
    "\n",
    "**Цель:** быстро сравнить решения, удобно для анализа в pandas/Excel.\n",
    "\n",
    "#### ✅ Configuration JSON\n",
    "\n",
    "Полный «паспорт» оптимизации:\n",
    "\n",
    "* Настройки рейтингов и CR-бинов\n",
    "* Источник целевого распределения\n",
    "* Budget tolerance\n",
    "* Monte Carlo параметры\n",
    "* Весовые коэффициенты фитнеса\n",
    "* Информация о фиксированных ячейках\n",
    "* Лучшая fitness и differentiation\n",
    "* Количество уникальных кандидатов\n",
    "\n",
    "**Цель:** 100% воспроизводимость и прозрачность.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Детальный анализ матрицы (analyze_matrix_application)**\n",
    "\n",
    "Применяет лучшую матрицу к реальной популяции сотрудников.\n",
    "\n",
    "**Что анализируется:**\n",
    "\n",
    "**✅ Budget Summary**\n",
    "\n",
    "* Общая зарплата\n",
    "* Целевой бюджет и фактический\n",
    "* Отклонение\n",
    "* В пределах бюджета? (YES/NO)\n",
    "\n",
    "**✅ Merit by Rating**\n",
    "Показывает средний % повышения и количество сотрудников по каждому рейтингу.\n",
    "\n",
    "**✅ Zero Merit**\n",
    "Сколько сотрудников получат 0% — важно для HR и коммуникаций.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Анализ риска (analyze_scenario_risk)**\n",
    "\n",
    "Проверяет матрицу на 1000+ сценариев (включая стрессовые).\n",
    "\n",
    "**Выводит:**\n",
    "\n",
    "* Диапазон допуска (budget tolerance)\n",
    "* Success Rate (% сценариев в бюджете)\n",
    "* Mean Deviation (среднее отклонение)\n",
    "* Std Dev (разброс затрат)\n",
    "\n",
    "**Интерпретация:**\n",
    "\n",
    "* > 80% → низкий риск ✅\n",
    "* 60–80% → средний риск ⚠️\n",
    "* <60% → высокий риск ❌\n",
    "\n",
    "**Цель:** понять реальную устойчивость матрицы.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf941e-2076-4c2c-975d-bc160b7bbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# REPORTING\n",
    "# ======================\n",
    "\n",
    "def print_summary(candidates: List[MatrixCandidate]):\n",
    "    \"\"\"Print summary of top candidates\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TOP CANDIDATE MATRICES\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"{'Rank':<6} {'Fitness':<10} {'Success%':<10} {'Budget':<10} {'Constraint':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, cand in enumerate(candidates[:20], 1):\n",
    "        print(f\"{i:<6} {cand.fitness:<10.6f} {cand.success_rate*100:<10.1f} \"\n",
    "              f\"{cand.budget_score:<10.6f} {cand.constraint_score:<12.6f}\")\n",
    "\n",
    "\n",
    "def export_results(candidates: List[MatrixCandidate], df: pd.DataFrame, merit_pool: float):\n",
    "    \"\"\"Export all results to a single Excel workbook with multiple sheets\"\"\"\n",
    "    \n",
    "    if not candidates:\n",
    "        print(\"No candidates to export\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EXPORTING RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    I, J = candidates[0].matrix.shape\n",
    "    rating_cols = [f\"Rating {RATING_ORDER[j]}\" for j in range(J)]\n",
    "    \n",
    "    # Create descriptive CR bin labels - show ranges when custom bins are used\n",
    "    cr_labels = []\n",
    "    if CUSTOM_CR_BINS is not None:\n",
    "        for i in range(I):\n",
    "            lo, hi = CR_BIN_EDGES[i], CR_BIN_EDGES[i+1]\n",
    "            if np.isinf(hi):\n",
    "                cr_labels.append(f\"CR Bin {i} [{lo:.2f}, ∞)\")\n",
    "            else:\n",
    "                cr_labels.append(f\"CR Bin {i} [{lo:.2f}, {hi:.2f})\")\n",
    "    else:\n",
    "        for i in range(I):\n",
    "            if i == 0:\n",
    "                cr_labels.append(f\"CR Bin {i} (Lowest CR - Best Positioned)\")\n",
    "            elif i == I - 1:\n",
    "                cr_labels.append(f\"CR Bin {i} (Highest CR - Worst Positioned)\")\n",
    "            else:\n",
    "                cr_labels.append(f\"CR Bin {i}\")\n",
    "    \n",
    "    # Create single Excel workbook\n",
    "    excel_path = os.path.join(OUTPUT_DIR, \"merit_matrices_all_scenarios.xlsx\")\n",
    "    \n",
    "    print(f\"\\nCreating Excel workbook with {len(candidates)} scenarios...\")\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        for i, cand in enumerate(candidates, 1):\n",
    "            sheet_name = f\"Rank_{i:02d}\"\n",
    "            \n",
    "            # Convert to percentage and round to 2 decimals\n",
    "            matrix_pct = np.round(cand.matrix * 100, 2)\n",
    "            \n",
    "            # Create matrix dataframe\n",
    "            df_matrix = pd.DataFrame(\n",
    "                matrix_pct,\n",
    "                index=cr_labels,\n",
    "                columns=rating_cols\n",
    "            )\n",
    "            \n",
    "            # Add metadata rows - include differentiation score\n",
    "            diff_sc = differentiation_score(cand.matrix)\n",
    "            metadata = pd.DataFrame({\n",
    "                'Metric': ['Fitness', 'Success Rate (%)', 'Budget Score', 'Constraint Score', 'Diff Score', 'Mean Deviation (%)'],\n",
    "                'Value': [\n",
    "                    f\"{cand.fitness:.6f}\",\n",
    "                    f\"{cand.success_rate*100:.2f}\",\n",
    "                    f\"{cand.budget_score:.6f}\",\n",
    "                    f\"{cand.constraint_score:.6f}\",\n",
    "                    f\"{diff_sc:.6f}\",\n",
    "                    f\"{cand.mean_deviation*100:.4f}\"\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            # Generate policy\n",
    "            policy = generate_policy_for_matrix(cand.matrix, df, merit_pool)\n",
    "            \n",
    "            if policy:\n",
    "                policy_df = pd.DataFrame([{\n",
    "                    'Rating': p.rating,\n",
    "                    'Target %': f\"{p.target_pct:.2f}\",\n",
    "                    'Hard Min %': f\"{p.hard_min_pct:.2f}\",\n",
    "                    'Hard Max %': f\"{p.hard_max_pct:.2f}\"\n",
    "                } for p in policy])\n",
    "            else:\n",
    "                policy_df = pd.DataFrame({'Note': ['No successful policy distributions found']})\n",
    "            \n",
    "            # Write to sheet with sections\n",
    "            # Section 1: Metadata\n",
    "            metadata.to_excel(writer, sheet_name=sheet_name, index=False, startrow=0)\n",
    "            \n",
    "            # Section 2: Merit Matrix (with blank row separator)\n",
    "            startrow_matrix = len(metadata) + 2\n",
    "            writer.sheets[sheet_name].cell(row=startrow_matrix, column=1, value=\"MERIT MATRIX (%)\")\n",
    "            df_matrix.to_excel(writer, sheet_name=sheet_name, startrow=startrow_matrix + 1)\n",
    "            \n",
    "            # Section 3: Policy Guidance (with blank row separator)\n",
    "            startrow_policy = startrow_matrix + len(df_matrix) + 4\n",
    "            writer.sheets[sheet_name].cell(row=startrow_policy, column=1, value=\"POLICY GUIDANCE\")\n",
    "            policy_df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow_policy + 1)\n",
    "            \n",
    "            if (i) % 5 == 0:\n",
    "                print(f\"  Exported {i}/{len(candidates)} scenarios\")\n",
    "    \n",
    "    print(f\"\\nExported to single Excel file: '{excel_path}'\")\n",
    "    print(f\"  - {len(candidates)} sheets (one per scenario)\")\n",
    "    print(f\"  - Each sheet contains: metadata, merit matrix, and policy guidance\")\n",
    "    \n",
    "    # Also export summary CSV\n",
    "    summary = pd.DataFrame([{\n",
    "        'rank': i,\n",
    "        'fitness': c.fitness,\n",
    "        'success_rate': c.success_rate,\n",
    "        'budget_score': c.budget_score,\n",
    "        'constraint_score': c.constraint_score,\n",
    "        'mean_deviation': c.mean_deviation\n",
    "    } for i, c in enumerate(candidates, 1)])\n",
    "    summary_path = os.path.join(OUTPUT_DIR, \"candidate_summary.csv\")\n",
    "    summary.to_csv(summary_path, index=False)\n",
    "    print(f\"  - Summary CSV: '{summary_path}'\")\n",
    "    \n",
    "    # Export configuration - include Monte Carlo settings\n",
    "    config = {\n",
    "        'num_ratings': NUM_RATINGS,\n",
    "        'rating_order': RATING_ORDER,\n",
    "        'target_distribution': {str(k): v for k, v in TARGET_RATING_DISTRIBUTION.items()},\n",
    "        'custom_target_distribution_used': CUSTOM_TARGET_DISTRIBUTION is not None,\n",
    "        'num_cr_bins': NUM_CR_BINS,\n",
    "        'cr_bin_edges': [float(e) if not np.isinf(e) else 'inf' for e in CR_BIN_EDGES],\n",
    "        'custom_cr_bins_used': CUSTOM_CR_BINS is not None,\n",
    "        'cr_bin_interpretation': 'Bin 0 = Lowest CR (best positioned), Higher bins = Higher CR (worse positioned)',\n",
    "        'merit_pool_value': MERIT_POOL_VALUE,\n",
    "        'budget_tolerance_lower': BUDGET_TOLERANCE_LOWER,\n",
    "        'budget_tolerance_upper': BUDGET_TOLERANCE_UPPER,\n",
    "        'monte_carlo': {\n",
    "            'concentration': SCENARIO_CONCENTRATION,\n",
    "            'hard_zero_ratings': HARD_ZERO_RATINGS,\n",
    "            'stress_honors_zeros': HARD_ZERO_RATINGS,\n",
    "            'note': 'Higher concentration = less variance around target distribution'\n",
    "        },\n",
    "        'fitness_weights': FITNESS_WEIGHTS,\n",
    "        'diff_weight': DIFF_WEIGHT,\n",
    "        'best_diff_score': float(differentiation_score(candidates[0].matrix)),\n",
    "        'strict_zero_cells': {str(k): v for k, v in (FORCE_ZERO_CELLS or {}).items()} if FORCE_ZERO_CELLS else None,\n",
    "        'anchor_cell_max': ANCHOR_CELL_MAX,\n",
    "        'anchor_cell_min': ANCHOR_CELL_MIN,\n",
    "        'best_fitness': candidates[0].fitness,\n",
    "        'num_unique_candidates': len(candidates)\n",
    "    }\n",
    "    \n",
    "    config_path = os.path.join(OUTPUT_DIR, \"optimization_config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"  - Configuration JSON: '{config_path}'\")\n",
    "\n",
    "\n",
    "def analyze_matrix_application(matrix: np.ndarray, df: pd.DataFrame, merit_pool: float):\n",
    "    \"\"\"Comprehensive analysis\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"DETAILED ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    df_analysis = df.copy()\n",
    "    rng = np.random.default_rng(SEED_BASE_POPULATION)\n",
    "    df_analysis['rating'] = rng.choice(\n",
    "        RATING_ORDER,\n",
    "        size=len(df_analysis),\n",
    "        p=[TARGET_RATING_DISTRIBUTION[r] for r in sorted(RATING_ORDER)]\n",
    "    )\n",
    "    rating_to_idx = {r: i for i, r in enumerate(sorted(RATING_ORDER))}\n",
    "    df_analysis['rating_idx'] = df_analysis['rating'].map(rating_to_idx)\n",
    "    \n",
    "    df_analysis['merit_pct'] = df_analysis.apply(\n",
    "        lambda row: matrix[int(row['cr_bin']), int(row['rating_idx'])], axis=1\n",
    "    )\n",
    "    df_analysis['merit_amount'] = df_analysis['base_salary'] * df_analysis['merit_pct']\n",
    "    \n",
    "    total_merit_cost = df_analysis['merit_amount'].sum()\n",
    "    actual_merit_pct = total_merit_cost / df_analysis['base_salary'].sum()\n",
    "    variance = (total_merit_cost - merit_pool) / merit_pool\n",
    "    \n",
    "    print(f\"\\nBUDGET SUMMARY\")\n",
    "    print(f\"Total Payroll:    {df_analysis['base_salary'].sum():,.0f}\")\n",
    "    print(f\"Target Merit:     {merit_pool:,.0f} ({MERIT_POOL_VALUE:.2%})\")\n",
    "    print(f\"Actual Merit:     {total_merit_cost:,.0f} ({actual_merit_pct:.2%})\")\n",
    "    print(f\"Variance:         {total_merit_cost - merit_pool:+,.0f} ({variance:+.2%})\")\n",
    "    within = (variance >= -BUDGET_TOLERANCE_LOWER) and (variance <= BUDGET_TOLERANCE_UPPER)\n",
    "    print(f\"Within Budget:    {'YES' if within else 'NO'}\")\n",
    "    \n",
    "    print(f\"\\nMERIT BY RATING\")\n",
    "    for rating in sorted(RATING_ORDER):\n",
    "        subset = df_analysis[df_analysis['rating'] == rating]\n",
    "        if len(subset) > 0:\n",
    "            avg_merit = subset['merit_pct'].mean() * 100\n",
    "            count = len(subset)\n",
    "            print(f\"  Rating {rating}: {avg_merit:5.2f}% avg (n={count})\")\n",
    "    \n",
    "    zero_merit = df_analysis[df_analysis['merit_pct'] == 0]\n",
    "    if len(zero_merit) > 0:\n",
    "        print(f\"\\nZERO MERIT: {len(zero_merit)} employees ({len(zero_merit)/len(df_analysis)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "def analyze_scenario_risk(matrix: np.ndarray, df: pd.DataFrame, merit_pool: float) -> None:\n",
    "    \"\"\"Scenario risk analysis\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SCENARIO RISK ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    scenarios = generate_rating_scenarios(df, 1000, True)\n",
    "    \n",
    "    costs = []\n",
    "    for S in scenarios:\n",
    "        cost = (S * matrix).sum()\n",
    "        costs.append(cost)\n",
    "    \n",
    "    deviations = np.array([(c - merit_pool) / merit_pool * 100 for c in costs])\n",
    "    \n",
    "    # Asymmetric budget check\n",
    "    within = sum(1 for d in deviations if d >= -BUDGET_TOLERANCE_LOWER * 100 and d <= BUDGET_TOLERANCE_UPPER * 100)\n",
    "    \n",
    "    print(f\"\\nBudget Tolerance: {-BUDGET_TOLERANCE_LOWER*100:.1f}% to +{BUDGET_TOLERANCE_UPPER*100:.1f}%\")\n",
    "    print(f\"Success Rate: {within/len(scenarios)*100:.1f}% ({within}/{len(scenarios)} scenarios within band)\")\n",
    "    print(f\"Mean Deviation: {deviations.mean():+.2f}%\")\n",
    "    print(f\"Std Dev: {deviations.std():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49941cb-f90f-4d62-82f6-72568878cbdc",
   "metadata": {},
   "source": [
    "## Main Execution Function (main)\n",
    "\n",
    "Главная функция, управляющая всем процессом.\n",
    "\n",
    "### **Основные этапы:**\n",
    "\n",
    "### Phase 1: Печать конфигурации\n",
    "\n",
    "Показываются все ключевые параметры:\n",
    "\n",
    "* Кол-во рейтингов\n",
    "* CR-бин структура\n",
    "* Источник распределения (custom/auto)\n",
    "* Merit pool\n",
    "* Budget tolerance\n",
    "* Monte Carlo concentration\n",
    "  **Цель:** прозрачность и проверка перед запуском.\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 2: Валидация\n",
    "\n",
    "Проверяются настройки.\n",
    "Если что-то некорректно — показывается ошибка и выполнение останавливается.\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 3: Загрузка данных\n",
    "\n",
    "* Если Excel есть — загружается.\n",
    "* Если нет — генерируются синтетические данные.\n",
    "* Считается общий payroll и merit pool в долларах.\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 4: Генетический алгоритм (быстрая оптимизация)\n",
    "\n",
    "Запускается GA с quick evaluation (2k сценариев).\n",
    "Получаем top кандидатов.\n",
    "\n",
    "Если кандидатов нет — завершаем процесс.\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 5: Full Evaluation (точная оценка)\n",
    "\n",
    "Топ кандидаты тестируются на 10k сценариях.\n",
    "Применяется локальная донастройка (только для топ-5).\n",
    "Формируется финальный рейтинг.\n",
    "\n",
    "Если нет успешных — завершаем.\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 6: Reporting & Export\n",
    "\n",
    "* Печать summary\n",
    "* Генерация Excel/CSV/JSON\n",
    "* Детальный анализ лучшей матрицы\n",
    "* Анализ риска\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 7: Завершение\n",
    "\n",
    "Печать: **\"OPTIMIZATION COMPLETE\"**\n",
    "\n",
    "---\n",
    "\n",
    "## **Обработка ошибок**\n",
    "\n",
    "* Нет файла данных → синтетика\n",
    "* Нет кандидатов → сообщение и выход\n",
    "* Все обрабатывается корректно, исключения наружу не выбрасываются\n",
    "\n",
    "---\n",
    "\n",
    "## **Entry Point**\n",
    "\n",
    "Используется стандартный Python-подход:\n",
    "`if __name__ == \"__main__\": main()`\n",
    "\n",
    "Позволяет:\n",
    "\n",
    "* Запуск как скрипт\n",
    "* Импорт как модуль без автозапуска\n",
    "\n",
    "---\n",
    "\n",
    "# Итоговый workflow:\n",
    "\n",
    "1. Конфигурация → проверка → загрузка данных\n",
    "2. GA (quick eval) → топ кандидаты\n",
    "3. Full eval (точность) → финальный список\n",
    "4. Local refinement (дополировка лучших)\n",
    "5. Экспорт (Excel/CSV/JSON)\n",
    "6. Аналитика (бюджет + риск)\n",
    "\n",
    "---\n",
    "\n",
    "## Ключевые метрики:\n",
    "\n",
    "* Success Rate (% успешных сценариев)\n",
    "* Fitness (общий балл)\n",
    "* Mean Deviation (точность бюджета)\n",
    "* Constraint Score (структурная корректность)\n",
    "* Differentiation (видимость различий по рейтингам)\n",
    "\n",
    "---\n",
    "\n",
    "## Типичные результаты:\n",
    "\n",
    "* Success Rate: **80–95%**\n",
    "* Fitness: **0.90–0.98**\n",
    "* Mean Deviation: **0.5–2%**\n",
    "* Runtime: **5–30 минут**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31473ef2-d6b3-4f9c-b8b5-8966fc257915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom target distribution\n",
      "Using custom CR bins: 5 bins defined\n",
      "\n",
      "Constraint Analysis:\n",
      "  Merit Pool: 13.00%\n",
      "  Cell Range: 0.00% to 39.00% (span: 39.00%)\n",
      "  Min Rating Step: 1.95% → Total: 7.80%\n",
      "  Min CR Step: 0.97% → Total: 3.90%\n",
      "  Feasibility Check: ✓ Good (20% utilization of available range)\n",
      "================================================================================\n",
      "MERIT MATRIX OPTIMIZER v4.7\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "Ratings: 5 (scale 1-5)\n",
      "Target Distribution Source: CUSTOM (exact), Monte Carlo perturbs around this mix.\n",
      "CR Bins: 5\n",
      "  Using CUSTOM CR bins:\n",
      "    Bin 0: [0.00, 0.80)\n",
      "    Bin 1: [0.80, 0.90)\n",
      "    Bin 2: [0.90, 1.10)\n",
      "    Bin 3: [1.10, 1.20)\n",
      "    Bin 4: [1.20, ∞)\n",
      "Merit Pool: 13.00%\n",
      "Budget Tolerance: -5.0% to +5.0%\n",
      "Monte Carlo Concentration: 166.67 (higher = less variance)\n",
      "\n",
      "Target Distribution:\n",
      "  Rating 1:  10.0%\n",
      "  Rating 2:  15.0%\n",
      "  Rating 3:  50.0%\n",
      "  Rating 4:  15.0%\n",
      "  Rating 5:  10.0%\n",
      "Configuration validated\n",
      "Loaded data from 'Misha.xlsx'\n",
      "\n",
      "Loaded 25 employees\n",
      "  Payroll: 50,257,241\n",
      "  Merit Pool: 6,533,441\n",
      "\n",
      "================================================================================\n",
      "GENETIC ALGORITHM EVOLUTION\n",
      "================================================================================\n",
      "\n",
      "Matrix: 5 CR bins × 5 ratings\n",
      "Orientation: Rows = CR bins (0=lowest CR), Cols = ratings (1..N)\n",
      "\n",
      "Generating 2000 evaluation scenarios...\n",
      "Scenarios ready\n",
      "\n",
      "Initializing population of 1000 matrices...\n",
      "Initial population evaluated\n",
      "  Best fitness: 0.751478\n",
      "\n",
      "Generation 1/500\n",
      "  Best fitness: 0.751478\n",
      "  Success rate: 47.3%\n",
      "  Mean deviation: 0.0615\n",
      "\n",
      "Generation 10/500\n",
      "  Best fitness: 0.773480\n",
      "  Success rate: 55.5%\n",
      "  Mean deviation: 0.0520\n",
      "\n",
      "Generation 20/500\n",
      "  Best fitness: 0.800393\n",
      "  Success rate: 61.8%\n",
      "  Mean deviation: 0.0457\n",
      "\n",
      "Generation 30/500\n",
      "  Best fitness: 0.850648\n",
      "  Success rate: 72.5%\n",
      "  Mean deviation: 0.0370\n",
      "\n",
      "Generation 40/500\n",
      "  Best fitness: 0.862816\n",
      "  Success rate: 83.8%\n",
      "  Mean deviation: 0.0286\n",
      "\n",
      "Generation 50/500\n",
      "  Best fitness: 0.910773\n",
      "  Success rate: 95.1%\n",
      "  Mean deviation: 0.0201\n",
      "\n",
      "Generation 60/500\n",
      "  Best fitness: 0.936400\n",
      "  Success rate: 96.3%\n",
      "  Mean deviation: 0.0189\n",
      "\n",
      "Generation 70/500\n",
      "  Best fitness: 0.949704\n",
      "  Success rate: 98.8%\n",
      "  Mean deviation: 0.0156\n",
      "\n",
      "Generation 80/500\n",
      "  Best fitness: 0.951835\n",
      "  Success rate: 97.3%\n",
      "  Mean deviation: 0.0175\n",
      "\n",
      "Generation 90/500\n",
      "  Best fitness: 0.966599\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0181\n",
      "\n",
      "Generation 100/500\n",
      "  Best fitness: 0.966599\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0181\n",
      "\n",
      "Generation 110/500\n",
      "  Best fitness: 0.968014\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0180\n",
      "\n",
      "Generation 120/500\n",
      "  Best fitness: 0.968014\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0180\n",
      "\n",
      "Generation 130/500\n",
      "  Best fitness: 0.968014\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0180\n",
      "\n",
      "Generation 140/500\n",
      "  Best fitness: 0.968014\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0180\n",
      "\n",
      "Generation 150/500\n",
      "  Best fitness: 0.968014\n",
      "  Success rate: 97.0%\n",
      "  Mean deviation: 0.0180\n",
      "\n",
      "Converged at generation 158\n",
      "\n",
      "================================================================================\n",
      "EVOLUTION COMPLETE\n",
      "================================================================================\n",
      "Final best fitness: 0.968014\n",
      "\n",
      "================================================================================\n",
      "FULL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Generating 10000 scenarios...\n",
      "Full scenario set ready\n",
      "  Evaluated 5/20\n",
      "  Evaluated 10/20\n",
      "  Evaluated 15/20\n",
      "  Evaluated 20/20\n",
      "Full evaluation complete\n",
      "\n",
      "================================================================================\n",
      "TOP CANDIDATE MATRICES\n",
      "================================================================================\n",
      "\n",
      "Rank   Fitness    Success%   Budget     Constraint  \n",
      "------------------------------------------------------------\n",
      "1      0.988110   97.8       0.933884   0.570369    \n",
      "2      0.987671   97.8       0.927501   0.585138    \n",
      "3      0.986137   97.7       0.924144   0.586338    \n",
      "4      0.983946   97.5       0.920491   0.586338    \n",
      "5      0.981985   98.1       0.939664   0.573477    \n",
      "6      0.981598   98.0       0.940645   0.535189    \n",
      "7      0.981149   98.0       0.937348   0.567859    \n",
      "8      0.980581   97.9       0.932913   0.559754    \n",
      "9      0.980232   97.8       0.927654   0.561482    \n",
      "10     0.980232   97.8       0.927654   0.561482    \n",
      "11     0.979785   97.7       0.927149   0.567456    \n",
      "12     0.979615   97.4       0.917159   0.559128    \n",
      "13     0.979352   98.0       0.933253   0.579290    \n",
      "14     0.978373   97.4       0.917910   0.578620    \n",
      "15     0.978354   97.9       0.933317   0.566813    \n",
      "16     0.976290   98.1       0.936766   0.560617    \n",
      "17     0.972928   98.7       0.961978   0.487033    \n",
      "18     0.971773   98.2       0.943854   0.517331    \n",
      "19     0.967534   99.1       0.971981   0.495479    \n",
      "20     0.967427   99.1       0.972741   0.494071    \n",
      "\n",
      "================================================================================\n",
      "EXPORTING RESULTS\n",
      "================================================================================\n",
      "\n",
      "Creating Excel workbook with 20 scenarios...\n",
      "  Exported 5/20 scenarios\n",
      "  Exported 10/20 scenarios\n",
      "  Exported 15/20 scenarios\n",
      "  Exported 20/20 scenarios\n",
      "\n",
      "Exported to single Excel file: 'artifacts\\merit_matrices_all_scenarios.xlsx'\n",
      "  - 20 sheets (one per scenario)\n",
      "  - Each sheet contains: metadata, merit matrix, and policy guidance\n",
      "  - Summary CSV: 'artifacts\\candidate_summary.csv'\n",
      "  - Configuration JSON: 'artifacts\\optimization_config.json'\n",
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "BUDGET SUMMARY\n",
      "Total Payroll:    50,257,241\n",
      "Target Merit:     6,533,441 (13.00%)\n",
      "Actual Merit:     6,636,591 (13.21%)\n",
      "Variance:         +103,150 (+1.58%)\n",
      "Within Budget:    YES\n",
      "\n",
      "MERIT BY RATING\n",
      "  Rating 1: 11.82% avg (n=2)\n",
      "  Rating 2: 12.47% avg (n=2)\n",
      "  Rating 3: 13.66% avg (n=9)\n",
      "  Rating 4: 13.81% avg (n=9)\n",
      "  Rating 5: 16.06% avg (n=3)\n",
      "\n",
      "================================================================================\n",
      "SCENARIO RISK ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Budget Tolerance: -5.0% to +5.0%\n",
      "Success Rate: 96.4% (964/1000 scenarios within band)\n",
      "Mean Deviation: -0.35%\n",
      "Std Dev: 2.26%\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZATION COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# MAIN\n",
    "# ======================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*80)\n",
    "    print(\"MERIT MATRIX OPTIMIZER v4.7\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CONFIGURATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Ratings: {NUM_RATINGS} (scale 1-{NUM_RATINGS})\")\n",
    "    \n",
    "    # Display target distribution info\n",
    "    if CUSTOM_TARGET_DISTRIBUTION is not None:\n",
    "        if HARD_ZERO_RATINGS:\n",
    "            print(f\"Target Distribution Source: CUSTOM (exact with hard zeros), Monte Carlo perturbs around this mix.\")\n",
    "        else:\n",
    "            print(f\"Target Distribution Source: CUSTOM (exact), Monte Carlo perturbs around this mix.\")\n",
    "    else:\n",
    "        print(f\"Target Distribution Source: AUTO (bell curve), Monte Carlo perturbs around this.\")\n",
    "    \n",
    "    print(f\"CR Bins: {NUM_CR_BINS}\")\n",
    "    if CUSTOM_CR_BINS is not None:\n",
    "        print(f\"  Using CUSTOM CR bins:\")\n",
    "        for i in range(len(CR_BIN_EDGES) - 1):\n",
    "            lower = CR_BIN_EDGES[i]\n",
    "            upper = CR_BIN_EDGES[i+1]\n",
    "            if np.isinf(upper):\n",
    "                print(f\"    Bin {i}: [{lower:.2f}, ∞)\")\n",
    "            else:\n",
    "                print(f\"    Bin {i}: [{lower:.2f}, {upper:.2f})\")\n",
    "    else:\n",
    "        print(f\"  Auto-generated: {CR_BIN_FIRST:.2f} to {CR_BIN_LAST:.2f}\")\n",
    "    \n",
    "    print(f\"Merit Pool: {MERIT_POOL_VALUE:.2%}\")\n",
    "    print(f\"Budget Tolerance: -{BUDGET_TOLERANCE_LOWER:.1%} to +{BUDGET_TOLERANCE_UPPER:.1%}\")\n",
    "    print(f\"Monte Carlo Concentration: {SCENARIO_CONCENTRATION:.2f} (higher = less variance)\")\n",
    "    \n",
    "    print(f\"\\nTarget Distribution:\")\n",
    "    for rating, pct in sorted(TARGET_RATING_DISTRIBUTION.items()):\n",
    "        print(f\"  Rating {rating}: {pct*100:5.1f}%\")\n",
    "    \n",
    "    validate_configuration()\n",
    "    \n",
    "    df = load_employee_data(DATA_FILE)\n",
    "    \n",
    "    base_payroll = df['base_salary'].sum()\n",
    "    merit_pool = MERIT_POOL_VALUE * base_payroll\n",
    "    \n",
    "    print(f\"\\nLoaded {len(df)} employees\")\n",
    "    print(f\"  Payroll: {base_payroll:,.0f}\")\n",
    "    print(f\"  Merit Pool: {merit_pool:,.0f}\")\n",
    "    \n",
    "    top_candidates = run_genetic_algorithm(df, merit_pool)\n",
    "    \n",
    "    if not top_candidates:\n",
    "        print(\"\\nNo candidates produced\")\n",
    "        return\n",
    "    \n",
    "    final_candidates = full_evaluation(top_candidates, df, merit_pool)\n",
    "    \n",
    "    if not final_candidates:\n",
    "        print(\"\\nNo candidates after evaluation\")\n",
    "        return\n",
    "    \n",
    "    print_summary(final_candidates)\n",
    "    export_results(final_candidates, df, merit_pool)\n",
    "    analyze_matrix_application(final_candidates[0].matrix, df, merit_pool)\n",
    "    analyze_scenario_risk(final_candidates[0].matrix, df, merit_pool)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"OPTIMIZATION COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a0168-2505-428a-a7fb-3a9d5a07dab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
