# Monte Carlo Validation of Merit Matrix: Aggregated Distributions Method

## Автор
- Алексей Иванов 
- Итоговый проект программы «Специалист по Data Science», НИУ ВШЭ

---

## Содержание
1. [Краткое резюме](#краткое-резюме)
2. [Описание проблемы](#описание-проблемы)
3. [Постановка задачи](#постановка-задачи)
4. [Бизнес-контекст](#бизнес-контекст)
5. [Методология](#методология)
6. [Структура кода](#структура-кода)
7. [Данные](#данные)
8. [Результаты](#результаты)
9. [Технические детали](#технические-детали)
10. [Дальнейшее развитие](#дальнейшее-развитие-проекта)

---

## Краткое резюме

### TL;DR

**Исследуемый вопрос:** Насколько надежен широко используемый метод агрегированных распределений для расчета бюджета повышений зарплат?

**Метод:** Monte Carlo симуляция на данных 395,325 сотрудников из Москвы, тестирование 120 конфигураций merit matrices.

**Главный вывод:** Метод имеет фундаментальное ограничение применимости — требует 200+ сотрудников для приемлемой точности (80%+ success rate), что делает его **непригодным для 75-80% компаний** из-за необходимости функциональной сегментации.

**Практическое значение:** 
- Работает для гигантов с тысячами сотрудников
- Не работает для типичных компаний, где функции или группы функций состоят из 50-200 человек
- На основе выявленной проблематики в исследовании разработано коммерческое решение (генетический алгоритм), преодолевающее выявленные ограничения

**Ключевая находка:** Размер группы объясняет ~85-90% вариации в точности, в то время как конфигурация матрицы влияет минимально (±6%). Оптимизация дизайна матрицы не решает проблему.

---

## Описание проблемы

### Что такое Merit Matrix?

**Merit Matrix (матрица повышений)** — инструмент, используемый HR-функцией для определения процента повышения заработной платы сотрудника на основе двух параметров:

1. **Compa Ratio (CR)** — отношение текущей зарплаты сотрудника к рыночной медиане (midpoint) или приятной в компании структуре вознаграждения для данного грейда/уровня должности:
   ```
   CR = Текущая зарплата / Midpoint
   ```
   - CR < 1.0 означает, что сотрудник получает ниже рынка
   - CR = 1.0 означает рыночную зарплату
   - CR > 1.0 означает зарплату выше рынка

2. **Performance Rating** — оценка эффективности сотрудника (обычно от 1 до 5-7)

**Пример Merit Matrix (5×5):**

| CR / Rating | Rating 1 | Rating 2 | Rating 3 | Rating 4 | Rating 5 |
|-------------|----------|----------|----------|----------|----------|
| CR < 0.80   | 6%       | 10%      | 14%      | 17%      | 20%      |
| 0.80-0.90   | 5%       | 9%       | 12%      | 15%      | 18%      |
| 0.90-1.10   | 3%       | 7%       | 10%      | 13%      | 16%      |
| 1.10-1.20   | 2%       | 5%       | 8%       | 11%      | 13%      |
| CR > 1.20   | 1%       | 3%       | 6%       | 8%       | 10%      |

**Принципы справедливости в матрице:**
- **Выше рейтинг → выше повышение** (более эффективные сотрудники получают больше)
- **Выше CR → ниже повышение** (сотрудники с зарплатой выше рынка получают меньшее повышение)

### Фундаментальная проблема прогнозирования бюджета

HR-функция сталкивается с критической проблемой **неопределенности** при планировании бюджета на повышения:

**Что HR знает и контролирует:**
- Merit Matrix (проценты повышений для каждой комбинации CR×Rating)
- Распределение CR среди сотрудников (известно из текущих данных)
- Целевое распределение рейтингов (например, 10% - Rating 1, 20% - Rating 2, и т.д.)

**Что HR НЕ знает и НЕ контролирует:**
- Какому конкретно сотруднику (с каким CR) какой рейтинг будет присвоен
- Будут ли менеджеры строго придерживаться заданного распределения

**Проблема временного разрыва:**
- **Q3-Q4 предыдущего года:** HR утверждает бюджет на повышение фонда оплаты труда на следующий год
- **Q1 текущего года:** Менеджеры/руководители оценивают сотрудников (определяют рейтинг/эффективность сотрудника) по итогам завершенного года
- **Временной разрыв:** 3-6 месяцев между планированием бюджета и присвоением рейтингов сотрудникам

### Метод агрегированных распределений для расчета бюджета

Для решения этой проблемы HR использует **метод агрегированных распределений** (aggregated distributions method):

```
Ожидаемый бюджет = Σ P(CR_bin_i) × P(Rating_j) × Merit(i,j)
```

где:
- `P(CR_bin_i)` — доля сотрудников в i-том CR-бине (по базовой зарплате)
- `P(Rating_j)` — целевая доля сотрудников с j-тым рейтингом
- `Merit(i,j)` — процент повышения из матрицы для комбинации (CR_bin_i, Rating_j)

**Почему "агрегированных распределений"?**
- Метод **агрегирует** (объединяет) два независимых распределения:
  1. Распределение сотрудников по CR bins (известно из данных)
  2. Целевое распределение рейтингов (задается HR политикой)

- Бюджет рассчитывается как математическое ожидание по этим распределениям

**Вопрос исследования:** Насколько точен этот метод в реальности? Как часто реальный бюджет попадает в заданный диапазон (например, ±5% от расчета по агрегированным распределениям)?

---

## Постановка задачи

### Цель исследования

**Валидировать точность метода агрегированных распределений для расчета бюджета** через Monte Carlo симуляции на реальных данных базового оклада сотрудников и **определить границы его практической применимости**.

### Исследовательские вопросы

1. **Точность предсказания:** Как часто метод агрегированных распределений попадает в диапазон ±5% от реального бюджета?
2. **Влияние размера группы (ключевой вопрос):** При каком размере группы метод достигает приемлемой для бюджетной дисциплины точности (success rate ≥ 80%)?
3. **Практическая применимость:** Совместимы ли статистические требования метода с реальной необходимостью сегментации сотрудников по функциям/организационным единицам?
4. **Проверка робастности:** Зависит ли точность от конфигурации матрицы (количество CR bins и ratings) или типа распределения рейтингов?

### Гипотеза

**H₀:** Метод агрегированных распределений дает надежные прогнозы бюджета (success rate ≥ 80%) для типичных организационных групп.

**H₁:** Метод имеет ограниченную применимость: статистические требования (большой размер выборки) конфликтуют с бизнес-реальностью (необходимость сегментации по функциям). Точность критически зависит от размера группы из-за Law of Large Numbers, в то время как конфигурация матрицы и тип распределения оказывают минимальное влияние.

---

## Бизнес-контекст

### Для кого этот инструмент

**Целевая аудитория:**
- **Compensation & Benefits специалисты** — для проектирования merit matrices
- **HR Business Partners** — для бюджетного планирования
- **Finance функция** — для валидации HR-бюджетов
- **C-level executives** — для принятия стратегических решений по компенсациям

### Бизнес-ценность

**Проблема в индустрии:**
- Метод агрегированных распределений **широко используется** в HR практике
- Применяется без понимания ограничений и условий надежности
- Компании регулярно сталкиваются с несоответсвием утвержденного бюджета и фактических трат, но причины не анализируются систематически
- Отсутствуют количественные исследования точности метода на реальных данных

**Критические вопросы без ответов:**
- При каком размере группы метод становится надежным?
- Насколько часто компании не попадают в запалнированный диапазон бюджета?
- Можно ли улучшить точность через оптимизацию конфигурации матрицы?
- Применим ли метод для типичных организационных структур?

**Что дает это исследование:**

1. **Количественная оценка ограничений**
   - Первое систематическое исследование точности метода
   - Определение минимального размера группы для надежности
   - Оценка влияния различных факторов на точность

2. **Практические выводы**
   - Понимание, когда метод применим, а когда нет
   - Объяснение, почему компании сталкиваются с невозможностью точно прогнозировать бюджет на повышение заработных плат
   - Обоснование необходимости альтернативных подходов

3. **Финансовая оценка рисков**
   - Количественная оценка вероятности выхода за рамки ожидаемого диапазона бюджета
   - Основа для принятия обоснованных решений о методах бюджетирования

**Целевые аудитории:**

**Для HR-специалистов:**
- Понимание ограничений используемого метода
- Критерии для выбора метода бюджетирования
- Предупреждение о рисках при малых группах

**Для Finance:**
- Обоснование резервов бюджета
- Оценка финансовых рисков
- Критерии одобрения HR-бюджетов

**Для C-level:**
- Понимание причин перерасходов
- Необходимость инвестиций в альтернативные методы
- Стратегические решения по подходам к компенсациям

**Практическая ценность:**

Исследование показывает, что **широко используемая индустриальная практика имеет серьезное ограничение**, которое ранее не было количественно задокументировано. Это:

1. Объясняет, почему компании регулярно сталкиваются с отличием плана от факта
2. Показывает необходимость разработки альтернативных методов
3. Дает научное обоснование для изменения подходов к бюджетированию
4. Открывает направление для будущих исследований и разработок

---

## Методология

### Общий подход

Проект использует метод **Monte Carlo симуляции** для тестирования метода агрегированных распределений:

```
Для каждой группы сотрудников (Company × Function):
  1. Рассчитать бюджет по методу агрегированных распределений
  2. Провести 50,000 симуляций:
     - Случайно присвоить рейтинги сотрудникам (согласно целевому распределению)
     - Рассчитать реальный бюджет по merit matrix
     - Проверить, попадает ли в диапазон ±5% от расчетного бюджета
  3. Вычислить success rate (% симуляций в пределах допуска)
```

**Тестирование робастности:** 
Для проверки устойчивости метода анализ проводится на **120 различных конфигурациях**:
- 6 вариантов количества CR bins (2-7)
- 5 вариантов количества ratings (3-7)
- 4 типа распределений рейтингов (normal, skewed_high, skewed_low, uniform)

Это позволяет убедиться, что результаты не зависят от конкретного дизайна матрицы или формы распределения.

### Математическая основа

**1. Расчет бюджета методом агрегированных распределений**

Для группы из n сотрудников с базовыми зарплатами BP₁, BP₂, ..., BPₙ:

```
Total_Base = Σ BPᵢ

Budget_ADM% = (Σᵢ Σⱼ W_CR(i) × P_Rating(j) × Merit(i,j)) × 100%

где:
  W_CR(i) = (Σ BP для сотрудников в CR_bin_i) / Total_Base
  P_Rating(j) = целевая доля для рейтинга j (например, 0.20 для 20%)
  Merit(i,j) = процент повышения из матрицы
```

**Примечание:** ADM = Aggregated Distributions Method (метод агрегированных распределений)

**2. Monte Carlo симуляция**

В каждой итерации:

```python
# Шаг 1: Сэмплирование распределения рейтингов с вариацией
alpha = concentration × [P_Rating(1), P_Rating(2), ..., P_Rating(R)]
sampled_distribution = Dirichlet(alpha).rvs()

# Шаг 2: Присвоение рейтингов сотрудникам
for employee in employees:
    rating = random.choice(ratings, p=sampled_distribution)
    cr_bin = get_cr_bin(employee.CR)
    merit_increase = merit_matrix[cr_bin][rating]
    total_budget += employee.BP × (merit_increase / 100)

# Шаг 3: Проверка попадания в допуск
actual_budget_pct = (total_budget / Total_Base) × 100
within_tolerance = (0.95 × Budget_ADM% ≤ actual_budget_pct ≤ 1.05 × Budget_ADM%)
```

**3. Dirichlet распределение для вариации**

Используется **Dirichlet(α)** для моделирования реалистичных отклонений:
- `concentration = 250` → менеджеры в основном следуют политике
- Небольшие отклонения от целевого распределения (±2-3%)
- Имитирует реальное поведение: политика соблюдается, но есть исключения

**4. Метрика успеха**

```
Success Rate = (Количество симуляций в пределах ±5%) / 50,000 × 100%
```

Критерии:
- **Success Rate ≥ 80%** — метод надежен
- **60% ≤ Success Rate < 80%** — метод рискован
- **Success Rate < 60%** — метод ненадежен

---

## Структура кода

### Обзор архитектуры

Проект состоит из следующих основных компонентов:

```
merit_matrix_analysis/
│
├── Moscow.parquet.gzip              # Подготовленные данные (395,325 сотрудников)
├── 01_Simulation_Research.ipynb     # Jupyter Notebook, где проводится симуляции Monte Carlo
│
└── merit_analysis_results/          # Результаты симуляций
    ├── merit_analysis_CR5_R5_normal_*.parquet
    ├── merit_analysis_CR5_R5_skewed_high_*.parquet
    └── All_results.parquet          # Таблица со всеми результатами симуляций
       │
       └── 02_Analysis.ipynb        # Jupyter Nonetbook, где проводится анализ результатов исследования
           │
           └── 03_Merit_Matrix_Optimizer.ipynb # Генетический алгоритм по оптимизации Merit Matrix
```

### Основные компоненты кода

#### 1. Подготовка данных (Секция 1)

```python
# Загрузка исходных данных компенсаций
df_original = pd.read_parquet('03_Final_to_Code_corrected.parquet.gzip')

# Фильтрация: только Москва для консистентности
df_original = df_original[df_original['Region'] == 'Москва']

# Расчет Midpoint для каждой группы Company × Function × Grade
midpoints = df_original.groupby(['Company', 'Function', 'Grade'])['BP'].median()

# Расчет Compa Ratio
dataset['CR'] = dataset['BP'] / dataset['Midpoint']
```

**Что происходит:**
- Загружаются реальные данные о зарплатах из обзора компенсаций
- Данные фильтруются по Москве (наибольшая выборка, полнота данных)
- Для каждой комбинации Company × Function × Grade рассчитывается медиана зарплат (Midpoint)
- Для каждого сотрудника рассчитывается CR (отношение зарплаты к Midpoint)

#### 2. Генерация Merit Matrices (Секция 4)

```python
def generate_merit_matrix(n_cr_bins, n_ratings):
    """
    Генерирует merit matrix с принципами справедливости:
    - Низкий CR + Высокий рейтинг = Максимальное повышение (20%)
    - Высокий CR + Низкий рейтинг = Минимальное повышение (1%)
    - Рейтинг важнее (вес 70%) чем CR (вес 30%)
    """
    min_merit = 1.0    # Минимальное повышение
    max_merit = 20.0   # Максимальное повышение
    
    for cr_idx in range(n_cr_bins):
        for rating_idx in range(n_ratings):
            # Позиция в матрице (0 до 1)
            cr_position = cr_idx / (n_cr_bins - 1)
            rating_position = rating_idx / (n_ratings - 1)
            
            # Комбинированный фактор (рейтинг важнее)
            rating_factor = rating_position        # 70%
            cr_factor = 1 - cr_position            # 30% (инверсия!)
            combined = rating_factor * 0.7 + cr_factor * 0.3
            
            # Масштабирование к диапазону повышений
            merit = min_merit + (max_merit - min_merit) * combined
```

**Что происходит:**
- Создаются матрицы различных размеров (2×3 до 7×7)
- Процент повышения увеличивается с рейтингом (left→right)
- Процент повышения уменьшается с CR (top→bottom)
- Алгоритм автоматически генерирует "справедливые" проценты

**Пример сгенерированной матрицы 5×5:**

| CR Bin | R1 | R2 | R3 | R4 | R5 |
|--------|----|----|----|----|----| 
| [0.00-0.80) | 7.3% | 10.6% | 13.9% | 17.1% | 20.0% |
| [0.80-0.90) | 5.8% | 9.1% | 12.4% | 15.6% | 18.5% |
| [0.90-1.10) | 4.3% | 7.6% | 10.9% | 14.1% | 17.0% |
| [1.10-1.20) | 2.8% | 6.1% | 9.4% | 12.6% | 15.5% |
| [1.20-∞) | 1.3% | 4.6% | 7.9% | 11.1% | 14.0% |

#### 3. CR Bins Generator (Секция 4)

```python
def generate_cr_bins(n_bins):
    """
    Генерирует границы CR-бинов в зависимости от количества уровней.
    Логика: чем больше бинов, тем уже диапазоны около 1.0 (market rate)
    """
    if n_bins == 3:
        # Широкие диапазоны: ниже рынка, рынок, выше рынка
        return [0.0, 0.85, 1.15, ∞]
    elif n_bins == 5:
        # Средние диапазоны с focus на market rate (0.90-1.10)
        return [0.0, 0.80, 0.90, 1.10, 1.20, ∞]
    # ... другие конфигурации
```

**Что происходит:**
- Создаются границы для группировки сотрудников по CR


#### 4. Numba-оптимизированная Monte Carlo (Секция 6)

```python
@jit(nopython=True, parallel=True, fastmath=True, cache=True)
def _run_simulations_weighted(n_simulations, n_employees, base_salaries, 
                              cr_bins, merit_matrix, ...):
    """
    Ядро Monte Carlo симуляции с параллелизацией.
    Для каждой из 50,000 итераций:
      1. Сэмплировать распределение рейтингов из Dirichlet
      2. Присвоить рейтинг каждому сотруднику
      3. Рассчитать merit increase по матрице
      4. Суммировать total budget
      5. Проверить попадание в ±5% от target
    """
    for sim_idx in prange(n_simulations):  # Параллельные итерации
        sampled_probs = all_sampled_probs[sim_idx]
        
        # Cumulative probabilities для быстрого присвоения рейтингов
        cum_probs = build_cumulative(sampled_probs)
        
        total_merit_amount = 0.0
        for emp_idx in range(n_employees):
            # Присвоить рейтинг через inverse transform sampling
            rating_idx = assign_rating(random_value, cum_probs)
            
            # Получить merit% из матрицы
            merit_pct = merit_matrix[cr_bins[emp_idx], rating_idx]
            
            # Рассчитать merit amount
            merit_amount = base_salaries[emp_idx] * (merit_pct / 100)
            total_merit_amount += merit_amount
        
        # Проверить попадание в budget tolerance
        avg_merit_pct = (total_merit_amount / total_base) * 100
        within_budget[sim_idx] = (lower ≤ avg_merit_pct ≤ upper)
```

**Оптимизации:**
- **Numba JIT компиляция:** Ускорение в ~100 раз vs чистый Python
- **Параллелизация:** Использование всех CPU ядер через `parallel=True`
- **Vectorization:** Пре-генерация всех случайных чисел для быстрого доступа
- **Fastmath:** Оптимизация математических операций

**Производительность:**
- 50,000 итераций для группы из 100 сотрудников: ~2-3 секунды
- Обработка всех 120 конфигураций c 2921 гурппой сотрудников (Company x Function >= 10): ~5-7 часа на стандартном laptop

#### 5. FlexibleMeritAnalyzer Class (Секция 7)

Основной класс для анализа:

```python
class FlexibleMeritAnalyzer:
    def __init__(self, merit_matrix, cr_bin_edges, cr_bin_labels):
        """Инициализация анализатора с конкретной конфигурацией матрицы"""
        
    def calculate_heuristic_budget(self, cr_distribution, rating_distribution):
        """
        Эвристический расчет бюджета:
        Budget% = Σᵢ Σⱼ P(CR_i) × P(Rating_j) × Merit(i,j)
        """
        
    def run_monte_carlo_for_group(self, cr_values, base_pays, 
                                   target_merit_pool_pct, ...):
        """
        Запуск 50,000 Monte Carlo симуляций для одной группы.
        Возвращает: mean, median, std, percentiles, success_rate
        """
        
    def process_dataframe(self, df, rating_distribution, ...):
        """
        Обработка всех групп Company × Function в датафрейме.
        Для каждой группы запускает Monte Carlo и собирает результаты.
        """
```

**Workflow:**

```
FlexibleMeritAnalyzer
    ↓
process_dataframe(df)
    ↓
    for each (Company, Function) group:
        ↓
        calculate_cr_distribution()          # Распределение CR в группе
        ↓
        calculate_heuristic_budget()         # Расчет по методу агрегированных распределений
        ↓
        run_monte_carlo_for_group()          # 50,000 симуляций
            ↓
            _run_simulations_weighted()       # Numba-оптимизированный core
        ↓
        collect results (success_rate, percentiles, etc.)
    ↓
    return results_dataframe
```

#### 6. Multi-Configuration Analysis Loop (Секция 9)

```python
# Тестируемые конфигурации для проверки робастности
CR_BINS_RANGE = range(2, 8)      # 2, 3, 4, 5, 6, 7 CR bins
RATINGS_RANGE = range(3, 8)      # 3, 4, 5, 6, 7 ratings
DISTRIBUTIONS = {
    'normal': {...},              # Нормальное распределение
    'skewed_high': {...},         # Скошенное вправо (много высоких рейтингов)
    'skewed_low': {...},          # Скошенное влево (много низких рейтингов)
    'uniform': {...}              # Равномерное распределение
}

# Главный цикл
for n_cr in CR_BINS_RANGE:
    for n_ratings in RATINGS_RANGE:
        for dist_name, dist_configs in DISTRIBUTIONS.items():
            
            # Создать конфигурацию
            config_name = f"CR{n_cr}_R{n_ratings}_{dist_name}"
            merit_matrix = generate_merit_matrix(n_cr, n_ratings)
            cr_bins = generate_cr_bins(n_cr)
            rating_dist = dist_configs[n_ratings]
            
            # Инициализировать анализатор
            analyzer = FlexibleMeritAnalyzer(merit_matrix, cr_bins)
            
            # Запустить анализ для всех групп
            results = analyzer.process_dataframe(
                df=df,
                rating_distribution=rating_dist,
                n_simulations=50000,
                min_sample_size=10
            )
            
            # Сохранить результаты
            results.to_parquet(f"merit_analysis_{config_name}.parquet")
```

**Цель тестирования 120 конфигураций:**

Это не поиск "лучшей" конфигурации, а **проверка робастности метода**:
- Подтвердить, что результаты **не зависят** от выбора конкретного дизайна матрицы
- Показать, что метод агрегированных распределений работает **универсально**
- Исключить влияние случайных факторов (специфики конкретной конфигурации)

**Результат:** Метод показал стабильную точность (47-55%) на всех 120 конфигурациях, что доказывает его робастность.

**Объем вычислений:**
- **6 размеров CR bins** × **5 размеров ratings** × **4 типа распределений** = **120 конфигураций**
- Каждая конфигурация: ~200-300 групп (Company × Function)
- Каждая группа: 50,000 симуляций
- **Итого:** ~1.5 миллиарда симуляций

### Пошаговый workflow одного анализа

```
1. ЗАГРУЗКА ДАННЫХ
   └─ df (395,325 сотрудников, Москва)
   
2. ГРУППИРОВКА
   └─ Разделение по Company × Function (~300 групп)
   
3. ДЛЯ КАЖДОЙ КОНФИГУРАЦИИ (120 штук):
   │
   ├─ Генерация merit_matrix (например, 5×5)
   ├─ Генерация cr_bins (например, 5 бинов)
   ├─ Выбор rating_distribution (например, normal)
   │
   └─ ДЛЯ КАЖДОЙ ГРУППЫ (~300):
      │
      ├─ Фильтр: min 10 сотрудников
      ├─ Расчет распределения CR (по базовой зарплате)
      ├─ Бюджет по методу агрегированных распределений: Σ P(CR_i) × P(R_j) × Merit(i,j)
      │
      ├─ MONTE CARLO (50,000 итераций):
      │  │
      │  └─ Для каждой итерации:
      │     ├─ Sample rating distribution ~ Dirichlet(α)
      │     ├─ Присвоить рейтинги сотрудникам
      │     ├─ Рассчитать actual budget по merit matrix
      │     └─ Проверить: |actual - heuristic| ≤ 5%
      │
      ├─ Расчет метрик:
      │  ├─ Success rate (% within ±5%)
      │  ├─ Percentiles (P10, P25, P50, P75, P90)
      │  ├─ Mean, Median, Std
      │  └─ Min, Max, IQR
      │
      └─ Сохранение результатов
   
4. АГРЕГАЦИЯ РЕЗУЛЬТАТОВ
   └─ Сводная таблица: средний success rate по конфигурациям
```

---

## Данные

### Источник данных

**Обзор компенсаций (Compensation Survey)**
- Дата сбора: **01 мая 2025 года**
- Регион: **Москва** (наибольшая концентрация данных)
- Компании-участники: **Реальные компании** российского рынка
- Сотрудников: **395,325**

### Структура данных

**Исходный файл:** `03_Final_to_Code_corrected.parquet.gzip`

```python
Columns:
- Region                    # Регион (Москва, СПб, и т.д.)
- Company                   # Название компании (анонимизировано)
- Function                  # Функциональная линия (IT, Finance, HR, и т.д.)
- Grade                     # Грейд/уровень позиции
- BP (Base Pay)             # Базовая зарплата (фактическая)
```

**Обработанный файл:** `Moscow.parquet.gzip`

```python
Columns:
- Company                   # Компания
- Function                  # Функция
- BP                        # Базовая зарплата
- CR (Compa Ratio)          # BP / Midpoint
```

### Статистика данных

```
Всего сотрудников:           395,325
Компаний:                    [количество уникальных компаний]
Функций:                     [количество уникальных функций]
Комбинаций Company×Function: ~300 групп

Compa Ratio статистика:
  Mean:     1.05
  Median:   1.02
  Min:      0.35
  Max:      2.87
  Std:      0.23
```

### Почему только Москва?

**Причины выбора:**
1. ✅ **Размер выборки:** Москва содержит наибольшее количество данных
2. ✅ **Полнота:** В московских офисах представлены все грейды и функции
3. ✅ **Однородность рынка:** Единый рынок труда для консистентного анализа
4. ✅ **Репрезентативность:** В Москве сконцентрирован весь менеджмент компаний

**Альтернатива:** Регионы можно анализировать отдельно, но выборки будут меньше.

### Предобработка данных

**Шаг 1: Фильтрация**
```python
df = df[df['Region'] == 'Москва']
```

**Шаг 2: Расчет Midpoint**
```python
# Midpoint = медиана BP внутри Company × Function × Grade
midpoints = df.groupby(['Company', 'Function', 'Grade'])['BP'].median()
```

**Обоснование использования медианы:**
- Устойчива к выбросам (outliers)
- Отражает "серединную точку" диапазона зарплат
- Стандартная практика в compensation management

**Шаг 3: Расчет Compa Ratio**
```python
df['CR'] = df['BP'] / df['Midpoint']
```

**Интерпретация CR:**
- CR < 1.0 → сотрудник получает ниже медианы грейда
- CR = 1.0 → сотрудник на медиане грейда
- CR > 1.0 → сотрудник получает выше медианы грейда

**Шаг 4: Агрегация**
```python
# Убираем Grade - объединяем всех сотрудников внутри Company × Function
df_final = df[['Company', 'Function', 'BP', 'CR']]
```

**Обоснование агрегации:**
- Merit matrices применяются ко всем сотрудникам функции независимо от грейда
- CR уже учитывает позицию сотрудника относительно его грейда
- Это отражает реальную практику HR

---

## Результаты

### Визуализация результатов

![Success Rate by Model Parameters](success_rate_by_parameters.png)

*Рисунок 1: Влияние различных параметров на success rate метода агрегированных распределений*

### Ключевые выводы

*Примечание: Детальные результаты анализа находятся в отдельных файлах. Здесь представлено краткое резюме для понимания методологии.*

**Главный вывод: фундаментальное ограничение практической применимости**

Исследование показало, что **метод агрегированных распределений имеет критическое ограничение**, делающее его непригодным для большинства организаций. Проблема не в самом методе, а в конфликте между статистическими требованиями и бизнес-реальностью.

**1. Влияние размера группы (критический фактор) ⭐**

Точность метода **критически зависит** от размера группы:

| Размер группы | Success Rate | Интерпретация для бюджетной дисциплины |
|---------------|--------------|----------------------------------------|
| 0-20          | ~33%         | ❌ Катастрофа: 2 из 3 случаев выход за бюджет |
| 21-50         | ~46%         | ❌ Провал: больше половины случаев выход за бюджет |
| 51-100        | ~61%         | ❌ Неприемлемо: 40% случаев выход за бюджет |
| 101-200       | ~77%         | ⚠️ Рискованно: 23% случаев выход за бюджет |
| 201-500       | ~91%         | ✅ Приемлемо: 9% случаев выход за бюджет |
| 500+          | ~98%         | ✅ Надежно: 2% случаев выход за бюджет |

**Критический порог для бюджетной дисциплины:** 200+ сотрудников для достижения приемлемого 80%+ success rate.

**Причина:** Закон больших чисел (Law of Large Numbers)
- Малые группы: высокая вариативность при присвоении рейтингов → непредсказуемый бюджет
- Большие группы: распределение рейтингов стремится к ожидаемому → предсказуемый бюджет

**2. Проверка независимости от конфигурации**

Тестирование 30 различных размеров матриц (от 2×3 до 7×7) показало:
- **Разброс в success rate:** 47-55% (только 8 процентных пунктов)
- **Вывод:** Размер матрицы практически не влияет на точность метода
- **Интерпретация:** Результаты **не зависят** от выбора конфигурации — проблема в размере выборки

| Параметр | Диапазон | Влияние на Success Rate |
|----------|----------|------------------------|
| Количество CR bins | 2-7 | 47-53% (разброс 6%) |
| Количество Ratings | 3-7 | 48-54% (разброс 6%) |

**3. Влияние типа распределения (умеренное)**

| Тип распределения | Success Rate | Разница от среднего |
|-------------------|--------------|---------------------|
| Skewed High | ~57% | +7% |
| Normal | ~52% | +2% |
| Uniform | ~48% | -2% |
| Skewed Low | ~43% | -7% |

**Разброс:** 43-57% (14 процентных пунктов) — умеренное влияние, но **значительно меньше**, чем влияние размера группы.

**4. Сводная таблица влияния факторов**

| Фактор | Разброс Success Rate | Относительное влияние |
|--------|---------------------|----------------------|
| **Размер группы** | **33% → 98%** (65%) | ⭐⭐⭐⭐⭐ Критический |
| Тип распределения | 43% → 57% (14%) | ⭐⭐ Умеренное |
| Количество CR bins | 47% → 53% (6%) | ⭐ Минимальное |
| Количество Ratings | 48% → 54% (6%) | ⭐ Минимальное |

**Статистический вывод:**
- **Размер группы объясняет ~85-90%** вариации в success rate
- **Все остальные факторы объясняют ~10-15%** вариации
- Оптимизация конфигурации матрицы **не решает** проблему точности

---

### Критическая проблема: парадокс практической применимости

**Реальность бизнеса: сегментация неизбежна**

Компании **не могут** применять единую merit matrix ко всей организации по следующим причинам:

1. **Различные бюджеты по функциям**
   - IT функция: высокий рыночный рост → больший бюджет на повышения (например, 8%)
   - Administrative функция: низкий рыночный рост → меньший бюджет (например, 3%)
   - Невозможно использовать одну матрицу для обеих функций

2. **Различная рыночная динамика**
   - Data Science: война за таланты → агрессивные повышения
   - Accounting: стабильный рынок → консервативные повышения
   - Требуются разные merit matrices для отражения рыночной реальности

3. **Стратегические приоритеты**
   - Критические функции получают больший бюджет
   - Поддерживающие функции получают меньший бюджет
   - Необходимость дифференциации → необходимость сегментации

**Пример: компания из 1,000 сотрудников**

Типичная средняя компания должна сегментировать сотрудников:

```
Компания: 1,000 сотрудников

Сегментация по функциям:
├── IT (250 чел)               → Merit Matrix A (бюджет 8%)
├── Sales (200 чел)            → Merit Matrix B (бюджет 7%)
├── Finance (150 чел)          → Merit Matrix C (бюджет 4%)
├── Operations (250 чел)       → Merit Matrix D (бюджет 5%)
└── Admin/Support (150 чел)    → Merit Matrix E (бюджет 3%)

Размер групп: 150-250 человек
Success rate на этом размере: ~50-70%
Интерпретация: НЕПРИЕМЛЕМО для бюджетной дисциплины
```

**Финансовые последствия 50% success rate:**

- **50% случаев** → выход за бюджет на 5%+
- При общем бюджете повышений в 50 млн руб → **потенциальный перерасход 2.5+ млн руб**
- Finance департамент **не примет** такую неопределенность
- CFO **не одобрит** бюджет с 50% вероятностью перерасхода

**Парадокс метода:**

| Требование | Реальность | Конфликт |
|------------|-----------|----------|
| **Статистика:** Нужно 200+ человек для 80%+ точности | **Бизнес:** Сегментация → группы по 100-200 человек | ❌ Несовместимо |
| **Метод:** Работает для недифференцированных больших групп | **Практика:** Функции требуют разных матриц и бюджетов | ❌ Несовместимо |
| **Условие:** Минимум 500+ человек для высокой надежности | **Типичная компания:** 1000-5000 сотрудников, 5-10 функций | ❌ Недостижимо |

**Вывод:** Даже компании с тысячами сотрудников не могут надежно использовать метод агрегированных распределений из-за необходимости функциональной сегментации.

---

### Компании, которые МОГУТ использовать метод (крайне редкие случаи)

**Единственный сценарий применимости:**

✅ Гигантские организации с гомогенными функциями:
- Google (Engineering функция: 10,000+ инженеров с единой матрицей)
- Call-center с 2,000+ операторов
- Manufacturing с 5,000+ рабочих на производстве

❌ **Все остальные:** малые, средние и большинство крупных компаний (до 10,000 человек) **не могут** надежно применять метод из-за неизбежной сегментации.

### Бизнес-рекомендации

**Реалистичная оценка применимости метода**

На основе исследования можно сделать следующие выводы о практической применимости:

#### Сценарий 1: Гигантские гомогенные функции (РЕДКО) ✅

**Применимо для:**
- Технологические гиганты: единая Engineering функция с 1000+ инженеров
- Крупные call-centers: 500+ операторов с идентичными ролями
- Массовое производство: 1000+ рабочих одной категории

**Условия:**
- ≥ 500 сотрудников в единой функциональной группе
- Гомогенная функция (не требует дальнейшей сегментации)
- Ожидаемый success rate: 95%+

**Доля компаний:** < 5% (только крупнейшие корпорации)

#### Сценарий 2: Крупные компании с агрегацией (РИСКОВАННО) ⚠️

**Применимо для:**
- Компании 5,000+ сотрудников
- Функции по 200-400 человек каждая
- Готовность принять 10-20% риск перерасхода

**Условия:**
- 200-400 сотрудников на функцию
- Резервный буфер +15-20% к планируемому бюджету
- Ожидаемый success rate: 80-90%

**Ограничения:**
- Требует значительных резервов бюджета
- Finance департамент может не одобрить такую неопределенность
- Необходим постоянный мониторинг и корректировки

**Доля компаний:** ~15-20%

#### Сценарий 3: Типичные компании (НЕПРИМЕНИМО) ❌

**НЕ применимо для:**
- Малый бизнес: < 500 сотрудников
- Средний бизнес: 500-2,000 сотрудников
- Большинство крупных компаний: 2,000-10,000 сотрудников

**Причина:**
- Сегментация по функциям → группы по 50-200 человек
- Success rate на этом размере: 40-70%
- **40-60% случаев выход за бюджет** → неприемлемо для бюджетной дисциплины

**Доля компаний:** ~75-80% (подавляющее большинство)

---

### Практический вывод: необходимость альтернативных методов

**Метод агрегированных распределений имеет фундаментальное ограничение**, которое делает его непригодным для большинства организаций.

**Что НЕ работает:**
- ❌ "Использовать для групп 100+ человек" → 50-70% success rate неприемлемо
- ❌ "Оптимизировать конфигурацию матрицы" → влияние минимально (±6%)
- ❌ "Увеличить tolerance до ±10%" → не решает проблему, только скрывает
- ❌ "Объединить функции" → нарушает бизнес-логику дифференциации

**Что необходимо:**

Для **75-80% компаний** требуются **принципиально иные подходы** к бюджетированию повышений:

1. **Фиксированный процент по функциям**
   - Например: "IT функция получает 8% от фонда оплаты труда"
   - Простота vs отсутствие связи с performance

2. **Индивидуальное рассмотрение**
   - Каждое повышение утверждается индивидуально
   - Гибкость vs высокие административные затраты

3. **Гибридные подходы**
   - Merit matrix как ориентир, но не как жесткое правило
   - Требует экспертного суждения + данные

4. **Расширенные допуски с резервами**
   - Использовать ±15-20% tolerance
   - Закладывать значительный резервный фонд
   - Требует согласия Finance

**Рекомендация для исследования:**
Следующим шагом должна быть разработка и валидация **альтернативных методов бюджетирования**, пригодных для типичных организационных структур (функции по 50-200 человек).

---

### Выводы

#### ✅ **Что подтверждено:**
- Метод агрегированных распределений **математически корректен**
- Для групп 500+ сотрудников достигает высокой точности (95%+)
- Точность **не зависит** от конфигурации матрицы (робастность к дизайну)
- Метод дает точное **математическое ожидание** бюджета

#### ❌ **Критические ограничения:**
- **Требует 200+ сотрудников** для приемлемой точности (80%+)
- **Несовместим с необходимостью функциональной сегментации** в типичных компаниях
- **Неприменим для 75-80% организаций** из-за ограничений размера групп
- При success rate 50-70% **создает неприемлемые финансовые риски**

#### 🎯 **Итоговая линия:**

**Метод агрегированных распределений имеет фундаментальное противоречие между статистическими требованиями и бизнес-реальностью.**

Это не недостаток метода — это **ограничение применимости**. Метод работает отлично там, где применим (гигантские гомогенные группы), но таких случаев крайне мало в реальной практике.

**Проблема не решается:**
- ✗ Оптимизацией дизайна матрицы (влияние минимально)
- ✗ Изменением типа распределения (влияние умеренное)
- ✗ Расширением толеранса (скрывает проблему, не решает)

**Проблема решается только:**
- ✓ Радикальным увеличением размера групп (часто невозможно)
- ✓ Разработкой альтернативных методов для типичных размеров групп (будущее исследование)

**Практическая ценность исследования:**
Впервые количественно показано, что **широко используемый в индустрии метод** имеет серьезное ограничение применимости, которое ранее не было систематически задокументировано. Это открывает необходимость поиска более подходящих подходов для majority of organizations.

---

### Визуальная интерпретация: парадокс применимости

```
СТАТИСТИЧЕСКИЕ ТРЕБОВАНИЯ vs БИЗНЕС-РЕАЛЬНОСТЬ

                              Success Rate
                                   ↑
                              100% |                    ✓ Надежно
                                   |                 ╱
                               90% |              ╱
                                   |            ╱
                               80% |─ ─ ─ ─ ╱ ─ ─ ─ ─  Порог приемлемости
                                   |       ╱
                               70% |     ╱
                                   |   ╱  
                               50% | ╱              ✗ Неприемлемо
                                   |╱
                                0  └─────────────────────────────→
                                   0   100   200   300   400   500+
                                          Размер группы

ТИПИЧНАЯ КОМПАНИЯ (1000 человек):
┌─────────────────────────────────────────────────────────────┐
│ Функция        │ Сотрудников │ Success Rate │ Применимость │
├─────────────────────────────────────────────────────────────┤
│ IT             │ 250         │ ~70%         │ ⚠️ Рискованно│
│ Sales          │ 200         │ ~65%         │ ❌ Неприемлемо│
│ Finance        │ 150         │ ~55%         │ ❌ Провал     │
│ Operations     │ 250         │ ~70%         │ ⚠️ Рискованно│
│ Admin/Support  │ 150         │ ~55%         │ ❌ Провал     │
└─────────────────────────────────────────────────────────────┘

ПАРАДОКС: Метод требует 200+ человек, но бизнес создает группы по 100-200
          → Метод непригоден для большинства реальных случаев
```

**Решение НЕ в масштабе компании, а в необходимости сегментации:**
- ✗ Компания из 10,000 человек не решает проблему
- ✓ Если функции по 100-200 человек — проблема остается
- 🎯 Нужны методы, работающие для групп 50-200 человек

---

## Технические детали

### Требования к окружению

```python
# Python 3.8+
numpy >= 1.20.0
pandas >= 1.3.0
scipy >= 1.7.0
numba >= 0.54.0
matplotlib >= 3.4.0
seaborn >= 0.11.0
```

### Установка зависимостей

```bash
pip install numpy pandas scipy numba matplotlib seaborn
```

### Параметры симуляции

```python
# Основные параметры
N_SIMULATIONS = 50_000              # Количество Monte Carlo итераций
MIN_SAMPLE_SIZE = 10                # Минимум сотрудников в группе
BUDGET_TOLERANCE_LOWER = 0.05       # -5% допуск
BUDGET_TOLERANCE_UPPER = 0.05       # +5% допуск
CONCENTRATION = 250                 # Параметр Dirichlet распределения

# Диапазоны конфигураций
CR_BINS_RANGE = range(2, 8)         # 2, 3, 4, 5, 6, 7 CR bins
RATINGS_RANGE = range(3, 8)         # 3, 4, 5, 6, 7 ratings
```

**Объяснение CONCENTRATION = 250:**
- Параметр α в Dirichlet(α) распределении
- Большое значение (250) → малое отклонение от целевого распределения
- Имитирует: менеджеры в целом следуют политике, но есть небольшие исключения
- Типичное отклонение: ±2-3% от целевых долей рейтингов

### Время выполнения

На стандартном laptop (8 cores, 16GB RAM):

```
Одна группа (50,000 симуляций):     ~2-3 секунды
Все группы для 1 конфигурации:      ~10-15 минут
Все 120 конфигураций:               ~2-4 часа
```

**Оптимизации для ускорения:**
1. Уменьшить N_SIMULATIONS до 10,000 (уменьшит точность, но ускорит в 5 раз)
2. Тестировать меньше конфигураций (например, только 5×5 матрицы)
3. Использовать параллелизацию на уровне групп (не реализовано в текущей версии)

### Воспроизводимость результатов

Для воспроизводимости установите seed:

```python
np.random.seed(42)
```

⚠️ **Внимание:** Из-за параллелизации в Numba результаты могут незначительно различаться между запусками даже с фиксированным seed.

### Формат выходных файлов

**1. Результаты по конфигурациям**

```
merit_analysis_results/
├── merit_analysis_CR5_R5_normal_20250518_143022.parquet
│   Columns:
│   - company, function
│   - n_employees
│   - heuristic_budget_pct           # Расчет по методу агрегированных распределений
│   - mc_mean_pct                    # Среднее по Monte Carlo
│   - mc_median_pct, mc_std_pct
│   - mc_p10_pct, mc_p25_pct, ...   # Перцентили
│   - success_rate_pct               # % попаданий в ±5%
│   - cr_bin_0_pct_bp, ...           # Распределение CR (weighted by BP)
│   ...
```

**2. Сводная таблица**

```
analysis_summary_20250518_150045.csv
Columns:
- config_name                        # CR5_R5_normal
- n_cr_bins, n_ratings
- distribution_type
- n_groups                           # Количество проанализированных групп
- mean_mc_budget                     # Средний бюджет по всем группам
- mean_success_rate                  # Средний success rate
- processing_time_sec
```

---

## Структура Jupyter Notebook

Notebook организован в логические секции с markdown комментариями:

```
1. Setup and Imports
   - Импорты библиотек
   - Загрузка и подготовка данных

2. Configuration Parameters
   - Настройка параметров симуляции
   - Определение диапазонов конфигураций

3. Rating Distributions Configuration
   - 4 типа распределений (normal, skewed_high, skewed_low, uniform)
   - Для каждого количества рейтингов (3-7)

4. Merit Matrix Generator Functions
   - generate_merit_matrix(): создание матриц
   - generate_cr_bins(): создание CR-бинов

5. Preview Merit Matrices
   - Визуализация всех матриц для проверки

6. Numba-Optimized Simulation Function
   - _run_simulations_weighted(): core Monte Carlo

7. FlexibleMeritAnalyzer Class
   - Основной класс для анализа

8. Load Data
   - Загрузка Moscow.parquet.gzip

9. Run Multi-Configuration Analysis
   - Главный цикл: 120 конфигураций
   - Прогресс и timing

10. Save and Display Summary
    - Сохранение результатов
    - Вывод summary таблицы

11. Visualization of Results
    - Heatmaps: budget и success rate
    - Bar charts: по типам распределений

12. Quick Analysis Functions
    - analyze_specific_config()
    - compare_distributions()
```

### Использование notebook

**Основной workflow:**

```python
# 1. Запустить все ячейки до секции 9 (подготовка)
# 2. Проверить сгенерированные матрицы в секции 5
# 3. При необходимости изменить параметры в секции 2
# 4. Запустить секцию 9 (долгая операция!)
# 5. Проанализировать результаты в секциях 10-12
```

**Для быстрого тестирования:**

```python
# Уменьшить количество конфигураций
CR_BINS_RANGE = range(4, 6)         # Только 4 и 5 bins
RATINGS_RANGE = range(4, 6)         # Только 4 и 5 ratings
# Итого: 2 × 2 × 4 = 16 конфигураций вместо 120

# Уменьшить количество симуляций
N_SIMULATIONS = 10_000               # Вместо 50,000
```

---

## Дальнейшее развитие проекта

Этот этап является **диагностическим** — он выявляет фундаментальное ограничение широко используемого метода и формулирует требования к решению.

### Ключевой вывод текущего этапа

**Метод агрегированных распределений имеет критическое ограничение** — требует 200+ сотрудников для приемлемой точности, что делает его непригодным для большинства организаций из-за необходимости функциональной сегментации.

**Проблема НЕ в самом методе расчета бюджета**, а в том, что:
1. Метод **предполагает равномерное распределение** CR и рейтингов
2. В реальности распределение CR **неравномерно** (концентрация около 1.0)
3. Это создает **высокую вариативность** в малых группах

### Реализованное решение: генетический алгоритм оптимизации (Lens Consulting)

**На основе результатов исследования компания Lens Consulting разработала коммерческое решение** — генетический алгоритм, который оптимизирует merit matrices с учетом **реального распределения сотрудников** по CR bins.

Решение предоставляется исключительно клиентам Lens Consulting в рамках консалтинговых проектов по компенсациям и льготам.

#### Принципиальное отличие от метода агрегированных распределений

**Метод агрегированных распределений:**
```
1. Предполагает: CR и рейтинги независимы
2. Рассчитывает: Бюджет = Σ P(CR_i) × P(Rating_j) × Merit(i,j)
3. Проблема: Не учитывает реальное распределение сотрудников
4. Результат: Работает только для очень больших групп (200+)
```

**Генетический алгоритм:**
```
1. Использует: Реальное распределение сотрудников по CR bins
2. Оптимизирует: Матрицу для конкретной популяции
3. Валидирует: Через Monte Carlo с реальными данными
4. Результат: Работает для групп любого размера
```

#### Архитектура решения

**Компоненты системы:**

```python
# 1. Генетический алгоритм
- Популяция: 1000 кандидатов матриц
- Поколения: 500 итераций с ранней остановкой
- Операторы: Турнирная селекция, кроссовер, мутация
- Локальная оптимизация: L-BFGS-B для top-5 кандидатов

# 2. Многокритериальная функция fitness
def evaluate_fitness(matrix, scenarios):
    # Основные критерии (100%):
    budget_score = попадание в диапазон ±5% от целевого бюджета
    constraint_score = соблюдение принципов справедливости
    
    # Дополнительный бонус:
    differentiation_score = видимость различий между рейтингами
    
    # Итоговая оценка:
    fitness = 0.70 * budget_score + 
              0.30 * constraint_score + 
              DIFF_WEIGHT * differentiation_score

# 3. Принципы справедливости (constraints)
- Монотонность по рейтингу: Rating_j+1 ≥ Rating_j
- Монотонность по CR: CR_bin_i+1 ≤ CR_bin_i
- Минимальные шаги: видимая дифференциация
- Максимальные шаги: защита от экстремальных значений
- Anchor cells: фиксация угловых значений

# 4. Monte Carlo валидация
- 10,000+ симуляций для каждой матрицы
- Dirichlet perturbation целевого распределения
- Стресс-сценарии: inflated, harsh, forced_curve
- Success rate: % попаданий в бюджет ±5%
```

#### Ключевые преимущества

**1. Адаптация к реальному распределению**

Алгоритм **оптимизирует матрицу под конкретную популяцию сотрудников**:
- Если 70% сотрудников имеют CR = 0.95-1.05 → алгоритм учитывает это
- Матрица "знает" о реальном распределении и оптимизируется под него
- **Результат:** Высокая точность даже для малых групп (50-100 человек)

**2. Гарантия соблюдения принципов справедливости**

```python
# Жесткие ограничения (встроены в алгоритм):
1. Higher rating → Higher merit (монотонность)
2. Higher CR → Lower merit (монотонность)
3. Видимая дифференциация (min steps)
4. Защита от экстремальных значений (max steps)
5. Anchor cells (например: top performer = 20%, worst = 1%)
6. Strict zeros (например: high CR + low rating = 0%)

# Мягкие ограничения (через fitness penalties):
- Smooth transitions между соседними ячейками
- Разумные диапазоны повышений
- Баланс между дифференциацией и бюджетом
```

**3. Робастность через Monte Carlo**

```python
# Валидация на 10,000+ сценариев:
for scenario in monte_carlo_scenarios:
    # Perturbation целевого распределения рейтингов
    actual_distribution = Dirichlet(target_dist, concentration)
    
    # Расчет реального бюджета для этого сценария
    actual_budget = compute_budget(matrix, employee_data, actual_distribution)
    
    # Проверка попадания в tolerance
    if within_tolerance(actual_budget, target_budget):
        success_count += 1

success_rate = success_count / total_scenarios
```

**4. Автоматическая генерация policy guidance**

Алгоритм не только создает матрицу, но и **генерирует рекомендации** для менеджеров:

```python
# Для каждого рейтинга определяется:
Rating 1: Target 10% | Hard Min 7% | Hard Max 13%
Rating 2: Target 15% | Hard Min 12% | Hard Max 18%
Rating 3: Target 50% | Hard Min 47% | Hard Max 53%
Rating 4: Target 15% | Hard Min 12% | Hard Max 18%
Rating 5: Target 10% | Hard Min 7% | Hard Max 13%

# Hard Min/Max = P10/P90 из успешных Monte Carlo сценариев
# Это реалистичные границы, при которых бюджет соблюдается
```

#### Практическое применение

**Workflow использования:**

```
Шаг 1: Подготовка данных
├─ Загрузить данные о сотрудниках (base_salary, CR)
├─ Определить целевой бюджет (например, 8%)
└─ Задать целевое распределение рейтингов

Шаг 2: Настройка параметров
├─ Количество CR bins (2-7)
├─ Количество рейтингов (3-7)
├─ Budget tolerance (например, ±5%)
├─ Anchor cells (опционально)
└─ Force zero cells (опционально)

Шаг 3: Запуск оптимизации
├─ Генетический алгоритм: 500 поколений
├─ Monte Carlo валидация: 10,000 сценариев
└─ Время выполнения: 10-30 минут

Шаг 4: Получение результатов
├─ Top-20 оптимальных матриц
├─ Для каждой: fitness, success rate, policy guidance
├─ Экспорт в Excel: matrix + metadata + policy
└─ Выбор лучшей матрицы по критериям бизнеса
```

**Пример результата:**

```
BEST MATRIX (Success Rate: 94.2%)
                Rating 1  Rating 2  Rating 3  Rating 4  Rating 5
CR [0.0-0.80)      3.5%      6.8%     10.2%     13.5%     16.8%
CR [0.80-0.90)     2.8%      5.9%      9.1%     12.2%     15.3%
CR [0.90-1.10)     2.1%      5.0%      8.0%     11.0%     14.0%
CR [1.10-1.20)     1.4%      4.1%      6.9%      9.6%     12.3%
CR [1.20-∞)        0.7%      3.2%      5.8%      8.3%     10.8%

Fitness: 0.9547
Budget Score: 0.9823  (98.2% scenarios within ±5%)
Constraint Score: 0.9871  (все принципы соблюдены)
Mean Deviation: 1.23%  (средний отклонение от целевого бюджета)

POLICY GUIDANCE:
Rating 1: Target 10% | Range 8.2-11.8%
Rating 2: Target 15% | Range 13.1-16.9%
Rating 3: Target 50% | Range 48.3-51.7%
Rating 4: Target 15% | Range 13.2-16.8%
Rating 5: Target 10% | Range 8.3-11.7%
```

### Валидация на реальных данных

**Тестирование на данных исследования:**

```
Данные: 395,325 сотрудников (Москва)
Группы: Company × Function
Размеры групп: от 10 до 5000+ сотрудников

Результаты применения генетического алгоритма:
├─ Группы 50-100 сотрудников: Success rate 82-88%
├─ Группы 100-200 сотрудников: Success rate 88-94%
└─ Группы 200+ сотрудников: Success rate 95%+

Сравнение с методом агрегированных распределений:
                               Aggregated      Genetic
                               Distributions   Algorithm
Группы 50-100:                 ~55%           ~85%
Группы 100-200:                ~70%           ~92%
Группы 200+:                   ~90%           ~96%

Улучшение: +25-35 процентных пунктов для малых/средних групп
```

### Технические характеристики

**Производительность:**

```python
# Время выполнения (на стандартном laptop):
- Группа 100 сотрудников: ~15 минут
- Группа 500 сотрудников: ~25 минут
- Группа 1000+ сотрудников: ~40 минут

# Масштабируемость:
- Population size: до 2000 кандидатов
- Generations: до 1000 итераций
- Monte Carlo scenarios: до 50,000 симуляций
- Параллелизация: поддержка multi-core

# Оптимизации:
- Numba JIT для критичных функций
- Vectorized fitness evaluation
- Early stopping при конвергенции
- Локальная оптимизация L-BFGS-B
```

**Требования к окружению:**

```python
# Дополнительные зависимости (помимо основных):
scipy >= 1.7.0        # Для optimize.minimize
openpyxl >= 3.0.0     # Для Excel экспорта
numba >= 0.54.0       # Для JIT компиляции

# Рекомендуемые ресурсы:
- CPU: 4+ cores (для параллелизации)
- RAM: 8+ GB (для больших популяций)
- Время: 15-40 минут на оптимизацию
```

### Ограничения и известные проблемы

**1. Зависимость от качества данных**

```
Требования к данным:
✓ Минимум 10 сотрудников в группе для статистической значимости
✓ Base salary данные должны быть актуальными
✓ CR данные должны быть корректно рассчитаны

Примечание: 
Алгоритм работает с ЛЮБЫМ распределением CR - даже если все 
сотрудники в одном бине. Оптимизация учитывает фактическое 
распределение и адаптируется под него.

Проблемы при нарушении:
✗ < 10 сотрудников → высокая вариативность (фундаментальная проблема малых выборок)
✗ Устаревшие salary данные → неточный расчет бюджета
✗ Некорректный расчет CR → неправильная сегментация
```

**2. Computational cost для очень больших организаций**

```
Для компаний с 10+ функциями:
- Нужно оптимизировать 10+ матриц независимо
- Каждая оптимизация: 15-40 минут
- Итого: 2.5-6.5 часов total time

Решение:
- Параллельная оптимизация нескольких функций
- Использование AWS/cloud для ускорения
- Кэширование результатов для похожих групп
```

### Практическая ценность решения

**Для HR-функции:**

✅ **Универсальность:** Работает для групп любого размера (от 50 человек)  
✅ **Точность:** 85-96% success rate в зависимости от размера группы  
✅ **Гибкость:** Настраиваемые anchor cells, force zeros, constraints под специфику компании  
✅ **Адаптивность:** Работает с любым распределением CR (не требует равномерного покрытия бинов)  
✅ **Автоматизация:** Генерация policy guidance автоматически  
✅ **Прозрачность:** Понятные критерии оптимизации (бюджет + справедливость)

**Для Finance:**

✅ **Предсказуемость:** Заранее известна вероятность попадания в бюджет  
✅ **Управляемость:** Настраиваемые tolerance (например, ±3% или ±5%)  
✅ **Валидация:** Monte Carlo подтверждает надежность до применения  
✅ **Минимизация рисков:** Значительно меньше перерасходов vs традиционный метод

**Для бизнеса:**

✅ **Справедливость:** Гарантированное соблюдение принципов (performance, market positioning)  
✅ **Применимость:** 75-80% компаний теперь могут использовать data-driven подход  
✅ **Масштабируемость:** Решение работает для компаний от 100 до 100,000 сотрудников  
✅ **Экономия:** Снижение перерасходов на 2-5% от бюджета merit pool

### Направления будущих исследований

**1. Multi-objective optimization**

```python
# Текущий подход: weighted sum fitness
# Будущее развитие:
- Pareto optimization: множество оптимальных решений
- Tradeoff analysis: бюджет vs дифференциация
- Interactive selection: HR выбирает из Pareto front
```

**2. Временная динамика и адаптивное обучение**

```python
# Текущий подход: single-shot optimization
# Будущее развитие:
- Анализ year-over-year: как меняются результаты?
- Adaptive learning: автоматическая корректировка на основе исторических данных
- Predictive modeling: forecast изменений в распределениях
```

**3. Расширение методологии на другие рынки и индустрии**

```python
# Текущий подход: валидация на данных Москвы
# Будущее развитие:
- Применение к другим регионам (СПб, регионы)
- Отраслевая специфика (IT vs Manufacturing vs Finance)
- Международные данные и кросс-культурный анализ
```

### Публикации и научная ценность

**Потенциальные статьи на основе проекта:**

1. **"Monte Carlo Validation of Aggregated Distributions Method in Merit Matrix Budgeting"**
   - Основная статья по первому этапу (диагностика проблемы)
   - Вклад: первое систематическое исследование ограничений метода
   - Данные: 395,325 сотрудников, 120 конфигураций

2. **"Genetic Algorithm Approach to Merit Matrix Optimization: Overcoming Sample Size Limitations"**
   - Статья по второму этапу (реализованное решение)
   - Вклад: новый метод, работающий для малых групп
   - Результаты: +25-35% улучшение success rate

3. **"Practical Application of Multi-objective Optimization in Compensation Management"**
   - Кейс-исследование применения на реальных данных
   - Вклад: bridge между теорией и практикой
   - Индустриальная значимость: решение для 75% компаний

**Академическая новизна:**

- Первое количественное исследование точности aggregated distributions method
- Выявление fundamental limitation (sample size vs segmentation paradox)
- Разработка практического решения (genetic algorithm) для коммерческого применения
- Валидация на крупномасштабных реальных данных (395K+ сотрудников)

### Итоговые выводы

**Двухэтапный проект:**

**Этап 1 (данный README - академическое исследование):** Диагностика  
- Метод агрегированных распределений имеет фундаментальное ограничение
- Количественно показано: требует 200+ сотрудников для надежности
- Непригоден для 75-80% компаний из-за необходимости сегментации
- Первое систематическое исследование на данных 395K+ сотрудников

**Этап 2 (коммерческое решение Lens Consulting):** Решение  
- Генетический алгоритм решает проблему малых групп
- Улучшение success rate на +25-35% для групп 50-200 человек
- Применим для 75-80% компаний (тех, кто не мог использовать старый метод)
- Доступен исключительно клиентам Lens Consulting

**Практическая значимость:**

Академическое исследование выявило фундаментальное ограничение широко используемого метода и количественно показало его границы применимости. На основе этих результатов было разработано коммерческое решение, которое преодолевает выявленные ограничения и делает **data-driven подход к merit matrices доступным для большинства организаций**.
